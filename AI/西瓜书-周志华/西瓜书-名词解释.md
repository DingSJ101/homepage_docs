# 西瓜书-名词解释

## 符号解释

| 符号                                                         | 含义                                | 注释                                                         |
| ------------------------------------------------------------ | ----------------------------------- | ------------------------------------------------------------ |
| $D$                                                          | 数据集                              |                                                              |
| $x$                                                          | 测试样本                            |                                                              |
| $y_D$                                                        | 数据集标记                          | 随机变量，噪声可能导致$y_D\not=y$                            |
| $y$                                                          | 样本的真实标记                      | 常量                                                         |
| $X_i,\mu_i,\sum_i$                                           | 第`i`类的集合、均值向量、协方差矩阵 | Page60，线性判别分析                                         |
| $Ent(D) = -\sum\limits^{|\mathop{\mathcal Y}|}_{k=1}{p_klog_2p_k}$ | 集合D的信息熵                       | $p_k(k=1,2,\cdots,|\mathcal Y|)$表示集合`D`中第`k`类样本的比例 |
|                                                              |                                     |                                                              |
| $f(x;D)$                                                     | D上的模型`f`在`x`上的预测输出       |                                                              |
| $\mathbb{E}_{x\sim D}[f(x)]$                                 | 函数在分布`D`下的数学期望           | 意义明确时，可省略分布`D`                                    |
| $(x_1,\cdots,x_n)$                                           | 行向量                              |                                                              |
| $(x_1;\cdots;x_n)$                                           | 列向量                              |                                                              |
| $(w^*,b^*)=\\\mathop{arg min}\limits_{(w,b)}\sum\limits_{i=1}^m(f(x_i)-y_i)^2\\\mathop{arg min}\limits_{(w,b)}\sum\limits_{i=1}^m(y_i-wx_i-b)^2$ | 最小二乘法进行模型求解              | `w*，b*`表示参数w和b的解<br >argmin表示表达式取最小值时的参数值 |
| $\hat{w}^*=\mathop{argmin}\limits_{\hat{w}}(y-X\hat{w})^T(y-X\hat{w})$ | 向量形式的最小二乘法参数估计        | $\hat{w}=(w;b)$                                              |



## Toc

### <span id = "chapter 1" > ▢ </span>第1章 绪论  
[标记(label)](#concept 1-0)  
[假设(hypothesis)](#concept 1-1)  
[示例(instance)](#concept 1-2)  
[属性(attribute)](#concept 1-3)  
[属性空间(attribute space)](#concept 1-4)  
[数据集(data set)](#concept 1-5)  
[特征(feature)](#concept 1-6)  
[学习(learning)](#concept 1-7)  
[学习器(learner)](#concept 1-8)  
[训练(training)](#concept 1-9)  
[训练集(training data)](#concept 1-10)  
[训练样本(training sample)](#concept 1-11)  
[样本(sample)](#concept 1-12)  
[样本空间(sample space)](#concept 1-13)  
[样例(sample)](#concept 1-14)  
[真相(ground-truth)](#concept 1-15)  
[标记空间(label space)](#concept 1-16)  
[测试(testing)](#concept 1-17)  
[测试样本(testing sample)](#concept 1-18)  
[簇(cluster)](#concept 1-19)  
[独立同分布(independent and identically distributed)](#concept 1-20)  
[多分类(multi-class classification)](#concept 1-21)  
[二分类(binary classification)](#concept 1-22)  
[泛化(generalization)](#concept 1-23)  
[分类(classification)](#concept 1-24)  
[回归(regression)](#concept 1-25)  
[监督学习(supervised learning)](#concept 1-26)  
[聚类(clustering)](#concept 1-27)  
[无导师学习](#concept 1-28)  
[无监督学习(unsupervised learning)](#concept 1-29)  
[有导师学习](#concept 1-30)  
[概念学习(concept learning)](#concept 1-31)  
[归纳学习(inductive learning)](#concept 1-32)  
[版本空间(version space)](#concept 1-33)  
[归纳偏好(inductive bias)](#concept 1-34)  
[偏好](#concept 1-35)  
[奥卡姆剃刀(Occam's razor)](#concept 1-36)  
[符号主义(symbolism)](#concept 1-37)  
[连接主义(connectionism)](#concept 1-38)  
[人工智能](#concept 1-39)  
[机械学习](#concept 1-40)  
[类比学习](#concept 1-41)  
[示教学习](#concept 1-42)  
[统计学习](#concept 1-43)  
[数据挖掘](#concept 1-44)  
[WEKA](#concept 1-45)  
[迁移学习](#concept 1-46)  
### <span id = "chapter 2" > ▢ </span>第2章 模型评估与选择  
[错误率(error rate)](#concept 2-0)  
[泛化误差(generalization error)](#concept 2-1)  
[过拟合(overfitting)](#concept 2-2)  
[过配](#concept 2-3)  
[精度(accuracy)](#concept 2-4)  
[经验误差(empirical error)](#concept 2-5)  
[欠配(underfitting)](#concept 2-6)  
[误差(error)](#concept 2-7)  
[训练误差(trainning error)](#concept 2-8)  
[模型选择(model selection)](#concept 2-9)  
[分层采样(stratified sampling)](#concept 2-10)  
[留出法(hold-out)](#concept 2-11)  
[k折交叉验证(k-fold cross validation)](#concept 2-12)  
[交叉验证法(cross validation)](#concept 2-13)  
[包外估计(out of bag estimate)](#concept 2-14)  
[自助法(bootstrapping)](#concept 2-15)  
[参数调节(parameter tuning)](#concept 2-16)  
[验证集(validation set)](#concept 2-17)  
[均方误差(mean squared error)](#concept 2-18)  
[查全率(recall)](#concept 2-19)  
[查准率(precision)](#concept 2-20)  
[混淆矩阵(confusion matrix)](#concept 2-21)  
[召回率](#concept 2-22)  
[准确率](#concept 2-23)  
[P-R曲线](#concept 2-24)  
[平衡点(break-even point,bep)](#concept 2-25)  
[F1](#concept 2-26)  
[宏F1(macro-F1)](#concept 2-27)  
[宏查全率](#concept 2-28)  
[宏查准率](#concept 2-29)  
[微F1($\text{micro-}F1$)](#concept 2-30)  
[微查准率](#concept 2-31)  
[微查全率](#concept 2-32)  
[ROC曲线](#concept 2-33)  
[代价(cost)](#concept 2-34)  
[代价矩阵](#concept 2-35)  
[代价敏感(cost-sensitive)](#concept 2-36)  
[代价曲线](#concept 2-37)  
[规范化(normalization)](#concept 2-38)  
[归一化(regular)](#concept 2-39)  
[总体代价](#concept 2-40)  
[假设检验(hypothesis test)](#concept 2-41)  
[二项检验(binomial test)](#concept 2-42)  
[置信度(confidence)](#concept 2-43)  
[交叉验证成对t校验(paired t-tests)](#concept 2-44)  
[5x2交叉验证](#concept 2-45)  
[McNemar检验](#concept 2-46)  
[列联表](#concept 2-47)  
[Friedman检验](#concept 2-48)  
[Nemenyi后续检验(Nemenyi post-hoc test)](#concept 2-49)  
[偏差-方差分解](#concept 2-50)  

### <span id = "chapter 3" > ▢ </span>第3章 线性模型  
[线性回归(linear regression)](#concept 3-0)  
[线性模型(linear model)](#concept 3-1)  
[参数学习](#concept 3-2)  
[平方损失](#concept 3-3)  
[最小二乘法(least square method)](#concept 3-4)  
[多元线性回归(multivariate linear regression)](#concept 3-5)  
[对数线性回归(log-linear regression)](#concept 3-6)  
[正则化(regularization)](#concept 3-7)  
[对数几率回归(log-linear regression)](#concept 3-8)  
[广义线性模型(generalized linear model)](#concept 3-9)  
[阶跃函数(unit-step function)](#concept 3-10)  
[联系函数(link function)](#concept 3-11)  
[Sigmoid函数](#concept 3-12)  
[对率函数](#concept 3-13)  
[对率回归(logistic regression)](#concept 3-14)  
[对数几率函数(logistic function)](#concept 3-15)  
[几率(odds)](#concept 3-16)  
[替代函数(surrogate function)](#concept 3-17)  
[对数似然(log-likelihood)](#concept 3-18)  
[极大似然法(maximum likelihood method)](#concept 3-19)  
[Fisher判别分析(Fisher  Discriminant Analysis)](#concept 3-20)  
[线性判别分析(Linear Discriminant Analysis)](#concept 3-21)  
[广义瑞利商(generalized Rayleigh quotient)](#concept 3-22)  
[类间散度矩阵(within-class scatter matrix)](#concept 3-23)  
[类内散度矩阵(between-class scatter matrix)](#concept 3-24)  
[全局散度矩阵(global scatter matrix)](#concept 3-25)  
[MvM(Many vs. Many)](#concept 3-26)  
[OVO(one vs. one)](#concept 3-27)  
[OvR(one vs. Rest)](#concept 3-28)  
[多分类器学习](#concept 3-29)  
[纠错输出码(Error Correcting Output Codes,ECOC)](#concept 3-30)  
[编码矩阵(coding Matrix)](#concept 3-31)  
[类别不平衡(class-imbalance)](#concept 3-32)  
[过采样(oversampling)](#concept 3-33)  
[欠采样(undersampling)](#concept 3-34)  
[上采样(upsampling)](#concept 3-35)  
[稀疏表示(sparse representation)](#concept 3-36)  
[稀疏性(sparsity)](#concept 3-37)  
[下采样(downsampling)](#concept 3-38)  
[阈值移动(threshold-moving)](#concept 3-39)  
[再平衡(rebalance)](#concept 3-40)  
[再缩放(rescaling)](#concept 3-41)  
[多标记学习(multi-label learning)](#concept 3-42)  

### <span id = "chapter 4" > ▢ </span>第4章 决策树  
[决策树(decision tree)](#concept 4-0)  
[判定树](#concept 4-1)  
[分而治之(divide-and-conquer)](#concept 4-2)  
[ID3决策树(Iterative Dichotomiser decision tree)](#concept 4-3)  
[划分选择](#concept 4-4)  
[信息增益(information gain)](#concept 4-5)  
[增益率(gain ratio)](#concept 4-6)  
[C4.5决策树](#concept 4-7)  
[CART决策树(Classfication and Regression Tree)](#concept 4-8)  
[后剪枝(postpruning)](#concept 4-9)  
[基尼指数(Gini index)](#concept 4-10)  
[剪枝(pruning)](#concept 4-11)  
[预剪枝(prepruning)](#concept 4-12)  
[决策树桩(decison stump)](#concept 4-13)  
[离散化](#concept 4-14)  
[缺失值](#concept 4-15)  
[多变量决策树(multivariate decision tree)](#concept 4-16)  
[斜决策树(oblique descision tree)](#concept 4-17)  
[增量学习(incremental learning)](#concept 4-18)  

### <span id = "chapter 5" > ▢ </span>第5章 神经网络  
[M-P神经元模型](#concept 5-0)  
[人工神经网络](#concept 5-1)  
[神经网络(neural networks)](#concept 5-2)  
[神经元(neuron)](#concept 5-3)  
[阈值(bias/threshold)](#concept 5-4)  
[感知机(perceptron)](#concept 5-5)  
[激活函数(activation function)](#concept 5-6)  
[挤压函数(squashing function)](#concept 5-7)  
[阈值逻辑单元(threshold logic unit)](#concept 5-8)  
[非线性可分(linearly unseparable)](#concept 5-9)  
[功能神经元(functional neuron)](#concept 5-10)  
[收敛(converge)](#concept 5-11)  
[线性超平面(linear meta-surface)](#concept 5-12)  
[线性可分(linearly seprarable)](#concept 5-13)  
[学习率(learning rate)](#concept 5-14)  
[哑结点(dummy node)](#concept 5-15)  
[振荡(fluctuation)](#concept 5-16)  
[多层前馈神经网络(multi-layer feedforward neural network)](#concept 5-17)  
[BP算法(BackPropagation algorithm)](#concept 5-18)  
[BP网络](#concept 5-19)  
[单隐层网络](#concept 5-20)  
[反向传播算法](#concept 5-21)  
[连接权(connection weight)](#concept 5-22)  
[误差逆传播(error BackPropagaton)](#concept 5-23)  
[梯度下降](#concept 5-24)  
[链式法则](#concept 5-25)  
[累积误差逆传播(accumulated eror backpropagation)](#concept 5-26)  
[早停(early stopping)](#concept 5-27)  
[正则化(regularization)](#concept 5-28)  
[参数空间(parameter space)](#concept 5-29)  
[局部极小](#concept 5-30)  
[全局最小](#concept 5-31)  
[模拟退火(simulated annealing)](#concept 5-32)  
[遗传算法(genetic algorithms)](#concept 5-33)  
[ART网络(Adaptive Resonance Theory network)](#concept 5-34)  
[RBF网络(Radial Basis Function network)](#concept 5-35)  
[径向基函数(Radial Basis Function)](#concept 5-36)  
[竞争型学习(competitive learning)](#concept 5-37)  
[胜者通吃(winner-take-all)](#concept 5-38)  
[自适应谐振理论(Adaptive Resonance Theory)](#concept 5-39)  
[Kohonen网络](#concept 5-40)  
[SOM网络(Self-Organizing Map network)](#concept 5-41)  
[可塑性-稳定性窘境(stability-plasticity dilemma)](#concept 5-42)  
[在线学习(online learning)](#concept 5-43)  
[自组织映射(Self-Organizing Map)](#concept 5-44)  
[级联相关(Cascade-Correlation)](#concept 5-45)  
[Boltzmann分布(Boltzmann distribution)](#concept 5-46)  
[Boltzmann机(Boltzmann machine)](#concept 5-47)  
[Elman网络(Elman Network)](#concept 5-48)  
[递归神经网络(Recurrent neural networks)](#concept 5-49)  
[基于能量的模型(energy-based model)](#concept 5-50)  
[对比散度(Constrastive Divergence)](#concept 5-51)  
[受限Boltzmann机(Restricted Boltzmann Machine, RBM)](#concept 5-52)  
[发散(diverge)](#concept 5-53)  
[卷积神经网络(Convoutional Neural Network,CNN)](#concept 5-54)  
[权共享(weight sharing)](#concept 5-55)  
[深度学习(deep learning)](#concept 5-56)  
[无监督逐层训练(unsupervised layer-wise training)](#concept 5-57)  
[ReLU(Rectified Linear Unit)](#concept 5-58)  
[表示学习(Representation learning)](#concept 5-59)  
[汇合(pooling)](#concept 5-60)  
[特征学习(feature learning)](#concept 5-61)  
[广义δ规则](#concept 5-62)  
[可解释性](#concept 5-63)  
### <span id = "chapter 6" > ▢ </span>第6章 支持向量机  
[划分超平面](#concept 6-0)  
[支持向量](#concept 6-1)  
[间隔](#concept 6-2)  
[SVM](#concept 6-3)  
[对偶问题(dual problem)](#concept 6-4)  
[KKT条件(Karush-Kuhn-Tucker)](#concept 6-5)  
[核函数](#concept 6-6)  
[核技巧(kernel trick)](#concept 6-7)  
[支持向量展式](#concept 6-8)  
[核矩阵](#concept 6-9)  
[RKHS](#concept 6-10)  
[高斯核](#concept 6-11)  
[线性核](#concept 6-12)  
[软间隔](#concept 6-13)  
[硬间隔](#concept 6-14)  
[0/1损失函数](#concept 6-15)  
[替代损失](#concept 6-16)  
[hinge损失](#concept 6-17)  
[指数损失](#concept 6-18)  
[对率损失](#concept 6-19)  
[松弛变量](#concept 6-20)  
[软间隔支持向量机](#concept 6-21)  
[结构风险](#concept 6-22)  
[经验风险](#concept 6-23)  
[罚函数法](#concept 6-24)  
[支持向量回归](#concept 6-25)  
[核方法](#concept 6-26)  
[Mercer定理](#concept 6-27)  
[表示定理](#concept 6-28)  
[核化](#concept 6-29)  
[核线性判别分析](#concept 6-30)  
[割平面法](#concept 6-31)  
[多核学习](#concept 6-32)  
[一致性](#concept 6-33)  
### <span id = "chapter 7" > ▢ </span>第7章 贝叶斯分类器  
[贝叶斯风险(Bayes risk)](#concept 7-0)  
[贝叶斯最优分类器(Bayes optimal classifier)](#concept 7-1)  
[风险(risk)](#concept 7-2)  
[条件风险(conditional risk)](#concept 7-3)  
[贝叶斯定理](#concept 7-4)  
[判别式模型(discriminative models)](#concept 7-5)  
[生成式模型(generative models)](#concept 7-6)  
[似然(likelihood)](#concept 7-7)  
[先验(Prior)](#concept 7-8)  
[证据(evidence)](#concept 7-9)  
[极大似然估计(maximum likelihood estimation, MLE)](#concept 7-10)  
[朴素贝叶斯分类器(naive bayes classifier)](#concept 7-11)  
[条件独立性假设](#concept 7-12)  
[拉普拉斯修正(Laplacian correction)](#concept 7-13)  
[半监督贝叶斯分类器(semi-naive Bayes classifiers)](#concept 7-14)  
[独依赖估计(One-Dependent Estimator)](#concept 7-15)  
[懒惰学习(lazy learning)](#concept 7-16)  
[超父(super-parent)](#concept 7-17)  
[贝叶斯网(Bayesian network)](#concept 7-18)  
[概率图模型](#concept 7-19)  
[信念网(belief network)](#concept 7-20)  
[V型结构(V-structure)](#concept 7-21)  
[边际独立性(marginal independence)](#concept 7-22)  
[边际化(marginalization)](#concept 7-23)  
[道德图(moral graph)](#concept 7-24)  
[端正图](#concept 7-25)  
[有向分离(D-seperation)](#concept 7-26)  
[最小描述长度(Minimal Description Length)](#concept 7-27)  
[吉布斯采样](#concept 7-28)  
[近似推断](#concept 7-29)  
[精确推断](#concept 7-30)  
[马尔科夫链(Markov chain)](#concept 7-31)  
[平稳分布(stationary distribution)](#concept 7-32)  
[EM算法(Expectation-Maximization Algorithm)](#concept 7-33)  
[隐变量(latent variable)](#concept 7-34)  
[边际似然(marginal likehood)](#concept 7-35)  
[坐标下降(coordinate descent)](#concept 7-36)  
[贝叶斯分类器(Bayes Classifier)](#concept 7-37)  
[贝叶斯学习(Bayes learning)](#concept 7-38)  
### <span id = "chapter 8" > ▢ </span>第8章 集成学习  
[多分类器系统(multi-classifier system)](#concept 8-0)  
[个体学习器(individual learner)](#concept 8-1)  
[基学习器(base learner)](#concept 8-2)  
[基学习算法(base learning algorithm)](#concept 8-3)  
[集成学习(ensemble learning)](#concept 8-4)  
[弱学习器(weak learner)](#concept 8-5)  
[AdaBoost](#concept 8-6)  
[多样性(diversity)](#concept 8-7)  
[投票法(voting)](#concept 8-8)  
[Boosting](#concept 8-9)  
[加性模型](#concept 8-10)  
[重采样(re-sampling)](#concept 8-11)  
[重赋权(re-weighting)](#concept 8-12)  
[Bagging(Boostrap AGGregatING)](#concept 8-13)  
[自助采样法(Boostrap sampling)](#concept 8-14)  
[随机森林(Random Forest,RF)](#concept 8-15)  
[加权平均(weighted averaging)](#concept 8-16)  
[简单平均(simple averaging)](#concept 8-17)  
[绝对多数投票(majority voting) ](#concept 8-18)  
[加权投票(weighted voting)](#concept 8-19)  
[相对多数投票(plurality votiing)](#concept 8-20)  
[Stacking](#concept 8-21)  
[贝叶斯模型平均(Bayes Model Averaging)](#concept 8-22)  
[分歧(ambiguity)](#concept 8-23)  
[误差-分歧分解(error-ambiguity decomposition)](#concept 8-24)  
[差异性度量](#concept 8-25)  
[多样性度量(diversity measure)](#concept 8-26)  
[属性子集](#concept 8-27)  
[随机子空间(random subspace)](#concept 8-28)  
[稳定基学习器(stable base learner)](#concept 8-29)  
[子空间(subspace)](#concept 8-30)  
[集成修剪(ensemble pruning)](#concept 8-31)  
[选择性集成(selective emsemble)](#concept 8-32)  
### <span id = "chapter 9" > ▢ </span>第9章 聚类  
[有效性指标](#concept 9-0)  
[距离度量](#concept 9-1)  
[街区距离](#concept 9-2)  
[离散属性](#concept 9-3)  
[连续属性](#concept 9-4)  
[列名属性](#concept 9-5)  
[曼哈顿距离](#concept 9-6)  
[闵可夫斯基距离](#concept 9-7)  
[欧氏距离](#concept 9-8)  
[切比雪夫距离](#concept 9-9)  
[数值属性](#concept 9-10)  
[无序属性](#concept 9-11)  
[有序属性](#concept 9-12)  
[非度量距离](#concept 9-13)  
[混合属性](#concept 9-14)  
[加权距离](#concept 9-15)  
[相似度度量](#concept 9-16)  
[距离度量学习](#concept 9-17)  
[原型聚类](#concept 9-18)  
[k均值算法](#concept 9-19)  
[学习向量化(Learning Vector Quantization, LVQ)](#concept 9-20)  
[概率模型](#concept 9-21)  
[高斯混合](#concept 9-22)  
[密度聚类](#concept 9-23)  
[层次聚类](#concept 9-24)  
[聚类集成](#concept 9-25)  
[异常检测](#concept 9-26)  
[豪斯多夫距离](#concept 9-27)  
### <span id = "chapter 10" > ▢ </span>第10章 降维与度量学习  
[k近邻](#concept 10-0)  
[急切学习](#concept 10-1)  
[平均法](#concept 10-2)  
[最近邻分类器](#concept 10-3)  
[密采样](#concept 10-4)  
[多维缩放](#concept 10-5)  
[降维](#concept 10-6)  
[维数约简](#concept 10-7)  
[维数灾难](#concept 10-8)  
[PCA](#concept 10-9)  
[线性降维](#concept 10-10)  
[主成分分析](#concept 10-11)  
[奇异值分解](#concept 10-12)  
[本真低维空间](#concept 10-13)  
[非线性降维](#concept 10-14)  
[核化线性降维](#concept 10-15)  
[核主成分分析](#concept 10-16)  
[本真距离](#concept 10-17)  
[测地线距离](#concept 10-18)  
[等度量映射](#concept 10-19)  
[流形学习](#concept 10-20)  
[局部线性嵌入](#concept 10-21)  
[度量学习](#concept 10-22)  
[近邻成分分析](#concept 10-23)  
[必连约束](#concept 10-24)  
[勿连约束](#concept 10-25)  
[半监督聚类](#concept 10-26)  
[多视图学习](#concept 10-27)  
[流形假设](#concept 10-28)  
[流形正则化](#concept 10-29)  

### <span id = "chapter 11" > ▢ </span>第11章 特征选择与稀疏学习  
[冗余特征(redundant feature)](#concept 11-0)  
[数据预处理(data preprocessing)](#concept 11-1)  
[特征选择 & 相关特征(feature selection & relevant feature)](#concept 11-2)  
[相关特征(relevant feature)](#concept 11-3)  
[子集搜索(subset search)](#concept 11-4)  
[子集评价(subset evaluation)](#concept 11-5)  
[过滤式(filter)特征选择](#concept 11-6)  
[包裹式(wrapper)特征选择](#concept 11-7)  
[拉斯维加斯方法(Las Vegas method)](#concept 11-8)  
[蒙特卡洛方法(Monte Carlo method)](#concept 11-9)  
[LASSO](#concept 11-10)  
[Tikhonov 正则化(L2 正则化)](#concept 11-11)  
[岭回归(ridge regression)](#concept 11-12)  
[嵌入式(embedding)特征选择](#concept 11-13)  
[L1 正则化](#concept 11-14)  
[L2正则化](#concept 11-15)  
[Lipschitz 条件](#concept 11-16)  
[近端梯度下降(Proximal Gradient Descent)](#concept 11-17)  
[码书学习 & 字典学习(codebook & dictionary learning)](#concept 11-18)  
[稀疏编码(sparse coding)](#concept 11-19)  
[字典学习(dictionary learning)](#concept 11-20)  
[压缩感知(compressed sensing)](#concept 11-21)  
[局部线性嵌入(Locally Linear Embedding) ](#concept 11-22)  
[协同过滤(collaborative filtering)](#concept 11-23)  
[核范数 & 迹范数(nuclear norm & trace norm)](#concept 11-24)  
[迹范数(trace norm)](#concept 11-25)  
### <span id = "chapter 12" > ▢ </span>第12章 计算学习理论  
[计算学习理论(computational learning theory)](#concept 12-0)  
[Jensen不等式](#concept 12-1)  
[Hoeffding不等式](#concept 12-2)  
[McDiarmid 不等式](#concept 12-3)  
[概率近似正确](#concept 12-4)  
[概念类(concept class)](#concept 12-5)  
[假设空间(hypothesis space)](#concept 12-6)  
[PAC辨识(PAC Identify)](#concept 12-7)  
[PAC可学习(PAC Learnable)](#concept 12-8)  
[PAC学习算法(PAC Learning Algorithm)](#concept 12-9)  
[时间复杂度](#concept 12-10)  
[样本复杂度](#concept 12-11)  
[不可分(non-seperable)](#concept 12-12)  
[不一致(non-consistent)](#concept 12-13)  
[可分(seperable)](#concept 12-14)  
[恰PAC可学习(properly PAC learnable)](#concept 12-15)  
[有限假设空间](#concept 12-16)  
[不可知PAC可学习(agnostic PAC learnable)](#concept 12-17)  
[增长函数](#concept 12-18)  
[对分](#concept 12-19)  
[打散](#concept 12-20)  
[VC维](#concept 12-21)  
[经验风险最小化(Empirical Risk Minimization, ERM)](#concept 12-22)  
[Rademacher复杂度](#concept 12-23)  
[稳定性](#concept 12-24)  
[均匀稳定性](#concept 12-25)  
### <span id = "chapter 13" > ▢ </span>第13章 半监督学习  
[半监督学习(semi-supervised learning)](#concept 13-0)  
[查询(query)](#concept 13-1)  
[未标记样本(unlabeled sample)](#concept 13-2)  
[有标记样本(labeled sample)](#concept 13-3)  
[主动学习(active learning)](#concept 13-4)  
[聚类假设(cluster assumption)](#concept 13-5)  
[直推学习(transductive learning)](#concept 13-6)  
[S3VM(Semi-Supervised Support Vector Machine)](#concept 13-7)  
[半监督SVM](#concept 13-8)  
[图半监督学习](#concept 13-9)  
[亲和矩阵(affinity matrix)](#concept 13-10)  
[标记传播(label propagation)](#concept 13-11)  
[基于分歧的方法](#concept 13-12)  
[协同训练(co-training)](#concept 13-13)  
### <span id = "chapter 14" > ▢ </span>第14章 概率图模型(probabilistic model)  
[马尔科夫网(Markov network)](#concept 14-0)  
[推断](#concept 14-1)  
[隐马尔科夫模型(Hidden Markov Model)](#concept 14-2)  
[马尔科夫随机场(Markov Random Field)](#concept 14-3)  
[势函数(potential functions)](#concept 14-4)  
[因子(factor)](#concept 14-5)  
[全局马尔科夫性(global Markov property)](#concept 14-6)  
[局部马尔科夫性(local Markov property)](#concept 14-7)  
[成对马尔科夫性(pairwise Markov property)](#concept 14-8)  
[马尔科夫毯(Markov blanket)](#concept 14-9)  
[条件随机场(Conditional Random Field)](#concept 14-10)  
[链式条件随机场(chain-structured CRF)](#concept 14-11)  
[边际分布(marginal distribution)](#concept 14-12)  
[变量消去](#concept 14-13)  
[信念传播(Belief Propagation)](#concept 14-14)  
[MCMC(Markov Chain Monte Carlo)](#concept 14-15)  
[MH 算法(Metropolis-Hastings)](#concept 14-16)  
[变分推断(variational inference)](#concept 14-17)  
[盘式记法(plate notation)](#concept 14-18)  
[KL 散度(Kullback-Leibler divergence)](#concept 14-19)  
[平均场(mean field)](#concept 14-20)  
[话题模型(topic model)](#concept 14-21)  
[隐狄利克雷分配模型(Latent Dirichlet Allocation)](#concept 14-22)  
[非参数化(non-parametric)法](#concept 14-23)  
### <span id = "chapter 15" > ▢ </span>第15章 规则学习  
[规则(rule)](#concept 15-0)  
[规则学习(rule learning)](#concept 15-1)  
[逻辑文字(literal)](#concept 15-2)  
[冲突消解(conflict resolution)](#concept 15-3)  
[带序规则(ordered rule)](#concept 15-4)  
[优先级规则(priority rule)](#concept 15-5)  
[元规则(meta-rule)](#concept 15-6)  
[默认规则(default rule)](#concept 15-7)  
[缺省规则](#concept 15-8)  
[命题规则(propositional rule)](#concept 15-9)  
[原子命题](#concept 15-10)  
[一阶规则](#concept 15-11)  
[序贯覆盖(sequential covering)](#concept 15-12)  
[特化(specialization)](#concept 15-13)  
[泛化(generalization)](#concept 15-14)  
[似然率(Likelihood Ratio Statistics,LRS)](#concept 15-15)  
[RIPPER(Repeated Incremental Pruning to Produce Error Reduction)](#concept 15-16)  
[ILP(Inductive Logic Programming,归纳逻辑程序设计)](#concept 15-17)  
[归纳逻辑程序设计](#concept 15-18)  
[最小一般泛化(Least General Generalization)](#concept 15-19)  
[归纳(induction)](#concept 15-20)  
[逆归结](#concept 15-21)  
[演绎(deduction)](#concept 15-22)  
[置换(substitution)](#concept 15-23)  
[合一(unification)](#concept 15-24)  
[最一般合一置换(most general unifer,简称 MGU)](#concept 15-25)  
[归结商(resolution quotient)](#concept 15-26)  
[关系学习](#concept 15-27)  
[统计关系学习(statistical relational learning)](#concept 15-28)  
### <span id = "chapter 16" > ▢ </span>第16章 强化学习(reinforcement learning)  
[MDP](#concept 16-0)  
[奖赏(reward)](#concept 16-1)  
[马尔科夫决策过程(Markov Decision Process)](#concept 16-2)  
[强化学习(reinforcement learning)](#concept 16-3)  
[再励学习](#concept 16-4)  
[策略(policy)](#concept 16-5)  
[K-摇臂赌博机(K-armed bandit)](#concept 16-6)  
[ϵ-贪心](#concept 16-7)  
[探索-利用窘境(Exploration-Exploitation dilemma)](#concept 16-8)  
[Softmax](#concept 16-9)  
[有模型学习(model-based learning)](#concept 16-10)  
[状态-动作值函数(state-action value function)](#concept 16-11)  
[状态值函数(state value function)](#concept 16-12)  
[Bellman 等式](#concept 16-13)  
[策略迭代(policy iteration)](#concept 16-14)  
[值迭代(value iteration)](#concept 16-15)  
[免模型学习(model-free learning)](#concept 16-16)  
[TD(Temporal Difference) 学习](#concept 16-17)  
[时序差分学习](#concept 16-18)  
[Sarsa 算法](#concept 16-19)  
[Q-学习(Q-learning)](#concept 16-20)  
[表格值函数(tabular value function)](#concept 16-21)  
[值函数近似(value function approximation)](#concept 16-22)  
[模仿学习(imitation learning)](#concept 16-23)  
[逆强化学习(inverse reinforcement learning)](#concept 16-24)  
[近似动态规划(approximate dynamic programming)](#concept 16-25)  
### <span id = "chapter 17" > ▢ </span>第-1章 附录  
[行列式(determinant)](#concept 17-0)  
[迹(trace)](#concept 17-1)  
[Frobenius 范数](#concept 17-2)  
[低秩矩阵近似问题](#concept 17-3)  
[奇异值分解(Singular Value Decomposition,简称 SVD)](#concept 17-4)  
[拉格朗日乘子法(Lagrange multipliers)](#concept 17-5)  
[对偶函数(dual function)](#concept 17-6)  
[二次规划(Quadratic Programming,简称 QP)](#concept 17-7)  
[半正定规划(Seme-Definite Programming,简称 SDP)](#concept 17-8)  
[伯努利分布(Bernoulli distribution)](#concept 17-9)  
[均匀分布(uniform distribution)](#concept 17-10)  
[多项分布(multinominal distribution)](#concept 17-11)  
[二项分布(binomial distribution)](#concept 17-12)  
[贝塔分布(Beta distribution)](#concept 17-13)  
[狄利克雷分布(Dirichlet distribution)](#concept 17-14)  
[高斯分布(Gaussian distribution)](#concept 17-15)  
[正态分布(normal distribution)](#concept 17-16)  
[共轭分布(conjugate distribution)](#concept 17-17)  
[相对熵(relative entropy)](#concept 17-18)  
[信息散度(information divergence)](#concept 17-19)  
[交叉熵(cross entropy)](#concept 17-20)  
[熵(entropy)](#concept 17-21)  

 ## 绪论

<span id = "concept 1-0" > ▲ </span>**[标记(label)(2)](#chapter 1)** : 示例结果的信息，例如“好瓜”，称为标记

<span id = "concept 1-1" > ▲ </span>**[假设(hypothesis)(2,269)](#chapter 1)** : 学得模型对应了数据的某种潜在的规律，因此亦称假设

<span id = "concept 1-2" > ▲ </span>**[示例(instance)(2)](#chapter 1)** : 数据集中的每条记录是关于某个事件或对象的描述，称为一个“示例”或“样本”

<span id = "concept 1-3" > ▲ </span>**[属性(attribute)(2)](#chapter 1)** : 反映事务或对象在某方面的表现或性质的事项，如“色泽”，称为属性或特征

<span id = "concept 1-4" > ▲ </span>**[属性空间(attribute space)(2)](#chapter 1)** : 属性长成的空间称为属性空间，样本空间，或输入空间

<span id = "concept 1-5" > ▲ </span>**[数据集(data set)(2)](#chapter 1)** : 数据记录的集合称为一个数据集

<span id = "concept 1-6" > ▲ </span>**[特征(feature)(2,247)](#chapter 1)** : 同属性

<span id = "concept 1-7" > ▲ </span>**[学习(learning)(2)](#chapter 1)** : 从数据中学得模型的过程称为学习或训练

<span id = "concept 1-8" > ▲ </span>**[学习器(learner)(2)](#chapter 1)** : 学习过程就是为了找出或逼近真相，有时将模型称作学习器

<span id = "concept 1-9" > ▲ </span>**[训练(training)(2)](#chapter 1)** : 同学习

<span id = "concept 1-10" > ▲ </span>**[训练集(training data)(2)](#chapter 1)** : 训练过程中使用的数据称为“训练集”，其中每个样本称为一个“训练样本”，训练样本组成的集合称为训练集

<span id = "concept 1-11" > ▲ </span>**[训练样本(training sample)(2)](#chapter 1)** : 见训练集

<span id = "concept 1-12" > ▲ </span>**[样本(sample)(2)](#chapter 1)** : 同示例

<span id = "concept 1-13" > ▲ </span>**[样本空间(sample space)(2)](#chapter 1)** : 同属性空间

<span id = "concept 1-14" > ▲ </span>**[样例(sample)(2)](#chapter 1)** : 同示例(instance)

<span id = "concept 1-15" > ▲ </span>**[真相(ground-truth)(2)](#chapter 1)** : 潜在规律本身称为真相或真实

<span id = "concept 1-16" > ▲ </span>**[标记空间(label space)(3)](#chapter 1)** : 所有标记的集合称为标记空间或输出空间

<span id = "concept 1-17" > ▲ </span>**[测试(testing)(3)](#chapter 1)** : 学得模型后，使用其进行预测的过程称为测试，被预测的样本称为测试样本

<span id = "concept 1-18" > ▲ </span>**[测试样本(testing sample)(3)](#chapter 1)** : 见测试

<span id = "concept 1-19" > ▲ </span>**[簇(cluster)(3,197)](#chapter 1)** : 将训练集中的西瓜分成若干组，称为聚类，每个组称为一个簇

<span id = "concept 1-20" > ▲ </span>**[独立同分布(independent and identically distributed)(3,267)](#chapter 1)** : 我们获得的每个样本都是独立的从一个分布上采样获得的，即“独立同分布”

<span id = "concept 1-21" > ▲ </span>**[多分类(multi-class classification)(3)](#chapter 1)** : 预测值涉及多个类别时，称为“多分类”

<span id = "concept 1-22" > ▲ </span>**[二分类(binary classification)(3)](#chapter 1)** : 预测值设计两个分类的任务

<span id = "concept 1-23" > ▲ </span>**[泛化(generalization)(3,121,350)](#chapter 1)** : 学得模型适用于新样本的能力，称为“泛化”能力

<span id = "concept 1-24" > ▲ </span>**[分类(classification)(3)](#chapter 1)** : 如果预测的是离散值，此类学习任务称为分类

<span id = "concept 1-25" > ▲ </span>**[回归(regression)(3)](#chapter 1)** : 如果预测的值是连续值，此类学习任务称为回归

<span id = "concept 1-26" > ▲ </span>**[监督学习(supervised learning)(3)](#chapter 1)** : 根据训练数据是否拥有标记信息，学习任务可以大致分为两大类：监督学习和无监督学习，分类和回归是前者的代表，聚类是后者的代表

<span id = "concept 1-27" > ▲ </span>**[聚类(clustering)(3,197)](#chapter 1)** : 见簇

<span id = "concept 1-28" > ▲ </span>**[无导师学习(3)](#chapter 1)** : 同无监督学习

<span id = "concept 1-29" > ▲ </span>**[无监督学习(unsupervised learning)(3,197)](#chapter 1)** : 见有监督学习

<span id = "concept 1-30" > ▲ </span>**[有导师学习(3)](#chapter 1)** : 同有监督学习

<span id = "concept 1-31" > ▲ </span>**[概念学习(concept learning)(4,17)](#chapter 1)** : 广义的归纳学习大体相当于从样例中学习，而狭义的归纳学习则要求从训练数据中学得概念，因此亦称为概念学习或概念形成

<span id = "concept 1-32" > ▲ </span>**[归纳学习(inductive learning)(4,11)](#chapter 1)** : 从样例中学习

<span id = "concept 1-33" > ▲ </span>**[版本空间(version space)(5)](#chapter 1)** : 存在着一个与训练集一致的假设集合，称之为“版本空间”

<span id = "concept 1-34" > ▲ </span>**[归纳偏好(inductive bias)(6)](#chapter 1)** : 机器学习算法在学习过程中对某种类型假设的偏好，称为归纳偏好

<span id = "concept 1-35" > ▲ </span>**[偏好(6)](#chapter 1)** : 同归纳偏好

<span id = "concept 1-36" > ▲ </span>**[奥卡姆剃刀(Occam's razor)(7,17)](#chapter 1)** : 若有多个假设与观察一致，则选最简单的那个

<span id = "concept 1-37" > ▲ </span>**[符号主义(symbolism)(10,363)](#chapter 1)** : 基于逻辑表示

<span id = "concept 1-38" > ▲ </span>**[连接主义(connectionism)(10)](#chapter 1)** : 基于神经网络

<span id = "concept 1-39" > ▲ </span>**[人工智能(10)](#chapter 1)** : 有很多种说法。。见仁见智

<span id = "concept 1-40" > ▲ </span>**[机械学习(11)](#chapter 1)** : 信息存储与检索

<span id = "concept 1-41" > ▲ </span>**[类比学习(11)](#chapter 1)** : 通过观察和发现学习

<span id = "concept 1-42" > ▲ </span>**[示教学习(11)](#chapter 1)** : 从指令中学习

<span id = "concept 1-43" > ▲ </span>**[统计学习(12,139)](#chapter 1)** : 如SVM，核方法

<span id = "concept 1-44" > ▲ </span>**[数据挖掘(14)](#chapter 1)** : 从海量数据中发掘知识

<span id = "concept 1-45" > ▲ </span>**[WEKA(16)](#chapter 1)** : 机器学习算法库 http://www.cs.waikato.ac.nz/ml/weka

<span id = "concept 1-46" > ▲ </span>**[迁移学习(17)](#chapter 1)** : 类比学习升级版


## 模型评估与选择

### 经验误差与过拟合

<span id = "concept 2-0" > ▲ </span>**[错误率(error rate)(23)](#chapter 2)** : 分类错误的样本数占样本总数的比例。


> 如果在m个样本中有a个样本分类错误，则错误率`E = a/m`；
> 相应的，`1-a/m`称为精度。
>
> 对于数据集D，错误率为$\large E(f;D) = \dfrac{1}{m}\sum\limits^m_{i=1}\mathbb{I}(f(x_i)\not=y_i)$
> 更一般的，$\large E(f;D) = \int_{x\sim D}\mathbb{I}(f(x)\not=y)p(x)dx$

<span id = "concept 2-1" > ▲ </span>**[泛化误差(generalization error)(23)](#chapter 2)** : 模型在新样本上的误差。

<span id = "concept 2-2" > ▲ </span>**[过拟合(overfitting)(23,104,191,352)](#chapter 2)** : 当学习器把训练样本学得太好了的时候，很可能已经把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质，这样就会导致泛化性能下降，这种现象称为过拟合

<span id = "concept 2-3" > ▲ </span>**[过配(23)](#chapter 2)** : 同过拟合

<span id = "concept 2-4" > ▲ </span>**[精度(accuracy)(23,29)](#chapter 2)** : 精度=1-错误率

<span id = "concept 2-5" > ▲ </span>**[经验误差(empirical error)(23,267)](#chapter 2)** : 学习器在训练集上的误差称为“训练误差”

<span id = "concept 2-6" > ▲ </span>**[欠配(underfitting)(23)](#chapter 2)** : 欠拟合，对训练样本的一般性质尚未学好

<span id = "concept 2-7" > ▲ </span>**[误差(error)(23)](#chapter 2)** : 学习器的实际预测输出与样本的真实输出之间的差异称为误差

<span id = "concept 2-8" > ▲ </span>**[训练误差(trainning error)(23)](#chapter 2)** : 同经验误差

<span id = "concept 2-9" > ▲ </span>**[模型选择(model selection)(24)](#chapter 2)** : 选择学习算法与参数配置

<span id = "concept 2-10" > ▲ </span>**[分层采样(stratified sampling)(25)](#chapter 2)** : 如果从采样的角度看待数据集的划分过程，则保留类别比例的采样方式通常称为“分层采样”

### 评估方法

<span id = "concept 2-11" > ▲ </span>**[留出法(hold-out)(25)](#chapter 2)** : 直接将数据集D划分为两个互斥的集合，其中一个集合作为训练集S，另一个作为测试集T，在S上训练出模型后，用T来评估其测试误差，作为对泛化误差的估计。

<span id = "concept 2-12" > ▲ </span>**[k折交叉验证(k-fold cross validation)(26)](#chapter 2)** : 交叉验证先将数据集D划分为k个大小相似的互斥子集，每个自己都尽可能保持数据分布的一致性，即从数据集中分层采样得到，然后，每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集，这样就可以获得k组训练/测试集，最终返回k个测试结果的均值，交叉验证评估结果的稳定性和保真性很大程度上取决于k的取值，通常称之为k折交叉验证，最常用的k是10

<span id = "concept 2-13" > ▲ </span>**[交叉验证法(cross validation)(26)](#chapter 2)** : 同k折交叉验证

<span id = "concept 2-14" > ▲ </span>**[包外估计(out of bag estimate)(27,179)](#chapter 2)** : 用于测试的样本没在训练集中出现，这样的测试结果称为包外估计

<span id = "concept 2-15" > ▲ </span>**[自助法(bootstrapping)(27)](#chapter 2)** : 以自主采样法（可重复采样法）为基础，给定包含m个样本的数据集D，对它采样产生数据集D’：每次随机从D中挑选一个样本，将其考本放入D’， 然后再将该样本放回D中，下次可能再被采到，这个过程执行m次后，得到包含m个样本的数据集D’,m足够大时，有36.8%的样本不会被采到，于是可以用没采到的部分做测试集。

<span id = "concept 2-16" > ▲ </span>**[参数调节(parameter tuning)(28)](#chapter 2)** : 大多数学习算法有些参数需要设定，参数配置不同，学得模型的性能往往有显著差别，因此，在进行模型评估与选择时，除了要对适用学习算法进行选择，还需要对算法参数进行设定，这就是参数调节或者调参。

<span id = "concept 2-17" > ▲ </span>**[验证集(validation set)(28,105)](#chapter 2)** : 通常把学得模型在实际使用中遇到的数据称为测试数据，为了加以区分，为了加以区分，模型评估与选择中用于评估测试的数据集常称为“验证集”。

### 性能度量（performance measure）

<span id = "concept 2-18" > ▲ </span>**[均方误差(mean squared error)(29,54)](#chapter 2)** : 回归任务最常用的性能度量是均方误差(几何距离)

$E(f;D) = \frac{1}{m}\sum\limits^m_{i=1}(f(x_i)-y_i)^2$,更一般的，对于数据分布$D$和概率密度函数`p(·)`，则$E(f;D) = \int_{x\sim D}(f(x)-y)^2p(x)dx$

<span id = "concept 2-19" > ▲ </span>**[查全率(recall)(30)](#chapter 2)** : 预测为真且正确的结果占所有预测正确的结果的比例。

> 查全率$R = \dfrac{TP}{TP+FN}$

<span id = "concept 2-20" > ▲ </span>**[查准率(precision)(30)](#chapter 2)** : 预测为真且正确的结果占所有预测结果的比例。

> 查准率$P = \dfrac{TP}{TP+FP}$

<span id = "concept 2-21" > ▲ </span>**[混淆矩阵(confusion matrix)(30)](#chapter 2)** : 如下表：

|真实情况|预测为正例|预测为反例|
| :-:| :-:  | :-:  |
|正例| TP(真正例)| FN(假反例)|
| 反例 | FP(假正例)| TN(真反例)|
<span id = "concept 2-22" > ▲ </span>**[召回率(30)](#chapter 2)** : 同查全率

<span id = "concept 2-23" > ▲ </span>**[准确率(30)](#chapter 2)** : 同查准率

<span id = "concept 2-24" > ▲ </span>**[P-R曲线(31)](#chapter 2)** : 查准率(纵轴)与查全率(横轴)的关系曲线。

> 学习器A、B的性能优于学习器C。曲线所围面积一定程度表示性能，更直观的度量标准为平衡点BEP。

![](https://raw.githubusercontent.com/DingSJ101/picgo_hub/main/img/20221118213716.png)

<span id = "concept 2-25" > ▲ </span>**[平衡点(break-even point,bep)(31)](#chapter 2)** : 查准率=查全率时的取值。平衡点大的学习模型可以认为综合性能更好

<span id = "concept 2-26" > ▲ </span>**[F1(32)](#chapter 2)** : 查准率和查全率的调和平均，比算术平均(求和除以2)和几何平均(平方相乘开方)更重视较小值。

>  $\large \frac{1}{F1} = \frac{1}{2} \cdot (\frac{1}{P} + \frac{1}{R}) $  ,  $\large F_1= \frac{2\times P \times R}{P+R}=\frac{2\times TP}{样例总数+TP-TN}$

> 考虑到查准率和查全率在不同应用中的权重不同，F1的加权调和平均形式为$\large \frac{1}{F_\beta} = \frac{1}{1+\beta^2} \cdot (\frac{1}{P} + \frac{\beta^2}{R})$  ,  $\large F_\beta = \dfrac{(1+\beta^2)\times P \times R}{\beta^2\times P +R}$，其中$\beta >0 度量了查全率对查准率的相对重要性，\beta=1退化为F1$

<span id = "concept 2-27" > ▲ </span>**[宏F1(macro-F1)(32)](#chapter 2)** : 如果进行多次训练/测试，每次得到一个混淆矩阵，或是在多个数据集上进行训练/测试，可以在n个混淆矩阵上综合考察查准率和查全率

>  $\large \text{macro-}P=\frac{1}{n}\sum_{i=1}^{n}P_i$

<span id = "concept 2-28" > ▲ </span>**[宏查全率(32)](#chapter 2)** : $\large \text{macro-}R=\frac{1}{n}\sum_{i=1}^{n}R_i$

<span id = "concept 2-29" > ▲ </span>**[宏查准率(32)](#chapter 2)** : $\large \text{macro-}F1=\frac{2\times\text{macro-}P\times\text{macro-}R}{\text{macro-}P+\text{macro-}R}$

<span id = "concept 2-30" > ▲ </span>**[微F1($\text{macro-}F1$)(32)](#chapter 2)** : 将各混淆矩阵的对应元素进行平均，再去计算

> $\large \text{micro-}F1=\frac{2\times\text{micro-}P\times\text{micro-}R}{\text{micro-}P+\text{micro-}R}$

<span id = "concept 2-31" > ▲ </span>**[微查准率(32)](#chapter 2)** : 将各混淆矩阵的对应元素进行平均，再去计算

> $micro-P = \dfrac{\overline{TP}}{\overline{TP}+\overline{FP}}$

<span id = "concept 2-32" > ▲ </span>**[微查全率(32)](#chapter 2)** : 将各混淆矩阵的对应元素进行平均，再去计算

> $micro-R = \dfrac{\overline{TP}}{\overline{TP}+\overline{FN}}$

<span id = "concept 2-33" > ▲ </span>**[ROC曲线(33,46)](#chapter 2)** : 真正例率(True Positive Rate，TPR)和假正例率(FPR)的关系曲线

> $TPR=\frac{TP}{TP+FN}$
>
> $FPR=\frac{FP}{TN+FP}$
>
> ![](https://raw.githubusercontent.com/DingSJ101/picgo_hub/main/img/20221118220359.png)

> AUC(Area Under ROC Curve)：公式略P35  TODO

<span id = "concept 2-34" > ▲ </span>**[代价(cost)(35,47)](#chapter 2)** : 为权衡不同类型错误所造成的不同损失，可为错误赋予“非均等代价”

<span id = "concept 2-35" > ▲ </span>**[代价矩阵(35)](#chapter 2)** : $cost_{ij}表示将第i类样本预测为第j类的惩罚$，对应的代价矩阵如下表：

|真实情况|预测为0类|预测为1类|
| :-:| :-:  | :-:  |
|0类| 0| $cost_{01}$ |
|1类| $cost_{10}$ |0|

<span id = "concept 2-36" > ▲ </span>**[代价敏感(cost-sensitive)(36,67)](#chapter 2)** : 在损失函数中考虑了非均等代价

<span id = "concept 2-37" > ▲ </span>**[代价曲线(cost curve)(36)](#chapter 2)** : 正例概率代价(横轴)和归一化代价(纵轴)的曲线，可以反映出学习器的期望总体代价。

> 正例概率代价： $P(+)cost = \frac{p\times cost_{01}}{p \times cost_{01} + (1 - p) \times cost_{10}}$，p是样例为正例的概率
>
> 归一化代价： $cost_{norm} = \frac{FNR \times p \times cost_{01} + FPR \times (1-p) \times cost_{10}}{(p \times cost_{01}+ (1-p) \times cost_{10}}$，假反例率FNR=1-FPR
>
> ![](https://raw.githubusercontent.com/DingSJ101/picgo_hub/main/img/20221118223133.png)

<span id = "concept 2-38" > ▲ </span>**[规范化(normalization)(36,183)](#chapter 2)** : 将不同变化范围的值映射到相同的固定范围中，常见的是[0,1]，此时亦称归一化

<span id = "concept 2-39" > ▲ </span>**[归一化(regular)(36)](#chapter 2)** : 同规范化

<span id = "concept 2-40" > ▲ </span>**[总体代价(36)](#chapter 2)** : 错误率是直接计算错误次数，并没有考虑不同错误会造成不同的后果，在非均等代价下，我们所希望的不再是简单的最小化错误次数，而是希望最小化总体代价

### 比较检验 TODO

<span id = "concept 2-41" > ▲ </span>**[假设检验(hypothesis test)(37)](#chapter 2)** : **假设**是对学习器泛化错误率分布的某种判断或猜想(如$\epsilon = \epsilon_0$)，用测试错误率$\hat\epsilon$估计泛化错误率，以检查学习器性能。 

<span id = "concept 2-42" > ▲ </span>**[二项检验(binomial test)(38)](#chapter 2)** : 二项分布检验，根据收集到的样本数据，推断总体分布是否服从某个指定的二项分布。泛化错误率为e的学习器被测得测试错误率为e’的概率是服从二项分布的。

<span id = "concept 2-43" > ▲ </span>**[置信度(confidence)(38)](#chapter 2)** : 估计总体参数落在某一区间时，可能不犯错误的概率，一般用符号1-α表示。

<span id = "concept 2-44" > ▲ </span>**[交叉验证成对t校验(paired t-tests)(40)](#chapter 2)** : 对两个学习器A和B，使用k折交叉验证法分别得到k个测试错误率，如果两个学习器性能相同，则使用相同训练/测试集时测试错误率应该相同，求两个学习器的k个测试错误率的差，若$\left | \frac{\sqrt{k}\mu}{\sigma}\right|$＜临界值则认为两个学习器性能相同。

<span id = "concept 2-45" > ▲ </span>**[5x2交叉验证(41)](#chapter 2)** : 由于交叉验证中，不同轮次的训练集之间有一定程度的重复，会过高估计假设成立的概率，因此做5次2折交叉验证，每次验证前将数据打乱，对5次2对2个学习器的测试错误率求差值，对所有差值求方差，对前两次差值求均值，再进行临界值判断。

<span id = "concept 2-46" > ▲ </span>**[McNemar检验(41)](#chapter 2)** : 两个学习器分类差别列联表


|算法B\A|正确|错误|
| :-:| :-:  | :-:  |
|正确| e00| e01|
|错误| e10|e11|

检验变量|e01-e10|是否服从正态分布，服从则认为两学习器性能相同等同于检查τx² = (|e01-e10|-1)²/(e01+e10) 是否服从自由度为1的卡方分布(标准正态分布变量的平方)

<span id = "concept 2-47" > ▲ </span>**[列联表(41,187)](#chapter 2)** : 见McNemar检验

<span id = "concept 2-48" > ▲ </span>**[Friedman检验(42)](#chapter 2)** : 有多个数据集多个学习器进行比较时使用，对各个算法在各个数据集上对测试性能排序，对平均序值计算τx²和τF,并进行临界值检验。

<span id = "concept 2-49" > ▲ </span>**[Nemenyi后续检验(Nemenyi post-hoc test)(43)](#chapter 2)** : 学习器性能性能显著不同时，进行后续检验来进一步区分各算法，临界值域：$CD=q\alpha \times \sqrt{\frac{k(k+1)}{6N}}$

### 偏差与方差

<span id = "concept 2-50" > ▲ </span>**[偏差-方差分解(44,177)](#chapter 2)** : 对学习算法的期望泛化错误率进行拆解。

学习算法在不同训练集上学得的结果很可能不同。定义：真实输出`y`与期望输出$\overline{f}(x)$的差别称为偏差(bias)，使用样本数相同的不同训练集产生的输出的方差为var(x)，噪声为$\epsilon^2$，则有：$E(f;D)=bias^2(x)+var(x)+\varepsilon^2$

![](https://raw.githubusercontent.com/DingSJ101/picgo_hub/main/img/20221119150840.png)

> $$
> \begin {cases}
> \large\overline{f}(x) &= &\mathbb{E}_D[f(x;D)]& 期望输出\\
> \large var(x) &= &\mathbb{E}_D[(f(x;d)-\overline{f}(x))^2]& 方差：训练集变化对模型性能的影响\\
> \epsilon^2 &= &\mathbb{E}_D[(y_D-y)^2]& 噪声：期望泛化误差的下界\\
> bias^2(x)&=&(\overline{f}(x)-y)^2 & 偏差：拟合能力\\
> \end{cases}
> $$
> 假设数据噪声期望为0，即$\mathbb{E}_D[(y_D-y)]=0$，则有
> $$
> \begin{array}{}
> E(f;D) 
> &=&\mathbb{E}_D[(f(x;D)-y_D)^2]\\
> &=&\mathbb{E}_D[(f(x;D)-\overline{f}(x)+\overline{f}(x)-y_D)^2]\\
> &=& \mathbb{E}_D[(f(x;D)-\overline{f}(x))^2]+\mathbb{E}_D[(\overline{f}(x)-y_D)^2]\\
> &&+2\mathbb{E}_D[(f(x;D)-\overline{f}(x))\times (\overline{f}(x)-y_D)]&\#最后一项展开化简为0\\
> &=& \mathbb{E}_D[(f(x;D)-\overline{f}(x))^2]+\mathbb{E}_D[(\overline{f}(x)-y+y-y_D)^2]\\
> &=& \mathbb{E}_D[(f(x;D)-\overline{f}(x))^2]+\mathbb{E}_D[(\overline{f}(x)-y)^2]+\mathbb{E}_D[(y-y_D)^2]\\
> &&+2\mathbb{E}_D[(\overline{f}(x)-y)\times (y-y_D)]& \# 最后一项展开化简为0\\
> &=& \mathbb{E}_D[(f(x;D)-\overline{f}(x))^2]+(\overline{f}(x)-y)^2+\mathbb{E}_D[(y-y_D)^2]\\
> &=& var(x)+bias^2(x)+\epsilon^2
> \end{array}
> $$
>
> 

​    

## 线性模型

### 线性回归

<span id = "concept 3-0" > ▲ </span>**[线性回归(linear regression)(53,252)](#chapter 3)** : 给定数据集$D=\{(x_i,y_i),\cdots,(x_m,y_m)\}$，其中$x_i = (x_{i1};\cdots;x_{id}),y_i\in\mathbb{R}$，线性回归试图学得一个线性模型以尽可能准确地预测实值输出标记

<span id = "concept 3-1" > ▲ </span>**[线性模型(linear model)(53)](#chapter 3)** : 给定由d个属性描述的示例$x=(x_ 1;x_ 2;...;x_d)$，xi是x在第i个属性上的取值，线性模型试图学得一个通过属性的线性组合来进行预测的函数，即

$f(x) = w_1x_1+w_2x_2+...+w_dx_d+b$

<span id = "concept 3-2" > ▲ </span>**[参数学习(54)](#chapter 3)** : 线性回归试图学得$f(x_i) = wx_i + b,x_i\in\mathbb{R}$, 使得$f(x_i)\simeq y_i$

<span id = "concept 3-3" > ▲ </span>**[平方损失(54)](#chapter 3)** : 欧氏距离算得的均方误差

<span id = "concept 3-4" > ▲ </span>**[最小二乘法(least square method)(54,72)](#chapter 3)** : 基于均方误差最小化来进行模型求解的方法称为最小二乘法

<span id = "concept 3-5" > ▲ </span>**[多元线性回归(multivariate linear regression)(55)](#chapter 3)** : 样本由多个属性描述的线性回归，即学习$f(x_i) = w^Tx_i + b,x_i\in\mathbb{R^d}$, 使得$f(x_i)\simeq y_i$

<span id = "concept 3-6" > ▲ </span>**[对数线性回归(log-linear regression)(56)](#chapter 3)** : 线性回归的一种变化(广义线性模型在$g(\cdot)=ln(\cdot)$的特例)，$lny=w^Tx+b$

<span id = "concept 3-7" > ▲ </span>**[正则化(regularization)(56,105,133)](#chapter 3)** : 往往可以解出多个w都能使均方误差最小化，选择哪一个解将由学习算法的归纳偏好决定，常见的做法是引入正则化项。

<span id = "concept 3-9" > ▲ </span>**[广义线性模型(generalized linear model)(57)](#chapter 3)** : 考虑单调可微函数$g(.)$，令 $y=g^{-1}(w^Tx+b)$，这样得到的模型称为广义线性模型，其中函数g称为联系函数。

<span id = "concept 3-11" > ▲ </span>**[联系函数(link function)(57)](#chapter 3)** : 见广义线性模型

### 对数几率回归

<span id = "concept 3-10" > ▲ </span>**[阶跃函数(unit-step function)(57,98)](#chapter 3)** : 考虑二分类任务，我们需要将实值z转为0/1值，最理想的是单位阶跃函数：
$$
y=\begin{cases}
0,&z<0\\
0.5,&z=0\\
1,&z>0
\end{cases}
$$

<span id = "concept 3-12" > ▲ </span>**[Sigmoid函数(58,98,102)](#chapter 3)** : 形似S的函数，对数几率函数时重要的代表

<span id = "concept 3-13" > ▲ </span>**[对率函数(58)](#chapter 3)** : 同对数几率函数

<span id = "concept 3-16" > ▲ </span>**[几率(odds)(58)](#chapter 3)** : 若将模型输出y视为样本x作为正例的可能性，则1-y是其反例可能性，两者的比值$\frac{y}{1-y}$称为几率

<span id = "concept 3-15" > ▲ </span>**[对数几率函数(logistic function)(58,98)](#chapter 3)** : $y=\dfrac{1}{1+e^{-z}}$

<span id = "concept 3-8" > ▲ </span>**[对数几率回归(log-linear regression)(57)](#chapter 3)** : 对于分类问题，需要找一个单调可微函数将数据和线性模型关联起来，由于单位阶跃函数不连续，所以采用近似单位阶跃函数且单调可微的连续函数对数几率函数替代。
$$
y=\dfrac{1}{1+e^{-z}} = \dfrac{1}{1+e^{-(w^Tx+b)}} \\
等价变形为 \ln \frac{y}{1-y} = w^Tx+b
$$
<span id = "concept 3-14" > ▲ </span>**[对率回归(logistic regression)(58,132,325)](#chapter 3)** :用线性回归模型的预测结果去逼近真实标记的对数几率($\ln \large\frac{y}{1-y}$)，得到的模型称为“对数几率回归”。 TODO(Page58,分布假设)：如何理解“对分类可能性建模……避免假设分布”

<span id = "concept 3-17" > ▲ </span>**[替代函数(surrogate function)(58)](#chapter 3)** : 功能相似的函数，例如用对数几率函数替代单位阶跃函数



<span id = "concept 3-19" > ▲ </span>**[极大似然法(maximum likelihood method)(59,149,297)](#chapter 3)** : 估计类条件概率的一种常用策略。先假定其具有某种确定的概率分布形式，再基于训练样本对概率分布的参数进行估计。

<span id = "concept 3-18" > ▲ </span>**[对数似然(log-likelihood)(59,149)](#chapter 3)** : $l(w,b) = \sum\limits_{i=1}^m(\ln p(y_i|x_i;w,b))$

> 对率回归模型最大化“对数似然”，即令每个样本属于其真实标记的概率越大越好 TODO(Page 59，对率极大似然估计)

### 线性判别分析 TODO(Page60,LDA)

<span id = "concept 3-21" > ▲ </span>**[线性判别分析(Linear Discriminant Analysis)(60,139)](#chapter 3)** : 给定训练样例集，设法将样例投影到一条直线上，使得同类样例的投影尽可能接近，异类样例的投影点尽可能远离，在对新样本进行分类时，将其投影到同样的这条直线上，再根据投影点的位置来确定样本的类别。![](https://raw.githubusercontent.com/DingSJ101/picgo_hub/main/img/20221120215658.png)

<span id = "concept 3-20" > ▲ </span>**[Fisher判别分析(Fisher  Discriminant Analysis)(60)](#chapter 3)** : 同线性判别分析



<span id = "concept 3-22" > ▲ </span>**[广义瑞利商(generalized Rayleigh quotient)(61)](#chapter 3)** : LDA欲最大化的目标，即Sb(类间散度矩阵)，Sw(类内散度矩阵)的广义瑞利商

<span id = "concept 3-23" > ▲ </span>**[类间散度矩阵(within-class scatter matrix)(61,138)](#chapter 3)** : 各类样本内部求差平方，再求和

<span id = "concept 3-24" > ▲ </span>**[类内散度矩阵(between-class scatter matrix)(61,138)](#chapter 3)** : 各类样本之间的均值之差的平方和

<span id = "concept 3-25" > ▲ </span>**[全局散度矩阵(global scatter matrix)(62)](#chapter 3)** : 样本与全局均值之差的平方和

### 多分类学习

<span id = "concept 3-26" > ▲ </span>**[MvM(Many vs. Many)(63)](#chapter 3)** : 多分类转二分类的一种解决方法：每次将若干个类作为正类，若干个其他类作为反类，通常用纠错输出码ECOC来拆分。

<span id = "concept 3-27" > ▲ </span>**[OVO(one vs. one)(63)](#chapter 3)** : 一对一，对于多个分类，两两配对产生N(N-1)/2个二分类任务![](https://raw.githubusercontent.com/DingSJ101/picgo_hub/main/img/20221120221833.png)

<span id = "concept 3-28" > ▲ </span>**[OvR(one vs. Rest)(63)](#chapter 3)** : 一对多，每次将一个类的样例作为正例，所有其他类的样例作为反例来训练N个分类器。

<span id = "concept 3-29" > ▲ </span>**[多分类器学习(63)](#chapter 3)** : 顾名思义。。

<span id = "concept 3-30" > ▲ </span>**[纠错输出码(Error Correcting Output Codes,ECOC)(64)](#chapter 3)** : 将编码思想引入类别拆分，分编码和解码两部：

- 编码：对N个分类器做M次划分，每次划分将一部分类别划为正类，其余为反类，一共产生M个二分类训练集，训练出M个分类器
- 解码：M个分类器分别对测试样本做预测，所有预测标记组成一个编码，将这个预测编码与每个类别各自的编码做比较，返回其中距离最小的类别作为最终预测结果。

<span id = "concept 3-31" > ▲ </span>**[编码矩阵(coding Matrix)(65)](#chapter 3)** : ECOC中，类别划分通过编码矩阵(编码组成的矩阵)指定。

### 类别不平衡问题

<span id = "concept 3-41" > ▲ </span>**[再缩放(rescaling)(67)](#chapter 3)** : 原本决策规则是y/(1-y)\>1预测为正，即预测为正的可能性大于预测为负的可能性，但正例少的时候，我们可以修改为，预测为正的可能性高于观测到的几率，即$y/(1-y) > m_+/m_-$

<span id = "concept 3-40" > ▲ </span>**[再平衡(rebalance)(67)](#chapter 3)** : 同再缩放

<span id = "concept 3-32" > ▲ </span>**[类别不平衡(class-imbalance)(66,209)](#chapter 3)** : 分类任务中不同类别的训练样例数目差别很大的情况，往往通过再缩放处理。


<span id = "concept 3-33" > ▲ </span>**[过采样(oversampling)(67)](#chapter 3)** : 对训练集里的某类样例增加采样次数减小类别不平衡。

<span id = "concept 3-34" > ▲ </span>**[欠采样(undersampling)(67)](#chapter 3)** : 对训练集里的某类样例减少采样次数减小类别不平衡。

<span id = "concept 3-35" > ▲ </span>**[上采样(upsampling)(67)](#chapter 3)** : 同过采样

<span id = "concept 3-38" > ▲ </span>**[下采样(downsampling)(67)](#chapter 3)** : 同欠采样

<span id = "concept 3-39" > ▲ </span>**[阈值移动(threshold-moving)(67)](#chapter 3)** : 欠采样和过采样改变了观测几率，在执行在缩放时，根据采样比例调整阈值。

<span id = "concept 3-36" > ▲ </span>**[稀疏表示(sparse representation)(67,255)](#chapter 3)** : 见11章。

<span id = "concept 3-37" > ▲ </span>**[稀疏性(sparsity)(67)](#chapter 3)** : 本质上对应L0范数的优化。

<span id = "concept 3-42" > ▲ </span>**[多标记学习(multi-label learning)(68)](#chapter 3)** : 例如一幅画可同时标注蓝天，白云，羊群等，每个样本属于多个类别，这就是多标记学习。

​    

## 决策树

### 基本流程

<span id = "concept 4-0" > ▲ </span>**[决策树(decision tree)(73,363)](#chapter 4)** : 以二分类任务为例，我们希望从给定训练数据集学得一个模型用以对新示例进行分类，这儿把样本分类的任务，可以看做为当前样本是否属于正类这个问题的决策或判定过程，决策树是基于树结构进行决策的，决策时通常会进行一系列判断或子决策，决策的过程形成一个树结构。

基本算法：![](https://raw.githubusercontent.com/DingSJ101/picgo_hub/main/img/20221121190300.png)

<span id = "concept 4-1" > ▲ </span>**[判定树(73)](#chapter 4)** : 同决策树

<span id = "concept 4-2" > ▲ </span>**[分而治之(divide-and-conquer)(74)](#chapter 4)** : 分解问题分别进行处理的策略。

### 划分选择

<span id = "concept 4-5" > ▲ </span>**[信息增益(information gain)(75)](#chapter 4)** : 属性划分所减少的信息熵。信息熵越小，D的纯度越高。

$Gain(D,a)=Ent(D)-\sum\limits_{v=1}^V\dfrac{D_v}{D}Ent(D^v))，D^v是某个属性a的某个可能取值的样本集合$

<span id = "concept 4-3" > ▲ </span>**[ID3决策树(Iterative Dichotomiser decision tree)(75)](#chapter 4)** : 以信息增益为准则来划分属性的迭代二分器决策树。

<span id = "concept 4-4" > ▲ </span>**[划分选择(75)](#chapter 4)** : 决策树学习算法最重要的地方就是选择最优划分属性。

<span id = "concept 4-6" > ▲ </span>**[增益率(gain ratio)(77)](#chapter 4)** : 信息增益准则对可取值数目较多的属性有偏好，为减少这种偏好的不利影响，使用增益率选择最优划分属性，增益率定义为:$Gain\_ratio(D,a)=\frac{Gain(D,a)}{IV(a)}, IV(a)=-\sum\limits_{v=1}^V(\frac{|D^v|}{|D|}log_2(\frac{|D^v|}{|D|}))$，IV(a)称为属性a的固有值。属性可能取值数目越多，IV(a)的值越大，增益率即增益/固有值

<span id = "concept 4-7" > ▲ </span>**[C4.5决策树(78,83)](#chapter 4)** : 基于增益率和二分法，可处理连续值的决策树。使用启发式：先从候选划分属性中找出信息增益高于平均水平的属性，在从中选择增益率最高的。

<span id = "concept 4-10" > ▲ </span>**[基尼指数(Gini index)(79)](#chapter 4)** : 基尼值$Gini(D) = \sum\limits_{k=1}^{|\mathcal Y|}\sum\limits_{k'\not=k}p_kp_{k'}=1-\sum\limits_{k=1}^{|\mathcal Y|}p_k^2$,反映了从数据集D中随机抽取两个样本，其类别标记不一致的概率。 基尼值越小，数据集纯度越高。基尼指数定义为：$Gini\_index(D,a)=\sum\limits_{v=1}^V(\frac{|D^v|}{|D|}Gini(D^v))$

<span id = "concept 4-8" > ▲ </span>**[CART决策树(Classfication and Regression Tree)(79)](#chapter 4)** : 使用基尼指数划分属性的决策树。

### 剪枝处理

<span id = "concept 4-11" > ▲ </span>**[剪枝(pruning)(79,352)](#chapter 4)** : 决策树学习算法对付过拟合的主要手段，为了尽可能正确分类训练样本，结点划分过程将不断重复，有时会造成决策树分支过多，因训练样本过度学习导致将训练集自身的特点当做所有数据都具有的一般性质而导致过拟合，因此可通过主动去掉一些分支来降低过拟合的风险。

<span id = "concept 4-12" > ▲ </span>**[预剪枝(prepruning)(79,352)](#chapter 4)** : 在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能的提升，则停止划分并将当前结点标记为叶节点，预剪枝基于贪心存在欠拟合的风险。

<span id = "concept 4-9" > ▲ </span>**[后剪枝(postpruning)(79)](#chapter 4)** : 先从训练集生成一颗完整的决策树，然后自底向上地对非叶节点进行考察，若将该结点子树替换成叶节点能提升泛化性能，则进行替换，后剪枝训练时间开销大。

<span id = "concept 4-13" > ▲ </span>**[决策树桩(decison stump)(82)](#chapter 4)** : 仅有一层划分的决策树。

### 连续和缺失值

<span id = "concept 4-14" > ▲ </span>**[离散化(83)](#chapter 4)** : 连续属性转为离散值，可用二分法，即设定属性的某个划分点，将集合分为两部分。

<span id = "concept 4-15" > ▲ </span>**[缺失值(85)](#chapter 4)** : 样本在某些属性上的取值未知。

<span id = "concept 4-16" > ▲ </span>**[多变量决策树(multivariate decision tree)(88,92)](#chapter 4)** : 每个结点结合多个变量学习一个线性分类器，比如-0.8\*密度-0.044\*含糖率<=-0.313，这样的多个结点构成的决策树。

<span id = "concept 4-17" > ▲ </span>**[斜决策树(oblique descision tree)(90)](#chapter 4)** : 同多变量决策树。单变量决策树(univariate decision tree)的分类边界由若干个与坐标轴平行的线段组成。

<span id = "concept 4-18" > ▲ </span>**[增量学习(incremental learning)(92,109)](#chapter 4)** : 在接收到新样本后对已学得的模型进行调整，不用完全重新学习，主要机制是通过调整分支路径上的划分属性次序来对树进行部分重构。


​    
​    
## 神经网络
<span id = "concept 5-0" > ▲ </span>**[M-P神经元模型(97)](#chapter 5)** : 神经元接收来自n个其他神经元传递过来的输入信号，这些输入信号通过带权重的连接进行传递，神经元接收到的总输入值将与神经元的阈值进行比较，然后通过激活函数处理以产生神经元的输出。

<span id = "concept 5-1" > ▲ </span>**[人工神经网络(97)](#chapter 5)** : 非生物学意义的神经网络。

<span id = "concept 5-2" > ▲ </span>**[神经网络(neural networks)(97)](#chapter 5)** : 神经网络是由具有适应性的简单单元组成的广泛并行互联的网络，它的组织能够模拟生物神经系统对真实世界物体所作出的交互反应。

<span id = "concept 5-3" > ▲ </span>**[神经元(neuron)(97)](#chapter 5)** : 神经网络中具有适应新的简单单元，与其他神经元相连。

<span id = "concept 5-4" > ▲ </span>**[阈值(bias/threshold)(97,104)](#chapter 5)** : 临界值。

<span id = "concept 5-5" > ▲ </span>**[感知机(perceptron)(98)](#chapter 5)** : 由两层神经元组成，输入层接收外界输入信号后传递给输出层，输出层是M-P神经元，亦称“阈值逻辑单元”。

<span id = "concept 5-6" > ▲ </span>**[激活函数(activation function)(98)](#chapter 5)** : 将输入值映射为输出值0或1，理想的激活函数是阶跃函数，实际常用Sigmoid函数作为激活函数。

<span id = "concept 5-7" > ▲ </span>**[挤压函数(squashing function)(98)](#chapter 5)** : Sigmoid函数把可能在较大范围内变化的输入值挤压到(0,1)输出值范围内，因此有时也称为“挤压函数”。

<span id = "concept 5-8" > ▲ </span>**[阈值逻辑单元(threshold logic unit)(98)](#chapter 5)** : 经激活函数处理以产生输出的神经元。

<span id = "concept 5-9" > ▲ </span>**[非线性可分(linearly unseparable)(99)](#chapter 5)** : 用线性超平面无法划分

<span id = "concept 5-10" > ▲ </span>**[功能神经元(functional neuron)(99)](#chapter 5)** : 进行运算或其他处理的神经元。

<span id = "concept 5-11" > ▲ </span>**[收敛(converge)(99)](#chapter 5)** : 感知机的学习过程使得权重向量趋于稳定。

<span id = "concept 5-12" > ▲ </span>**[线性超平面(linear meta-surface)(99)](#chapter 5)** : 在空间内可以用线性模型表达的平面。

<span id = "concept 5-13" > ▲ </span>**[线性可分(linearly seprarable)(99,126)](#chapter 5)** : 存在一个线性超平面可以划分两种模式，则认为这两种模式线性可分，比如与、或、非问题。

<span id = "concept 5-14" > ▲ </span>**[学习率(learning rate)(99)](#chapter 5)** : 对权重每次的调整量。

<span id = "concept 5-15" > ▲ </span>**[哑结点(dummy node)(99)](#chapter 5)** : 输入固定的结点，不对输入做出响应，但会影响输出。

<span id = "concept 5-16" > ▲ </span>**[振荡(fluctuation)(99)](#chapter 5)** : 权重持续往不同方向波动。

<span id = "concept 5-17" > ▲ </span>**[多层前馈神经网络(multi-layer feedforward neural network)(100)](#chapter 5)** : 多个感知机相连，每层神经元与下一层神经元全互联，神经元之间不存在同层连接，也不存在跨层连接，这样的神经网络结构被称为“多层前馈神经网络”。

<span id = "concept 5-18" > ▲ </span>**[BP算法(BackPropagation algorithm)(101)](#chapter 5)** : 神经网络学习过程就是根据训练数据来调整神经元之间的连接权以及每个功能神经元的阈值。

    (误差)逆向传播，从最后一层开始，利用广义的感知机学习规则，基于梯度下降策略，以目标的负梯度方向对参数进行调整，

   - 对每个训练样例，先将输入示例提供给输入层神经元，
   - 然后逐层将信号前传
   - 知道产生输出层结果
   - 计算输出层误差
   - 将误差逆向传播至隐层
   - 根据隐层神经元的误差来对连接权和阈值进行调整
   - 迭代循环进行，直到某些条件(如训练误差已经很小)停止。
<span id = "concept 5-19" > ▲ </span>**[BP网络(101)](#chapter 5)** : 利用BP算法训练的神经网络

<span id = "concept 5-20" > ▲ </span>**[单隐层网络(101)](#chapter 5)** : 输入层神经元仅接受输入，不进行函数处理，隐层与输出层包含功能神经元，只包含一个隐层的神经网络称为“单隐层网络”，也称为两层网络(虽然有点歧义，实际上有输入，隐，输出三层)。

<span id = "concept 5-21" > ▲ </span>**[反向传播算法(101)](#chapter 5)** : 同BP算法。

<span id = "concept 5-22" > ▲ </span>**[连接权(connection weight)(101,104)](#chapter 5)** : 神经元之间的联系的权重。

<span id = "concept 5-23" > ▲ </span>**[误差逆传播(error BackPropagaton)(101)](#chapter 5)** : 见BP算法。

<span id = "concept 5-24" > ▲ </span>**[梯度下降(102,254,389,407)](#chapter 5)** : 以目标的负梯度方向对参数进行调整。

<span id = "concept 5-25" > ▲ </span>**[链式法则(103,402)](#chapter 5)** : 计算梯度时，按影响顺序依次计算导数然后相乘。

<span id = "concept 5-26" > ▲ </span>**[累积误差逆传播(accumulated eror backpropagation)(105)](#chapter 5)** : 针对多个训练样例进行误差逆传播计算。直接针对累积误差(同时考虑多个训练样例的误差)最小化，参数更新频率比标准误差逆传播低很多，但训练到一定程度下降会非常缓慢，这时标准BP往往会更快获得较好的解。

<span id = "concept 5-27" > ▲ </span>**[早停(early stopping)(105)](#chapter 5)** : 将数据分成训练集和验证集，训练集计算梯度，更新连接权和阈值，验证集用来估计误差，若训练集误差降低但验证集误差升高，则停止训练，同时返回具有最小验证集误差的连接权和阈值。以此防止过拟合。


<span id = "concept 5-28" > ▲ </span>**[正则化(regularization)(106)](#chapter 5)** : 在误差目标函数中增加一个用于描述网络复杂度的部分，例如连接权与阈值的平方和，并对这个部分加一个λ做折中。以此防止过拟合。

<span id = "concept 5-29" > ▲ </span>**[参数空间(parameter space)(106)](#chapter 5)** : 参数为坐标轴的空间，在这个空间中可以画出误差函数组成的屏幕。

<span id = "concept 5-30" > ▲ </span>**[局部极小(106)](#chapter 5)** : 在该点导数为0

<span id = "concept 5-31" > ▲ </span>**[全局最小(106)](#chapter 5)** : 最小的极小值。

<span id = "concept 5-32" > ▲ </span>**[模拟退火(simulated annealing)(107)](#chapter 5)** : 模拟退火在每一步都以一定概率接受比当前解更差的结果，从而有助于跳出局部极小，在每部迭代过程中，接受次优解的概率随着时间的推移而逐渐降低，从而保证算法稳定。

<span id = "concept 5-33" > ▲ </span>**[遗传算法(genetic algorithms)(107)](#chapter 5)** : 多个极小值竞争。

<span id = "concept 5-34" > ▲ </span>**[ART网络(Adaptive Resonance Theory network)(108)](#chapter 5)** : 自适应谐振理论网络，竞争型无监督学习，由比较层接收输入，识别层进行距离度量学习，对一个输入距离近的识别层神经元抑制其他神经元的激活，距离大于识别阈值则将输入归入识别层神经元的模式，同时更新网络连接权。识别过程中动态调整神经元个数以适应输入模式的变化。

<span id = "concept 5-35" > ▲ </span>**[RBF网络(Radial Basis Function network)(108)](#chapter 5)** : 径向基函数网络，是一种单隐层前馈神经网络，使用径向基函数作为激活函数，输出是对隐层神经元输出的线性组合。分两步，确定神经元中心(聚类，随机采样)，BP确定参数w和β。

<span id = "concept 5-36" > ▲ </span>**[径向基函数(Radial Basis Function)(108)](#chapter 5)** : ρ(x, ci) = e^(-βi||x-ci||²)


    样本与样本中心的欧氏距离的单调函数。
<span id = "concept 5-37" > ▲ </span>**[竞争型学习(competitive learning)(108)](#chapter 5)** : 网络中的输出神经元相互竞争，每一时刻仅有一个竞争获胜的神经元被激活，其他神经元的状态被抑制，这种机制亦称胜者通吃。

<span id = "concept 5-38" > ▲ </span>**[胜者通吃(winner-take-all)(108)](#chapter 5)** : 见竞争型学习。

<span id = "concept 5-39" > ▲ </span>**[自适应谐振理论(Adaptive Resonance Theory)(108)](#chapter 5)** : 见ART网络。

<span id = "concept 5-40" > ▲ </span>**[Kohonen网络(109)](#chapter 5)** : 同SOM网络

<span id = "concept 5-41" > ▲ </span>**[SOM网络(Self-Organizing Map network)(109)](#chapter 5)** : 自组织映射网络，将高维输入数据映射到低维空间(通常为二维)，同时保持输入数据在高维空间的拓扑结构，即将高位空间中相似的样本点映射到网络输出层的临近神经元。训练时，接收一个训练样本，每个输出层神经元计算该样本与自身携带的权向量之间的距离，距离最近的神经元成为竞争获胜者，称为最佳匹配单元，

<span id = "concept 5-42" > ▲ </span>**[可塑性-稳定性窘境(stability-plasticity dilemma)(109)](#chapter 5)** : 可塑性是指神经网络要有学习新知识的能力，而稳定性则是指神经网络在学习新知识时要保持对旧知识的记忆。往往两者不可兼得。

<span id = "concept 5-43" > ▲ </span>**[在线学习(online learning)(109,241,393)](#chapter 5)** : ART网络具有兼顾可塑性和稳定性的优点，适合在线学习。

<span id = "concept 5-44" > ▲ </span>**[自组织映射(Self-Organizing Map)(109)](#chapter 5)** : 将高维输入数据映射到低维空间，同时保持输入数据在高维空间的拓扑结构，即将高维空间中的相似的样本点映射到网络输出层中的邻近神经元。

<span id = "concept 5-45" > ▲ </span>**[级联相关(Cascade-Correlation)(110)](#chapter 5)** : 级联相关网络有两个主要成分：级联和相关，级联是指建立层次连接的层级结构，在开始训练时，网络只有输入层和输出层，处于最小拓扑结构，随着训练的进行，新的因曾神经元逐渐加入，从而创建起层级结构，当新的隐层神经元加入时，其输入端连接权值是冻结固定的。相关是指通过最大化新神经元的输出和网络误差之间的相关性来训练相关的参数，训练速度较快，但容易过拟合。

<span id = "concept 5-46" > ▲ </span>**[Boltzmann分布(Boltzmann distribution)(111)](#chapter 5)** : 若网络中的神经元以任意不依赖于输入值的顺序进行更新，则网络最终将达到Boltzmann分布，此时状态向量出现的概率将仅由其能量与所有可能状态向量的能量确定：P(s) = e**(-E(s))/sum(e**(-E(t)))

<span id = "concept 5-47" > ▲ </span>**[Boltzmann机(Boltzmann machine)(111)](#chapter 5)** : 通常分两层：显层与隐层，显层用于表示数据的输入与输出，隐层则被理解为数据的内在表达，神经元是布尔型的，只能取0、1两种状态，状态1表示激活，状态0表示抑制，状态向量出现的概率将仅由其能量与所有可能状态向量的能量确定。训练过程就是将每个训练样本视为一个状态向量，使其出现的概率尽可能大。

<span id = "concept 5-48" > ▲ </span>**[Elman网络(Elman Network)(111)](#chapter 5)** : 最常用的递归神经网络之一，结构与多层前馈网络相似，但隐层神经元的输出被反馈回来，与下一时刻输入层神经元提供的信号一起作为隐层神经元在下一时刻的输入。

<span id = "concept 5-49" > ▲ </span>**[递归神经网络(Recurrent neural networks)(111)](#chapter 5)** : 允许网络中出现环形结构，从而可让一些神经元的输出反馈回来作为输入信号，这样的结构与信息反馈过程，是的网络在t时刻的输出状态不仅与t时刻的输入有关，还与t-1时刻的网络状态有关，从而能处理与实际有关的动态变化。

<span id = "concept 5-50" > ▲ </span>**[基于能量的模型(energy-based model)(111)](#chapter 5)** : 为网络状态定义一个能量，能量最小化时网络达到理想状态，而网络的训练就是在最小化这个能量函数。

<span id = "concept 5-51" > ▲ </span>**[对比散度(Constrastive Divergence)(112)](#chapter 5)** : 假定网络中有d个显层神经元和q个隐层神经元，令v和h分别表示显层与隐层的状态向量，同一层内不存在连接，采用对比散度算法对网络进行训练，计算隐层神经元状态的概率分布，然后根据这个概率分布采样得到h，并更新连接权w。

<span id = "concept 5-52" > ▲ </span>**[受限Boltzmann机(Restricted Boltzmann Machine, RBM)(112)](#chapter 5)** : 标准Boltzmann机是一个全连接图，训练网络的复杂度很高，这使其难以用于解决现实任务，现实中常用受限Boltzmann机仅保留显层与隐层之间的连接，从而将Boltzmann机结构由完全图简化为二部图。

<span id = "concept 5-53" > ▲ </span>**[发散(diverge)(113)](#chapter 5)** : 不能达到稳定(收敛)状态

<span id = "concept 5-54" > ▲ </span>**[卷积神经网络(Convoutional Neural Network,CNN)(113)](#chapter 5)** : 用权共享来节省训练开销，通常包含多个“卷积层”和“采样层(pooling)”对输入信号进行加工，然后在连接层实现与输出目标之间的映射，每个卷积层包含多个特征映射(feature map)，每个特征映射是一个特征。详细内容可以参考这个[教程](https://github.com/ahangchen/GDLnotes/blob/master/note/lesson-3/README.md)

<span id = "concept 5-55" > ▲ </span>**[权共享(weight sharing)(113)](#chapter 5)** : 让一组神经元使用相同的连接权。

<span id = "concept 5-56" > ▲ </span>**[深度学习(deep learning)(113)](#chapter 5)** : 很多层的神经网络，可以增加隐层数目或增加隐层神经元数目来实现。

<span id = "concept 5-57" > ▲ </span>**[无监督逐层训练(unsupervised layer-wise training)(113)](#chapter 5)** : 多隐层网络训练的手段，基本思想是每次训练一层隐节点，训练时将上一层隐节点的输出做为输入，本层隐节点的输出作为下一层隐节点的输入，这称为“预训练”，预训练完成后，对整个网络做“微调(fine-tuning)”训练，如在DBN中，每层都是一个RBM，整个网络可视为若干个RBM堆叠而得，可按标准的RBM训练；然后将第一层训练好的隐节点视为第二层的输入结点，对第二层进行预训练，各层预训练完成后，再利用BP算法等对整个网络进行训练。，预训练+微调可视为将大量参数分组，对每组先找到局部看来比较好的设置，然后基于这些局部较优的结果联合起来进行全局寻优，利用了模型大量参数所提供的自由度的同时，有效地节省了训练开销。

<span id = "concept 5-58" > ▲ </span>**[ReLU(Rectified Linear Unit)(114)](#chapter 5)** : 将Sigmoid激活函数替换为修正线性函数f(x)=0 | x \<0 otherwise f(x)=x，这样的神经元被称为RELU。


<span id = "concept 5-59" > ▲ </span>**[表示学习(Representation learning)(114)](#chapter 5)** : 对输入信号进行逐层加工，从而把初始的、与输出目标之间的联系不太密切的输入表示，转化成与输出目标联系更加密切的表示，换言之，通过多层处理，逐渐将初始的“低层”特征表示成“高层”特征表示后，用“简单模型”即可完成复杂的分类等学习任务。

<span id = "concept 5-60" > ▲ </span>**[汇合(pooling)(114)](#chapter 5)** : 基于局部相关性原理进行亚采样，从而在减少数据量的同时保留有用信息。

<span id = "concept 5-61" > ▲ </span>**[特征学习(feature learning)(114)](#chapter 5)** : 同表示学习。

<span id = "concept 5-62" > ▲ </span>**[广义δ规则(115)](#chapter 5)** : 最小化网络均方误差，BP算法亦称广义δ规则。

<span id = "concept 5-63" > ▲ </span>**[可解释性(115,191)](#chapter 5)** : 神经网络是一种难解释的“黑箱模型”，难以解释其工作机理。


## 支持向量机
<span id = "concept 6-0" > ▲ </span>**[划分超平面(121)](#chapter 6)** : 超平面是将N维空间分成两个闭半空间的N-1维的仿射空间。划分超平面则是把两类数据集样本划分开来的超平面。

<span id = "concept 6-1" > ▲ </span>**[支持向量(122)](#chapter 6)** : 支持平面上把两类划分开来的超平面的向量点，即距离超平面最近的几个训练样本点。

<span id = "concept 6-2" > ▲ </span>**[间隔(122)](#chapter 6)** : 两个异类支持向量到超平面的距离之和为间隔，$\gamma = \frac{2}{\parallel \omega \parallel }$.

<span id = "concept 6-3" > ▲ </span>**[SVM(123)](#chapter 6)** : 公式如下：

    $\min_{\omega,b} \frac{1}{2}\parallel \omega \parallel ^{2} $ s.t. $y_i(\omega ^{T}x_i+b)\geqslant 1, i=1,2,...,m$
<span id = "concept 6-4" > ▲ </span>**[对偶问题(dual problem)(123,405)](#chapter 6)** : 在求最小值的原问题里，其对偶问题提供了一个下界(lower bound)。

<span id = "concept 6-5" > ▲ </span>**[KKT条件(Karush-Kuhn-Tucker)(124,124,132,135)](#chapter 6)** : 公式如下：

    - $\alpha _i\geqslant 1$
    - $y_i f(x_i)-1\geqslant 0$
    - $\alpha _i(y_if(x_i)-1)=0$ 

<span id = "concept 6-6" > ▲ </span>**[核函数(126)](#chapter 6)** : 可以看成是一种映射，不仅可以是点对点的映射，还可以是一个分布对点的映射。

<span id = "concept 6-7" > ▲ </span>**[核技巧(kernel trick)(127)](#chapter 6)** : $x_i$与$x_j$在特征空间的内积等于它们在原始样本空间中通过函数κ(·,·)计算的结果。

<span id = "concept 6-8" > ▲ </span>**[支持向量展式(127)](#chapter 6)** : 模型最优解课通过训练样本的核函数展开。

<span id = "concept 6-9" > ▲ </span>**[核矩阵(128,138,233)](#chapter 6)** : 公式如下：

    $K=\begin{bmatrix}\kappa(x_1,y_1) & \cdots\ & \kappa(x_1,y_j) & \cdots\ &\kappa(x_1,y_m)\\
 \vdots & \ddots & \vdots & \ddots  & \vdots  \\ \kappa(x_i,y_1) & \cdots\  & \kappa(x_i,y_j)  & \cdots\ & \kappa(x_i,y_m)\\
 \vdots & \ddots & \vdots & \ddots  & \vdots  \\ \kappa(x_m,y_1) & \cdots\ & \kappa(x_m,y_j)  & \cdots\ & \kappa(x_m,y_m)\\ \end{bmatrix}$
    形为这样的核函数，可以将低维空间映射为高维空间，将原来线性不可分的分布转化为线性可分的分布。核函数可以表示高维空间的内积。
    此外，核函数必须满足对称性和矩阵半正定。
<span id = "concept 6-10" > ▲ </span>**[RKHS(128)](#chapter 6)** : 非线性映射ϕ，它将原始特征空间中的数据点映射到另一个高维空间中，这个高维空间称为再生核希尔伯特空间(Reproducing Kernel Hilbert Space)，简称RKHS。

<span id = "concept 6-11" > ▲ </span>**[高斯核(128)](#chapter 6)** : 高斯核函数是最常用的径向基函数。

<span id = "concept 6-12" > ▲ </span>**[线性核(128)](#chapter 6)** : 线性核函数是$\kappa(x_i,y_i)=x_i^Tx_j$；多项式核是$\kappa(x_i,y_i)=(x_i^Tx_j)^d$，即d为1时退化为线性核。

<span id = "concept 6-13" > ▲ </span>**[软间隔(129)](#chapter 6)** : 允许支持向量机在一些样本上出错，即允许某些样本不满足约束。

<span id = "concept 6-14" > ▲ </span>**[硬间隔(129)](#chapter 6)** : 要求所有样本均满足约束，即所有样本都划分正确。

<span id = "concept 6-15" > ▲ </span>**[0/1损失函数(130,147)](#chapter 6)** : 公式如下：

    $ l_{0/1}(z) = \left\{ \begin{array}{rl} 1, &\mbox{ if $z<0$} \\ 0, &\mbox{ otherwise} \end{array} \right. $
<span id = "concept 6-16" > ▲ </span>**[替代损失(130)](#chapter 6)** : 0/1损失函数不易直接求解(非连续，不是convex)，所以通常会用其他函数来替代求解，也叫替代损失。

<span id = "concept 6-17" > ▲ </span>**[hinge损失(130)](#chapter 6)** : $l_{hinge}(z)=\max(0,1-z)$，采用hinge损失函数，则优化目标变成$\min_{w,b}\frac{1}{2}||w||^2+C\sum_{i=1}^{m}max(0,1-y_i(w^Tx_i+b))$

<span id = "concept 6-18" > ▲ </span>**[指数损失(130,173)](#chapter 6)** : $l_{exp}(z)=\exp(-z)$

<span id = "concept 6-19" > ▲ </span>**[对率损失(130)](#chapter 6)** : $l_{log}(z)=\log(1+\exp(-z))$

<span id = "concept 6-20" > ▲ </span>**[松弛变量(130)](#chapter 6)** : 松弛变量，即slack variables$\xi_i$


<span id = "concept 6-21" > ▲ </span>**[软间隔支持向量机(131)](#chapter 6)** : 引入了松弛变量$\xi_i$，式子可重写为：


    $ \begin{align*}& \min_{w,b}\frac{1}{2}||w||^2+C\sum_{i=1}^{m}max(0,1-y_i(w^Tx_i+b))\\& \begin{array}{r@{\quad}r@{}l@{\quad}l}s.t.&yi(w^Tx_i+b)\geq1-\xi_i\\ &\xi_i\geq0, i=1,2\ldots,m  \\\end{array} .\end{align*} $
<span id = "concept 6-22" > ▲ </span>**[结构风险(133)](#chapter 6)** : 描述模型f的性质，$\Omega(f)$.

<span id = "concept 6-23" > ▲ </span>**[经验风险(133)](#chapter 6)** : 描述模型和训练数据的契合程度，可以理解为误差。

<span id = "concept 6-24" > ▲ </span>**[罚函数法(133)](#chapter 6)** : 正则化。对不希望得到的结果施以惩罚，从而使得优化过程趋向于希望目标。

<span id = "concept 6-25" > ▲ </span>**[支持向量回归(133)](#chapter 6)** : Support Vector Regression(SVR)其实是对误差的计算加了一个误差容忍值epsilon(即$\epsilon$)，即落入这个$\epsilon$误差范围内的不计入误差和中。

<span id = "concept 6-26" > ▲ </span>**[核方法(137)](#chapter 6)** : 这一系列基于核函数的学习方法统称为核方法。最常见的是将线性学习器拓展为非线性学习器。如把线性不可分的低维分布通过方法转成线性可分的高维分布。

<span id = "concept 6-27" > ▲ </span>**[Mercer定理(137)](#chapter 6)** : 任何半正定的函数都可以作为核函数。

<span id = "concept 6-28" > ▲ </span>**[表示定理(137)](#chapter 6)** : 优化问题的解总可用核函数表示。

<span id = "concept 6-29" > ▲ </span>**[核化(137,232)](#chapter 6)** : 引入核函数来解决问题。

<span id = "concept 6-30" > ▲ </span>**[核线性判别分析(137)](#chapter 6)** : Kernelized Linear Discriminant Analysis(KLDA)是指引入核函数进行线性判别分析。

<span id = "concept 6-31" > ▲ </span>**[割平面法(139)](#chapter 6)** : Cutting plane algorithm是求全整数规划的一种方法，先松弛求得最优解，再逐步把不符合整数可行解的那一部分可行域通过平面(不等式分割)划分掉。

<span id = "concept 6-32" > ▲ </span>**[多核学习(140)](#chapter 6)** : 使用多个核函数，学习后获得最优凸组合。

<span id = "concept 6-33" > ▲ </span>**[一致性(140)](#chapter 6)** : 相合性。即考虑通过求解替代损失函数得到的解释是否是原问题的解。

​    

## 贝叶斯分类器
<span id = "concept 7-0" > ▲ </span>**[贝叶斯风险(Bayes risk)(147)](#chapter 7)** : 贝叶斯最优分类器对应的条件风险

<span id = "concept 7-1" > ▲ </span>**[贝叶斯最优分类器(Bayes optimal classifier)(147)](#chapter 7)** : 为最小化总体风险，只需在每个样本上选择那个能使条件风险最小的类别标记，此时判定准侧称为贝叶斯最优分类器。

<span id = "concept 7-2" > ▲ </span>**[风险(risk)(147)](#chapter 7)** : 决策论中将“期望损失”称为风险。

<span id = "concept 7-3" > ▲ </span>**[条件风险(conditional risk)(147)](#chapter 7)** : 基于后验概率$P(c_{i}|x)$可获得将样本x分类为ci所产生的期望损失，即在样本x上的条件风险。

<span id = "concept 7-4" > ▲ </span>**[贝叶斯定理(148)](#chapter 7)** : $P(c|x)=\frac{P(c)P(x|c)}{P(x)}$


    其中， P(c)是类“先验”(prior)概率；P(x|c)是样本x相对于类标记c的类条件概率(class-conditional probability)，或称为“似然”(likelihood)；P(x)是用于归一化的“证据”(evidence)因子。估计P(c|x)的问题转化为如何基于训练数据D来估计先验P(c)和似然P(x|c)。
<span id = "concept 7-5" > ▲ </span>**[判别式模型(discriminative models)(148,325)](#chapter 7)** : 给定x,可通过直接建模P(c|x)来预测c，这样得到的是判别式模型。


<span id = "concept 7-6" > ▲ </span>**[生成式模型(generative models)(148,295,325)](#chapter 7)** : 先对联合概率分布P(x,c)建模，然后再由此获得P(c|x)，这样得到的是生成式模型。


<span id = "concept 7-7" > ▲ </span>**[似然(likelihood)(148)](#chapter 7)** : 见贝叶斯定理。


<span id = "concept 7-8" > ▲ </span>**[先验(Prior)(148)](#chapter 7)** : 见贝叶斯定理


<span id = "concept 7-9" > ▲ </span>**[证据(evidence)(148)](#chapter 7)** : 见贝叶斯定理


<span id = "concept 7-10" > ▲ </span>**[极大似然估计(maximum likelihood estimation, MLE)(149)](#chapter 7)** : 

   令$D_{c}$表示训练集D中第c类样本组成的集合，假设这些样本是独立同分布的，则参数$\theta_{c}$对于数据集$D_{c}$的似然是：

   $P(D_{c}|\theta_{c}) = \prod_{x \in D_{c}} P(x|\theta_{c})$

<span id = "concept 7-11" > ▲ </span>**[朴素贝叶斯分类器(naive bayes classifier)(150)](#chapter 7)** : 基于贝叶斯公式来估计后验概率P(c|x)的主要困难在于：类条件概率P(x|c)是所有属性上的联合概率，难以从有限的训练样本直接估计而得，为避开这个障碍，朴素贝叶斯分类器采用了“属性条件独立性假设”：


    $P(c|x) = \frac{P(c)P(x|c)}{P(x)}=\frac{P(c)}{P(x)} * \prod_{i=1}^{d} P(x_{i}|c)$
    
    即P(x|c)等于在c的条件下，所有属性的概率的乘积。

<span id = "concept 7-12" > ▲ </span>**[条件独立性假设(150,305)](#chapter 7)** : 对已知类别，假设所有属性相互独立，换言之，假设每个属性独立的对分类结果发生影响。


<span id = "concept 7-13" > ▲ </span>**[拉普拉斯修正(Laplacian correction)(153)](#chapter 7)** : 为了避免其他属性携带的信息被训练集中未出现的属性值抹去，在估计概率值时通常要进行“平滑”，常用“拉普拉斯修正”，具体来说，另N表示训练集D中可能的类别数，$N_{i}$表示第i个属性可能的取值书，则类先验概率


    $\hat{P}(c)=\frac{|D_{c}|+1}{|D|+N}$
    
    条件概率：
    
    $\widehat{P}(x_{i}|c)=\frac{D_{c,x_{i}}+1}{D_{c}+N_{i}}$

<span id = "concept 7-14" > ▲ </span>**[半监督贝叶斯分类器(semi-naive Bayes classifiers)(154)](#chapter 7)** : 半朴素贝叶斯分类器的基本想法是适当考虑一部分属性间的相互依赖信息，从而既不需进行完全联合概率计算，又不至于彻底忽略了比较强的属性依赖关系。

<span id = "concept 7-15" > ▲ </span>**[独依赖估计(One-Dependent Estimator)(154)](#chapter 7)** : 

    独依赖估计是半朴素贝叶斯分类器最常用的一种策略，假设每个属性在类别之外最多仅依赖于一个其他属性，即
    
    $P(c|x)\propto P(c)\prod_{i=1}^{d}P(x_{i}|c,pa_{i})$
    
    其中$pa_{i}$为属性$x_{i}$所依赖的属性，称为$x_{i}$的父属性，对每个属性$x_{i}$，若其父属性$pa_{i}$已知，可以估计概率值$P(x_{i}|c,pa_{i})$，于是问题的关键就转化为如何确定每个属性的父属性，不同的做法产生不同的独依赖分类器。

<span id = "concept 7-16" > ▲ </span>**[懒惰学习(lazy learning)(154,225,240)](#chapter 7)** : 

   若任务数据更替频繁，则可采用“懒惰学习”方式，先不进行任何训练，待收到预测请求时再根据当前数据集进行概率估值；若数据不断增加，则可在现有估值基础上，仅对新增样本的属性值所涉及的概率估值进行计数修正即可实现增量学习。
<span id = "concept 7-17" > ▲ </span>**[超父(super-parent)(155)](#chapter 7)** : 

   假设所有属性都依赖于同一个属性，称为超父，然后通过交叉验证等模型选择方法来确定超父属性，由此形成了超父独依赖估计(Super-Parent ODE，SPODE).

<span id = "concept 7-18" > ▲ </span>**[贝叶斯网(Bayesian network)(156,319,339)](#chapter 7)** : 借助有向无环图来刻画属性之间的依赖关系，并使用条件概率表来描述属性的联合概率分布。具体来说，一个贝叶斯网有结构G和参数$\theta$两部分构成，即$B=<G,\theta>$。网络结构G是一个有向无环图，每个结点对应于一个属性，若两个属性有直接依赖关系，则它们由一条边连接起来；参数$\theta$定量描述这种依赖关系，假设属性$x_{i}$在G中的父结点集为$\pi_{i}$，则$\theta$包含了每个属性的条件概率表$\theta_{x_{i}|\pi_{i}}=P_{B}(x_{i}|\pi_{i})$。


<span id = "concept 7-19" > ▲ </span>**[概率图模型(156,319)](#chapter 7)** : 

  是一种用图来表达变量相关关系的概率模型，它以图为表示工具，最常见的是用一个结点表示一个或一组随机变量，结点之间的边表示变量间的概率相关关系，即“变量关系图”。根据边的性质不同，概率图模型可大致分为两类：第一类是用有向无环图表示变量间的以来关系，称为有向图模型或贝叶斯网；第二类是使用无向图表示变量间的相关关系，称为无向图模型或马尔科夫网。

<span id = "concept 7-20" > ▲ </span>**[信念网(belief network)(156)](#chapter 7)** : 

  即贝叶斯网。

<span id = "concept 7-21" > ▲ </span>**[V型结构(V-structure)(158)](#chapter 7)** : 也称冲撞结构


{% mermaid %}
graph TD;
  A[x1]-->B[x4];
  C[x2]-->B[x4];
{% endmermaid %}

  给定父节点$x_{4}$的取值，则$x_{1}$与$x_{2}$不独立，若x_{4}未知，则V型结构下$x_{1}$与$x_{2}$却是相互独立的，这样的独立性称为边际独立性。

<span id = "concept 7-22" > ▲ </span>**[边际独立性(marginal independence)(158)](#chapter 7)** : 见V型结构。


<span id = "concept 7-23" > ▲ </span>**[边际化(marginalization)(158,328)](#chapter 7)** : 对变量做积分或求和亦称边际化。


<span id = "concept 7-24" > ▲ </span>**[道德图(moral graph)(158)](#chapter 7)** : 为了分析又想吐中变量间的条件独立性，可使用“有向分离”，把有向图转为一个无向图：

  - 找出有向图中的所有V型结构，在V型结构的两个父节点之间加上一条无箱变；
  - 将所有有向边改为无向边。
    由此产生的无向图称为“道德图”，令父结点相连的过程称为“道德化”(moralization)。

<span id = "concept 7-25" > ▲ </span>**[端正图(158)](#chapter 7)** : 即道德图。


<span id = "concept 7-26" > ▲ </span>**[有向分离(D-seperation)(158)](#chapter 7)** : 

  见道德图。

<span id = "concept 7-27" > ▲ </span>**[最小描述长度(Minimal Description Length)(159)](#chapter 7)** : 常用评分函数通常基于信息论准则，此类准则将学习问题看做一个数据压缩任务，学习的目标是找到一个能以最短编码长度描述训练数据的模型，此时编码的长度包括了描述模型自身所需的字节长度和使用该模型描述数据所需的字节长度。对贝叶斯网学习而言，模型就是一个贝叶斯网，同时，每个贝叶斯网描述了一个在训练数据上的概率分布，自有一套编码机制能使那些经常出现的样本有更短的编码，选择综合编码长度(包括描述网络和编码数据)最短的贝叶斯网，这就是最小描述长度。


<span id = "concept 7-28" > ▲ </span>**[吉布斯采样(161,334)](#chapter 7)** : 吉布斯采样先随机产生一个与证据E=e一致的样本$q^{0}$作为初始点，然后每步从当前样本出发产生下一个样本。具体来说，在第t次采样中，算法先假设$q^{t}=q^{t-1}$，然后对非证据变量逐个进行采样改变其取值，采样概率根据贝叶斯网B和其他变量的当前取值(即Z=z)计算获得。假定经过T次采样得到的与q一致的样本共有$n_{q}$个，则可近似估算出后验概率


  $P(Q=q|E=e) \backsimeq \frac{n_{q}}{T}$

<span id = "concept 7-29" > ▲ </span>**[近似推断(161,161)](#chapter 7)** : 当网络结点较多，连接稠密时，难以进行精确推断，此时需借助“近似推断”，通过降低精度要求，在有限时间内求得近似解。


<span id = "concept 7-30" > ▲ </span>**[精确推断(161,328,331)](#chapter 7)** : 最理想的是直接根据贝叶斯网定义的联合概率分布来精确计算后验概率，精确推断是NP难的。


<span id = "concept 7-31" > ▲ </span>**[马尔科夫链(Markov chain)(161)](#chapter 7)** : 吉布斯采样是在贝叶斯网所有变量的联合状态空间与证据E=e一致的子空间中进行“随机漫步”，每一步仅依赖于前一步的状态，这是一个马尔可夫链。在一定条件下，无论从什么初始状态开始，马尔可夫链第t步的状态分布在$t\rightarrow\infty$时必收敛于一个平稳分布，对吉布斯采样来说，这个分布恰好是$P(Q|E=e)$。在T很大的时候，吉布斯采样相当于根据$P(Q|E=e)$采样，从而保证了后验概率收敛于$P(Q=q|E=e)$。

<span id = "concept 7-32" > ▲ </span>**[平稳分布(stationary distribution)(161)](#chapter 7)** : 见马尔科夫链。


<span id = "concept 7-33" > ▲ </span>**[EM算法(Expectation-Maximization Algorithm)(162,208,295,335)](#chapter 7)** : 常用的估计参数隐变量的利器，它是一种迭代式的方法，基本想法是：若参数$\theta$，则可根据训练数据推断出最优隐变量Z的值(E步)；反之，若Z的值已知，则可方便地对参数$\theta$做极大似然估计。


<span id = "concept 7-34" > ▲ </span>**[隐变量(latent variable)(162,319)](#chapter 7)** : 现实应用中往往会遇到不完整的训练样本，存在未观测的变量，未观测变量的学名是隐变量。


<span id = "concept 7-35" > ▲ </span>**[边际似然(marginal likehood)(163)](#chapter 7)** : 令X表示已观测变量集，Z表示隐变量集，$\theta$表示模型参数。若欲对$\theta$做极大似然估计，则应最大化对数似然


  $LL(\theta|X,Z)=ln P(X,Z|\theta)$

  然而由于Z是隐变量，上式无法直接秋季，此时我们可以通过对Z计算期望，来最大化已观测的对数“边际似然”

  $LL(\theta|X) = ln P(X|\theta) = ln \sum_Z P(X,Z|\theta)$

<span id = "concept 7-36" > ▲ </span>**[坐标下降(coordinate descent)(163,408)](#chapter 7)** : 非梯度优化方法，在每步迭代中沿着一个坐标方向进行搜索，通过循环使用不同的坐标方向来达到目标函数的局部极小值，不妨假设目标是求解函数$f(x)$的极小值，其中$x=(x_1,x_2,...,x_d)^T \in R^d$是一个d维向量。从初始点$x^0$开始，坐标下降法通过迭代地构造序列$x^0,x1,x2,...$来解决问题，$x^(t+1)$的第i个分量$x_i^{t+1}$构造为


  $x_i^(t+1) = argmin_{y \in \mathbb{R}}$

  迭代执行该过程，序列$x^0,x1,x2,...$能收敛到所期望的局部极小点或驻点。若目标函数不光滑，可能陷入非驻点。

<span id = "concept 7-37" > ▲ </span>**[贝叶斯分类器(Bayes Classifier)(164)](#chapter 7)** : 通过最大后验概率进行单点估计。

<span id = "concept 7-38" > ▲ </span>**[贝叶斯学习(Bayes learning)(164)](#chapter 7)** : 

  进行分布估计。


## 集成学习

<span id = "concept 8-0" > ▲ </span>**[多分类器系统(multi-classifier system)(171)](#chapter 8)** : 即集成学习。


<span id = "concept 8-1" > ▲ </span>**[个体学习器(individual learner)(171)](#chapter 8)** : 集成学习的一般结构是：先产生一组“个体学习器”，再用某种策略将它们结合起来，个体学习器通常由一个现有的学习算法从训练数据产生。


<span id = "concept 8-2" > ▲ </span>**[基学习器(base learner)(171)](#chapter 8)** : 集成中只包含同种类型的个体学习器，这样的集成是同质的。同质集成中的个体学习器亦称“基学习器”，相应的学习算法称为“基学习算法”。


<span id = "concept 8-3" > ▲ </span>**[基学习算法(base learning algorithm)(171)](#chapter 8)** : 见基学习器。


<span id = "concept 8-4" > ▲ </span>**[集成学习(ensemble learning)(171,311)](#chapter 8)** : 集成学习通过构建并结合多个学习器来完成学习任务，有时也被称为多分类器系统(multi-classifier system)，基于委员会的学习(committee-based learning)。


<span id = "concept 8-5" > ▲ </span>**[弱学习器(weak learner)(171)](#chapter 8)** : 集成学习通过将多个学习器进行结合，常可获得比单一学习器显著优越的泛化性能，这对弱学习器尤为明显，基学习器有时也被直接称为弱学习器。


<span id = "concept 8-6" > ▲ </span>**[AdaBoost(172)](#chapter 8)** : AdaBoost算法有多种推导方式，比较容易理解的是基于“加性模型”，即基学习器的线性组合


  $H(x) = \sum_{t=1}^T \alpha_t h_t (x)$

  来最小化指数损失函数(exponential loss function)

  $l_{exp}(H|D) = \mathbb{E}_{x~D}[e^{-f(x)H(x)}]$

<span id = "concept 8-7" > ▲ </span>**[多样性(diversity)(172)](#chapter 8)** : 学习器之间具有差异。


<span id = "concept 8-8" > ▲ </span>**[投票法(voting)(172,225)](#chapter 8)** : 少数服从多数。


<span id = "concept 8-9" > ▲ </span>**[Boosting(173,139)](#chapter 8)** : Boosting是一族可将弱学习器提升为强学习器的算法，这族算法的工作机制类似：先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器做错的样本在后续收到更多关注，然后基于调整后的样本分布来训练下一个基学习器，如此重复进行，直至基学习器数目达到事先指定的值T，最终将这T个基学习器进行加权结合。


<span id = "concept 8-10" > ▲ </span>**[加性模型(173)](#chapter 8)** : 见AdaBoost


<span id = "concept 8-11" > ▲ </span>**[重采样(re-sampling)(177)](#chapter 8)** : 在每一轮学习中，根据样本分布对训练集重新进行采样，再用重采样而得的样本集对基学习器进行训练。


<span id = "concept 8-12" > ▲ </span>**[重赋权(re-weighting)(177)](#chapter 8)** : 在训练过程的每一轮中，根据样本分布为每个训练样本重新赋予一个权重，对无法接受带权样本的基学习算法，则可通过重采样法处理，两种做法没有显著的优劣差别。


<span id = "concept 8-13" > ▲ </span>**[Bagging(Boostrap AGGregatING)(178)](#chapter 8)** : Bagging是并行式集成学习方法最著名的代表，基于自助采样法，给定包含m个样本的数据集，先随机取出一个样本放入采样集中，再把该样本放回初始数据集，使得下次采样时该样本仍有可能被选中，这样经过m次随机采样操作，我们得到含m个样本的采样集，初始训练集中有的样本在采样集里多次出现，有的从未出现。采样出T个含m个训练样本的采样集，然后基于每个采样集训练出一个基学习器，再将这些基学习器进行结合，这就是Bagging的基本流程。


<span id = "concept 8-14" > ▲ </span>**[自助采样法(Boostrap sampling)(178)](#chapter 8)** : 见Bagging。


<span id = "concept 8-15" > ▲ </span>**[随机森林(Random Forest,RF)(179)](#chapter 8)** : 是Bagging的一个扩展变体，RF在以决策树为基学习器构建Bagging集成的基础上，进一步在决策树的训练过程中引入随机属性选择。具体来说，传统决策树在选择划分属性时是在当前结点的属性集合(假定有d个属性)中选择一个最优属性，，而在RF中，对基决策树的每个结点，先从该结点的属性集合中随机选择一个包含k个属性的子集，然后再从这个子集中选择一个最优属性用于划分，这里的参数k控制了随机性的引入程度：若令k=d，则基决策树的构建与传统决策树相同；若令k=1，则是随机选择一个属性用于划分；一般情况下，推荐$k=log_2d$。


<span id = "concept 8-16" > ▲ </span>**[加权平均(weighted averaging)(182,225)](#chapter 8)** : 假定集成包含T个基学习器${h_1,h_2,...h_T}$，其中$h_i$在示例$x$上的输出为$h_i(x)$，加权平均结合$h_i$： $H(x)=\sum_{i=1}^Tw_ih_i(x)$


  其中$w_i$是个体学习器$h_i$的权重，通常要求$w_i\geqq0, \sum_{i=1}^T=1$

<span id = "concept 8-17" > ▲ </span>**[简单平均(simple averaging)(182)](#chapter 8)** : $H(x)=\frac{1}{T}\sum_{i=1}^Th_i(x).$


  符号含义见加权平均。

<span id = "concept 8-18" > ▲ </span>**[绝对多数投票(majority voting) (182)](#chapter 8)** : 对分类任务来说，学习器$h_i$将从类别标记集合${c_1,c_2,...,c_N}$中预测出一个标记，最常见的结合策略是使用投票法，将$h_i$在样本$x$上的预测输出表示为一个N维向量$(h_i^1(x);h_i^2(x);...;h_i^N(x))$，其中$h_i^j(x)$是$h_i$在类别标记$c_j$上的输出。


  绝对多数投票法: $\begin{eqnarray}H(x)= \begin{cases} c_j, &if \sum_{i=1}^Th_i^j(x)>0.5\sum_{k=1}^N\sum_{i=1}^Th_i^k(x)\cr reject, otherwise\end{cases} \end{eqnarray}$

  即若某标记得票过半数，则预测为该标记；否则拒绝预测。

<span id = "concept 8-19" > ▲ </span>**[加权投票(weighted voting)(183,225)](#chapter 8)** : $H(x)=c_{argmax_j\sum_{i=1}^Tw_ih_i^j(x)}$


  与加权平均法类似，$wi$是$h_i$的权重，通常$wi\geq0, \sum_{i=1}^Tw_i=1$.

<span id = "concept 8-20" > ▲ </span>**[相对多数投票(plurality votiing)(183)](#chapter 8)** : $H(x) = c_{argmax_j\sum_{i=1}^Th_i^j(x)}$


  即预测为得票最多的标记，若同时又多个标记获得最高表，则从中随机选取一个，绝对多数投票和相对多数投票统称为多数投票法。

<span id = "concept 8-21" > ▲ </span>**[Stacking(184)](#chapter 8)** : 一种集成学习方法，先从初始数据集训练出初级学习器，然后生成一个新数据集用于训练次级学习器，在新数据集中，初级学习器的输出被当作样例输入特征，而初始样本的标记仍被当做样例标记。


<span id = "concept 8-22" > ▲ </span>**[贝叶斯模型平均(Bayes Model Averaging)(185)](#chapter 8)** : 基于后验概率来为不同模型赋予权重，可视为加权平均法的一种特殊实现，理论上，若数据生成模型恰在当前考虑的模型中，且数据噪声少，则BMA不差于Stacking；然而，在现实应用中无法确保数据生成模型一定在当前考虑的模型中，甚至可能难以用当前考虑的模型来进行近似，因此，Stacking通常优于BMA，更鲁棒，BMA对模型近似误差更敏感。


<span id = "concept 8-23" > ▲ </span>**[分歧(ambiguity)(185,304)](#chapter 8)** : 假定我们用个体学习器$h_1,h_2,...,h_T$通过加权平均法结合产生的集成来完成回归学习任务$f:\mathbb{R}^d\mapsto\mathbb{R}$，对示例$x$，定义学习器$h_i$的“分歧”为：


  $A(h_i|x)=(h_i(x)-H(x))^2$

  则集成的“分歧”是 $\overline{A}(h|x) = \sum_{i=1}^Tw_iA(h_i|x) = \sum_{i=1}^Tw_i(h_i(x)-H(x))^2$

  这里的分歧表征了个体学习器在样本x上的不一致性，在一定程度上反映了个体学习器的多样性。

<span id = "concept 8-24" > ▲ </span>**[误差-分歧分解(error-ambiguity decomposition)(185)](#chapter 8)** : 公式如下：


  $E=\overline{E}-\overline{A}$

  $E$: 集成泛化误差，$\overline{E}$: 个体学习器泛化误差的加权均值，$\overline{A}$表示个体学习器的加权分歧值。这个分解明确提出：个体学习器准确性越高，多样性越大，集成越好。

<span id = "concept 8-25" > ▲ </span>**[差异性度量(187)](#chapter 8)** : 同多样性度量。


<span id = "concept 8-26" > ▲ </span>**[多样性度量(diversity measure)(187)](#chapter 8)** : 度量集成中个体分类器的多样性，估算个体学习器的多样化程度，典型做法是考虑个体分类器的两两相似/不相似性，常用度量有不合度量，相关系数，Q-统计量，K-统计量


<span id = "concept 8-27" > ▲ </span>**[属性子集(189)](#chapter 8)** : 训练样本通常由一组属性描述，不同的子空间(即属性子集)提供了观察数据的不同视角。


<span id = "concept 8-28" > ▲ </span>**[随机子空间(random subspace)(189)](#chapter 8)** : 依赖输入属性扰动产生随机的属性子集。


<span id = "concept 8-29" > ▲ </span>**[稳定基学习器(stable base learner)(189)](#chapter 8)** : 对数据样本扰动不敏感的学习器，例如线性学习器、支持向量机、朴素贝叶斯，k近邻学习器。


<span id = "concept 8-30" > ▲ </span>**[子空间(subspace)(189,227)](#chapter 8)** : 子空间一般指从初始的高维属性空间投影产生的低维属性空间，描述低维空间的属性是通过初始属性投影变换而得，未必是初始属性。


<span id = "concept 8-31" > ▲ </span>**[集成修剪(ensemble pruning)(191)](#chapter 8)** : 集成产生之后再视图通过去除一些个体学习器来获得较小的集成，称为集成修剪，有助于减小模型的存储开销和预测时间开销，减小集成规模常导致泛化性能下降，并行化集成进行修剪能在减小规模的同时提升泛化性能，并催生了基于优化的集成修剪技术。


<span id = "concept 8-32" > ▲ </span>**[选择性集成(selective emsemble)(191)](#chapter 8)** : 对并行化集成的修剪亦称“选择性集成”，但现在一般将选择性集成用作集成修剪的同义语，亦称集成选择(ensemble selection)。



## 聚类

<span id = "concept 9-0" > ▲ </span>**[有效性指标(197)](#chapter 9)** : 聚类性能度量，即评估其好坏的性能度量。聚类性能度量分为两类，外部指标和内部指标。


<span id = "concept 9-1" > ▲ </span>**[距离度量(199)](#chapter 9)** : 用于衡量点和点之间的距离，常用的有欧氏、曼哈顿、切比雪夫。最常用的是闵可夫斯基距离：  

  $dist_{mk}(x_i,x_j)={\left( \sum_{u=1}^{n}\left|x_{iu}-x_{ju} \right|^p\right)}^{\frac{1}{p}}$

<span id = "concept 9-2" > ▲ </span>**[街区距离(200)](#chapter 9)** : 闵可夫斯基距离$p=1$时即曼哈顿距离，又称街区距离: $dist_{man}(x_i,x_j)={\parallel x_i-x_j\parallel }_{1} =\sum_{u=1}^{n}\left|x_{iu}-x_{ju} \right|$


<span id = "concept 9-3" > ▲ </span>**[离散属性(200)](#chapter 9)** : 定义域上有限个取值，比如{西瓜，哈密瓜，木瓜}。


<span id = "concept 9-4" > ▲ </span>**[连续属性(200)](#chapter 9)** : 定义域上可以取无限个取值，如实数。


<span id = "concept 9-5" > ▲ </span>**[列名属性(200)](#chapter 9)** : “离散属性”也称“列名属性”，见“离散属性”。


<span id = "concept 9-6" > ▲ </span>**[曼哈顿距离(200)](#chapter 9)** : 同“街区距离”。


<span id = "concept 9-7" > ▲ </span>**[闵可夫斯基距离(200,220)](#chapter 9)** : 见“距离度量”。


<span id = "concept 9-8" > ▲ </span>**[欧氏距离(200)](#chapter 9)** : 闵可夫斯基距离$p=2$时即欧氏距离：  

  $dist_{ed}(x_i,x_j)={\parallel x_i-x_j\parallel }_{2} =\sqrt{\sum_{u=1}^{n}\left|x_{iu}-x_{ju} \right|^2}$

<span id = "concept 9-9" > ▲ </span>**[切比雪夫距离(200)](#chapter 9)** : 闵可夫斯基距离当$p\rightarrow \infty$时即切比雪夫距离。


<span id = "concept 9-10" > ▲ </span>**[数值属性(200)](#chapter 9)** : 见“连续属性”。


<span id = "concept 9-11" > ▲ </span>**[无序属性(200)](#chapter 9)** : 不能直接在属性值上计算距离。


<span id = "concept 9-12" > ▲ </span>**[有序属性(200)](#chapter 9)** : 可以直接在属性值上计算距离。


<span id = "concept 9-13" > ▲ </span>**[非度量距离(201)](#chapter 9)** : 不满足直递性的距离。


<span id = "concept 9-14" > ▲ </span>**[混合属性(201)](#chapter 9)** : 存在有序属性和无序属性。


<span id = "concept 9-15" > ▲ </span>**[加权距离(201)](#chapter 9)** : 即给每个距离加权重。


<span id = "concept 9-16" > ▲ </span>**[相似度度量(201)](#chapter 9)** : 对两个事物之间相似程度的综合性度量。


<span id = "concept 9-17" > ▲ </span>**[距离度量学习(201,237)](#chapter 9)** : 度量学习(Metric Learning)是常说的相似度学习，距离度量学习则是选定距离计算式来进行度量。


<span id = "concept 9-18" > ▲ </span>**[原型聚类(202)](#chapter 9)** : 基于原型的聚类，著名的几种方法包括k均值算法、学习向量量化和高斯混合聚类等。


<span id = "concept 9-19" > ▲ </span>**[k均值算法(202,218)](#chapter 9)** : 针对聚类所得的簇，同类样本的最小均方误差。



<span id = "concept 9-20" > ▲ </span>**[学习向量化(Learning Vector Quantization, LVQ)(204,218)](#chapter 9)** : 指通过找到一组原型向量来刻画聚类结构，每个原型向量代表一个聚类簇。


<span id = "concept 9-21" > ▲ </span>**[概率模型(206,319)](#chapter 9)** : 概率模型是将学习归结为计算变量的概率分布的一种描述。


<span id = "concept 9-22" > ▲ </span>**[高斯混合(206,296)](#chapter 9)** : 高斯混合是用高斯概率密度函数去量化，将变量/事物分解为若干个高斯密度函数的模型。


<span id = "concept 9-23" > ▲ </span>**[密度聚类(211)](#chapter 9)** : 基于密度的聚类，即是通过事物的紧密程度去聚类。如DBSCAN算法。


<span id = "concept 9-24" > ▲ </span>**[层次聚类(214)](#chapter 9)** : 通过不同层次对数据集进行划分，得到的是树形聚类结构。可采用“自顶向下”的分拆策略，也可用“自底向上”的聚合策略。著名的AGNES是自底向上聚合的层次聚类算法。


<span id = "concept 9-25" > ▲ </span>**[聚类集成(219)](#chapter 9)** : 对原始数据集的多个聚类器进行集成。可有效降低聚类过程中的随机性和聚类假设不符等因素的影响。


<span id = "concept 9-26" > ▲ </span>**[异常检测(219)](#chapter 9)** : 异常检测常借助聚类或距离计算，如将离心或密度极低的点作为异常点。


<span id = "concept 9-27" > ▲ </span>**[豪斯多夫距离(220)](#chapter 9)** : Hausdorff distance： $dist_H(X, Z) = \max (dist_h(X, Z), dist_h(Z, X))$ 其中 $dist_h(X, Z) = \max \limits_{x\in X} \min \limits_{z\in Z}\left \| x-z \right \|_2$



## 降维与度量学习

<span id = "concept 10-0" > ▲ </span>**[k近邻(225)](#chapter 10)** : k近邻是常用的监督学习方法，主要是用某种距离度量方法来找出与测试样本最靠近的k个点，根据这k位邻居的信息来预测其分类。是“懒惰学习”。


<span id = "concept 10-1" > ▲ </span>**[急切学习(225)](#chapter 10)** : 这种学习方法在训练阶段就对样本进行学习处理。


<span id = "concept 10-2" > ▲ </span>**[平均法(225)](#chapter 10)** : 将这k个样本的实值的平均值作为预测的输出。


<span id = "concept 10-3" > ▲ </span>**[最近邻分类器(225)](#chapter 10)** : k=1，即是最近邻分类器。


<span id = "concept 10-4" > ▲ </span>**[密采样(226)](#chapter 10)** : 训练样本的采样密度足够大，保证任意小的距离内都能找到一个训练样本，即为“密采样”。


<span id = "concept 10-5" > ▲ </span>**[多维缩放(227)](#chapter 10)** : 多维缩放是指多维空间的样本转换到低维空间上，能够继续保持其距离。


<span id = "concept 10-6" > ▲ </span>**[降维(227)](#chapter 10)** : 通过数学变换将高维空间投射到低维子空间。


<span id = "concept 10-7" > ▲ </span>**[维数约简(227)](#chapter 10)** : 即降维。

<span id = "concept 10-8" > ▲ </span>**[维数灾难(227,247)](#chapter 10)** : 即高维情况下带来的距离计算量大、样本稀疏等问题，比如随着维度增加，计算量会呈指数增长的趋势。


<span id = "concept 10-9" > ▲ </span>**[PCA(229)](#chapter 10)** : PCA(Principal Component Analysis，即主成分分析)，可从最近重构性和最大可分性来思考PCA。


  最近重构性则是希望样本点到超平面的距离足够小，优化目标是$\min_W -tr(W^TXX^TW)$ $s.t. W^TW=I$

  最大可分性则是希望样本点在该超平面的投影尽可能分开，优化目标是$\max_W tr(W^TXX^TW)$ $s.t. W^TW=I$

  PCA的步骤是对所有样本进行中心化，然后计算协方差矩阵，再对协方差矩阵做特征值分解，然后取最大的d'个特征值所对应的特征向量。

<span id = "concept 10-10" > ▲ </span>**[线性降维(229)](#chapter 10)** : 基于线性变换来进行降维的方法。


<span id = "concept 10-11" > ▲ </span>**[主成分分析(229)](#chapter 10)** : 同PCA。


<span id = "concept 10-12" > ▲ </span>**[奇异值分解(231,402)](#chapter 10)** : 任意的实矩阵都可以进行分解，

  如$A\in \mathbb{R}^{m\times n}$可以分解为$A=U\Sigma V^T$,其中U是m×m阶酉矩阵；Σ是半正定m×n阶对角矩阵；而$V^T$，即V的共轭转置，是n×n阶酉矩阵。$u\_i$称为A的左奇异值，$v_i$称为A的右奇异值。Σ对角线上的元素为A的奇异值。矩阵A的秩是非零奇异值的个数。

<span id = "concept 10-13" > ▲ </span>**[本真低维空间(232)](#chapter 10)** : 对原始低维空间和降维后的低维空间进行区分，称原始采样的低维空间为本真低维空间。


<span id = "concept 10-14" > ▲ </span>**[非线性降维(232)](#chapter 10)** : 非线性降维即是采用非线性变换的方法对数据进行降维，常用的是基于核技巧对线性降维方法进行核化。


<span id = "concept 10-15" > ▲ </span>**[核化线性降维(232)](#chapter 10)** : 对线性降维方法进行核化，以保持其原本的低维结构。


<span id = "concept 10-16" > ▲ </span>**[核主成分分析(232)](#chapter 10)** : Kernelized PCA，

  在高维特征空间将数据投影到由d维的W确定的超平面上，z是x在高维空间上的像，假设$z_i=\phi (x_i)$，引入核函数$\kappa (x_i,x_j)=\phi(x_i)^T\phi(x_j)$，进一步用矩阵K替代，进而计算出投影矩阵。主要作用是将线性不可分的数据，映射到高维后进行划分。

<span id = "concept 10-17" > ▲ </span>**[本真距离(234)](#chapter 10)** : 即为在原始空间上的距离。


<span id = "concept 10-18" > ▲ </span>**[测地线距离(234)](#chapter 10)** : 测地线距离是两点之间的本真距离。


<span id = "concept 10-19" > ▲ </span>**[等度量映射(234)](#chapter 10)** : 等度量映射认为高维空间的直线距离不能很好地衡量其距离，所以等度量映射试图让“流形”距离在降维后仍能很好保持。


<span id = "concept 10-20" > ▲ </span>**[流形学习(234)](#chapter 10)** : 流形是在局部与欧式空间同胚的空间，所以局部可以利用欧氏距离来计算。


<span id = "concept 10-21" > ▲ </span>**[局部线性嵌入(235)](#chapter 10)** : 保持邻域内样本的线性关系的一种方法。


<span id = "concept 10-22" > ▲ </span>**[度量学习(237)](#chapter 10)** : 通过学习，得到合适的距离度量方法。


<span id = "concept 10-23" > ▲ </span>**[近邻成分分析(238)](#chapter 10)** : NCA(Neighbourhood Component Analysis，即近邻成分分析)是和KNN关联的距离度量方法，

  在原数据集上进行NCA距离测量，并且完成降维，然后使用KNN在低维空间上对数据进行分类。NCA主要是随机选择近邻，然后通过LOO(Leave one out)的交换检验结果来求马氏距离的变换矩阵。通过优化目标可以得到最大化正确率的距离度量矩阵。

<span id = "concept 10-24" > ▲ </span>**[必连约束(239,307)](#chapter 10)** : 样本必属于一个簇。


<span id = "concept 10-25" > ▲ </span>**[勿连约束(239)](#chapter 10)** : 样本必不属于同一个簇。


<span id = "concept 10-26" > ▲ </span>**[半监督聚类(240,307)](#chapter 10)** : 半监督聚类的先验知识主要是样本相似度约束条件，将必连关系和勿连关系作为学习任务优化目标的约束。约束条件主要是基于约束和基于距离。前者主要是依靠用户提供的约束来实现监督指导作用，后者主要是自适应距离度量。


<span id = "concept 10-27" > ▲ </span>**[多视图学习(240)](#chapter 10)** : 多视图学习可以看成是从多个角度去学习，比如对同一个事物用多种方法去提取其特征，就能得到其多模态的特征，然后再对多模态特征进行学习。


<span id = "concept 10-28" > ▲ </span>**[流形假设(240,294)](#chapter 10)** : 流行假设是指在很小的一个领域内的样本具有相似的特性，则其标签也相似。


<span id = "concept 10-29" > ▲ </span>**[流形正则化(240)](#chapter 10)** : 在正则化项加入与流形相关的项。




## 特征选择与稀疏学习

<span id = "concept 11-0" > ▲ </span>**[冗余特征(redundant feature)(247)](#chapter 11)** : 在特征选择过程中，有一类特征所包含的信息能从其他特征中推演出来，这类特征成为『冗余特征』。  

  例如，考虑立方体对象，若已有特征『底面长』、『底面宽』，则『底面积』是冗余特征，因为它能从『底面长』和『底面宽』得到。  
  冗余特征很多时候不起作用，去除它们会减轻学习过程的负担。但有时又会降低学习任务的难度。例如若学习目标是估算立方体的体积，则『底面积』这个冗余特征的存在将使得体积的估算更加容易；确切地说，若某个冗余特征恰好对应了完成学习任务所需的『中心概念』，则该冗余特征是有益的。

<span id = "concept 11-1" > ▲ </span>**[数据预处理(data preprocessing)(247)](#chapter 11)** : 现实世界中数据大体上都是不完整、不一致的脏数据，无法直接进行数据挖掘，或挖掘结果差强人意。为了提高数据挖掘的质量产生了数据预处理技术。它是指在主要的处理以前对数据进行的一些处理。  

  数据预处理有多种方法：数据清理，数据集成，数据变换，数据归约等。在现实机器学习任务中，特征选择也是一个重要的数据预处理过程。

<span id = "concept 11-2" > ▲ </span>**[特征选择 & 相关特征(feature selection & relevant feature)(247)](#chapter 11)** : 对一个学习任务，给定的属性集称为特征。对当前学习任务有用的属性称为『相关特征』，没什么用的属性称为『无关特征』。从给定的特征中选出相关特征子集的过程，称为特征选择。


<span id = "concept 11-3" > ▲ </span>**[相关特征(relevant feature)(247)](#chapter 11)** : 见特征选择。


<span id = "concept 11-4" > ▲ </span>**[子集搜索(subset search)(248)](#chapter 11)** : 从特征集合中选取包含所有重要信息的特征子集，若没有任何领域知识作为先验，就只能遍历所有可能的子集。而这会遭遇组合爆炸问题导致计算不可行。可行的办法是产生一个『候选子集』，评价出它的好坏，基于评价结果产生下一个候选子集，再评价，……直到无法找到更好的候选子集为止。而产生候选子集的过程就是子集搜索。  

  具体而言，给定特征集合 ${a_1, a_2, ...., a_d}$, 可以将每个特征看作一个候选子集，对这 $d$ 个候选单特征子集进行评价，假定 ${a_2}$ 最优，于是将 ${a_2}$ 作为第一轮的选定集；然后，加入一个特征，构成包含两个特征的候选子集，假定在这 $d-1$ 个候选两特征子集中 ${a_2, a_4}$ 最优，且优于 ${a_2}$，于是将 ${a_2, a_4}$ 作为本轮选定集；直至最优的候选特征子集不如上一轮的选定集，则停止生成候选子集，并将上一轮的选定集作为特征选择结果。  
  逐渐增加相关特征的策略称为『前向』搜索；类似的，逐渐减少特征的策略称为『后向』搜索；前向与后向搜索结合起来的策略称为『双向』搜索。

<span id = "concept 11-5" > ▲ </span>**[子集评价(subset evaluation)(248)](#chapter 11)** : 由于子集搜索过程仅考虑了本轮选定集最优，无法解决这样的问题：例如在第三轮假定选择 ${a_5}$ 优于 ${a_6}$，于是选定集为 ${a_2, a_4, a_5}$，然而在第四轮却可能是 ${a_2, a_4, a_6, a_8}$ 比所有的 ${a_2, a_4, a_5, a_i}$ 都更优。  

  通过对每个候选特征子集，基于训练数据集计算其信息增益，以此作为评价准则。这一过程称为子集评价。  
  具体而言，给定数据集 $D$，假定 $D$ 中第 $i$ 类样本(假定样本属于离散型)所占的比例为 $p_i(i = 1,2,...,|y|)$。对属性子集 $A$，假定根据其取值将 $D$ 分成了 $V$ 个子集 ${D^1, D^2, ..., D^V}$，每个子集中的样本在 $A$ 上取值相同，于是属性子集 $A$ 的信息增益为：  
  $Gain(A) = Ent(D) - \sum_{v=1}^{V} \frac {|D^v|}{|D|} Ent(D^v)$，  
  其中信息熵定义为：  
  $Ent(D) = -\sum_{i=1}^{|y|} p_k log_2 p_k$，  
  信息增益 $Gain(A)$ 越大，意味着特征子集 $A$ 包含的有助于分类的信息越多。  
  更一般的，特征子集 $A$ 实际上确定了对数据集 $D$ 的一个划分，每个划分区域对应着 $A$ 上的一个取值，而样本标记信息 $Y$ 则对应着对 $D$ 的真实划分，通过估算这两个划分的差异，就能对 $A$ 进行评价。与 $Y$ 对应的划分的差异越小，则说明 $A$ 越好。

<span id = "concept 11-6" > ▲ </span>**[过滤式(filter)特征选择(249)](#chapter 11)** : 常见的特征选择方法之一。先对数据集进行特征选择，然后再训练学习器，特征选择过程与后续学习器无关。相当于先用特征选择过程对初始特征进行『过滤』，再用过滤后的特征来训练模型。  

  Relif 是一种著名的过滤式特征选择方法，该方法设计了一个『相关统计量』来度量特征的重要性。该统计量是一个向量，其每个分量分别对应于一个初始特征，而特征子集的重要性则是由子集中每个特征所对应的相关统计量分量之和来决定。最终只需指定一个阈值，然后选择比阈值大的相关统计量分量即可。也可指定欲选取的特征个数 $k$，然后选择相关统计量分量最大的 $k$ 个特征。时间开销岁采样次数以及原始特征数线性增长，是一个运行效率很高的过滤式特征选择算法。

<span id = "concept 11-7" > ▲ </span>**[包裹式(wrapper)特征选择(250)](#chapter 11)** : 常见的特征选择方法之一。直接把最终将要使用的学习器的性能作为特征子集的评价准则。它的目的就是为给定学习器选择有利于其性能、『量身定做』的特征子集。  

  LVW(Las Vegas Wrapper)是一个典型的包裹式特征选择方法。它在拉斯维加斯方法框架下使用随机策略来进行子集搜索，并以最终分类器的误差为特征子集评价准则。计算开销很大，且有可能运行很长时间达不到停止条件。

<span id = "concept 11-8" > ▲ </span>**[拉斯维加斯方法(Las Vegas method)(251)](#chapter 11)** : 是一种在电脑运算中永远给出正确解的随机化算法；也就是说，它总是给出正确结果，或是返回失败。 换言之，拉斯维加斯算法不赌结果的正确性，而是赌运算所用资源。它的一个显著特征是它所作的随机性决策有可能导致算法找不到所需的解。一个简单的例子是随机快速排序，他的中心点虽然是随机选择的，但排序结果永远一致。


<span id = "concept 11-9" > ▲ </span>**[蒙特卡洛方法(Monte Carlo method)(251,340,384)](#chapter 11)** : 也称统计模拟方法，是二十世纪四十年代由于科学技术的发展和电子计算机的发明，而提出的一种以概率统计理论为指导、使用随机数来解决问题的数值计算方法。


<span id = "concept 11-10" > ▲ </span>**[LASSO(252,261)](#chapter 11)** : 全称 Least Absolute Shrinkage and Selection Operator，对目标损失函数引入 $L_1$ 正则化项，即采用 $L_1$ 范数时，目标损失函数称为 LASSO，如式所示：  

  $min_w \sum_{i=1}^m (y_i - w^Tx_i)^2 + \lambda ||w||_1$

<span id = "concept 11-11" > ▲ </span>**[Tikhonov 正则化(L2 正则化)(252)](#chapter 11)** : 当样本特征很多，而样本数相对较少时，要优化的目标损失函数很容易陷入过拟合。为了缓解过拟合问题，对目标损失函数引入正则化项。Tikhonov 正则化(L2 正则化)就是使用 $L_2$ 范数正则化，即：$||w||_2^2$。


<span id = "concept 11-12" > ▲ </span>**[岭回归(ridge regression)(252)](#chapter 11)** : 引入 Tikhonov 正则化项(L2 正则化项)的目标损失函数称为岭回归，如式所示：  

  $min_w \sum_{i=1}^m (y_i - w^Tx_i)^2 + \lambda ||w||^2_2$

<span id = "concept 11-13" > ▲ </span>**[嵌入式(embedding)特征选择(252)](#chapter 11)** : 将特征选择过程与学习器训练过程融为一体，两者在同一个优化过程中完成，即在学习器训练过程中自动地进行了特征选择。


<span id = "concept 11-14" > ▲ </span>**[L1 正则化(253)](#chapter 11)** : 为了缓解过拟合问题，对目标损失函数引入正则化项。L1 正则化就是使用 $L_1$ 范数正则化，即：$||w||_1$。


<span id = "concept 11-15" > ▲ </span>**[L2正则化(253)](#chapter 11)** : 见 Tikhonov 正则化。


<span id = "concept 11-16" > ▲ </span>**[Lipschitz 条件(253)](#chapter 11)** : 在使用近端梯度下降对 L1 正则化问题求解时，对优化目标：$min_x f(x) + \lambda \lVert x \rVert_1$，若 $f(x)$ 可导，微分算子 $\nabla f$ 满足 L-Lipschitz 条件，即存在常数 $L>0$ 使得：  

  $\lVert \nabla f(x^{'})-\nabla f(x) \rVert_2^2 \leqslant L \lVert x^{'} - x \rVert_2^2 \quad (\forall x,x^{'})$ 在 $x_k$ 附近可将 $f(x)$ 通过二阶泰勒展开式近似为：  
  $f(x)^{*} \backsimeq f(x_k) + \langle \nabla f(x_k), x-x_k \rangle + \frac {L}{2}\lVert x - x_k \rVert^2$  
  L-Lipschitz 条件是指：对于在实数集的子集的函数 $f: D \subseteq \mathbb{R} \to \mathbb{R}$，若存在常数 $K$，使得 $\lvert f(a)-f(b)\rvert \leqslant K\lvert a-b\rvert \quad \forall a,b \in D$，则称 $f$ 符合 L-Lipschitz 条件，对于 $f$ 最小的常数 $K$ 称为 $f$ 的 L-Lipschitz 常数。

<span id = "concept 11-17" > ▲ </span>**[近端梯度下降(Proximal Gradient Descent)(253,259)](#chapter 11)** : 在引入 L1 正则项的目标损失函数：  

  $min \quad f(x) + \lambda \lVert x \rVert_1$  
  会遇到求导问题(L1 范数在 $x=0$ 处不可导)，若 $f(x)$ 可导，微分算子 $\nabla f$ 满足 L-Lipschitz 条件，在 $x_k$ 附近可将 $f(x)$ 通过二阶泰勒展开式近似为：  
  $f(x)^{*} \backsimeq f(x_k) + \langle \nabla f(x_k), x-x_k \rangle + \frac {L}{2}\lVert x - x_k \rVert^2$  
  $= \frac {L}{2} \lVert x - \lgroup x_k - \frac {1}{L} \nabla f(x_k) \rgroup \rVert_2^2 + const$，  
  其中 const 是与 $x$ 无关的常数，$\langle .,. \rangle$ 表示内积，上式最小值在如下 $x_{k+1}$ 获得：  
  $x_{k+1} = x_k - \frac {1}{L} \nabla f(x_k)$，  
  若通过梯度下降法对 $f(x)$ 最小化，则每一步梯度下降迭代实际上等价于最小化 $f(x)^{*}$，类似得到每一步迭代应为：  
  $x_{k+1} = arg\ min_x \frac {L}{2} \lVert x - \lgroup x_k - \frac {1}{L} \nabla f(x_k) \rgroup \rVert_2^2 + \lambda \lVert x \rVert_1$，  
  即在每一步对 $f(x)$ 进行梯度下降迭代的同时考虑 L1 范数最小化。  
  这种近似求解的方法称为近端梯度下降(Proximal Gradient Descent)。

<span id = "concept 11-18" > ▲ </span>**[码书学习 & 字典学习(codebook & dictionary learning)(255)](#chapter 11)** : 为普通稠密表达的样本找到合适的字典，将样本转化为合适的稀疏表示形式，从而使学习任务得以简化，模型复杂度得以降低，通常称为字典学习，亦称为码书学习。字典学习侧重于学得字典的过程。给定数据集 ${x_1,x_2,..,x_m}$，字典学习最简单的形式为：  

  $min_{\bf{B, \alpha_i}} \sum_{i=1}^m \lVert x_i - \bf{B \alpha_i} \rVert_2^2 + \lambda \sum_{i=1}^m \lVert \bf{\alpha_i} \rVert_1$，  
  其中 $\bf{B} \in \mathbb{R}^{d \times k}$ 为字典矩阵，$k$ 称为字典的词汇量，通常由用户指定，$\bf{\alpha_i} \in \mathbb{R}^k$ 则是样本 $\bf{x_i} \in \mathbb{R}^d$ 的稀疏表示。

<span id = "concept 11-19" > ▲ </span>**[稀疏编码(sparse coding)(255)](#chapter 11)** : 字典学习亦称为稀疏编码，后者更侧重于对样本进行稀疏表达的过程。两者通常在同一个优化求解过程中完成。


<span id = "concept 11-20" > ▲ </span>**[字典学习(dictionary learning)(255)](#chapter 11)** : 同码书学习。


<span id = "concept 11-21" > ▲ </span>**[压缩感知(compressed sensing)(257)](#chapter 11)** : 压缩感知(Compressed sensing)，也被称为压缩采样(Compressive sampling)或稀疏采样(Sparse sampling)，是一种寻找欠定线性系统的稀疏解的技术。在现实任务中，我们常希望根据部分信息来恢复全部信息，压缩感知就是为处理此类问题提供了方法。  

  压缩感知关注如何利用信号本身所具有的稀疏性，从部分观测样本中恢复信号。通常认为，压缩感知分为感知测量和重构恢复两个阶段。

<span id = "concept 11-22" > ▲ </span>**[局部线性嵌入(Locally Linear Embedding) (259)](#chapter 11)** : 局部线性嵌入(Locally Linear Embedding)是一种非常重要的降维方法。和传统的 PCA，LDA 等关注样本方差的降维方法相比，LLE 关注于降维时保持样本局部的线性特征，由于 LLE 在降维时保持了样本的局部特征，它广泛的用于图像图像识别，高维数据可视化等领域。

<span id = "concept 11-23" > ▲ </span>**[协同过滤(collaborative filtering)(259)](#chapter 11)** : 利用某兴趣相投、拥有共同经验之群体的喜好来推荐使用者感兴趣的资讯，个人通过合作的机制给予资讯相当程度的回应(如评分)并记录下来以达到过滤的目的进而帮助别人筛选资讯，回应不一定仅限于特别感兴趣的，特别不感兴趣资讯的记录也相当重要。分为以使用者为基础的协同过滤、以项目为基础的协同过滤和以模型为基础的协同过滤。


<span id = "concept 11-24" > ▲ </span>**[核范数 & 迹范数(nuclear norm & trace norm)(260)](#chapter 11)** : 矩阵奇异值之和。


<span id = "concept 11-25" > ▲ </span>**[迹范数(trace norm)(260)](#chapter 11)** : 同核范数。




## 计算学习理论

<span id = "concept 12-0" > ▲ </span>**[计算学习理论(computational learning theory)(267)](#chapter 12)** : 计算学习理论研究的是关于通过“计算”来进行“学习”的理论，即关于机器学习的理论基础，其目的是分析学习任务的困难本质，为学习算法提供理论保证，并根据分析结果指导算法设计。


<span id = "concept 12-1" > ▲ </span>**[Jensen不等式(268)](#chapter 12)** : $f(\mathbb{E}(x)) \leqq \mathbb{E}(f(x))$


  期望的函数小于函数的期望

<span id = "concept 12-2" > ▲ </span>**[Hoeffding不等式(268)](#chapter 12)** : 若$x_1,x_2,...,x_m$为$m$个独立随机变量，且满足$0\leqq x_i\leqq 1$，则对于任意$\epsilon\geqq 0$有： $P(\frac{1}{m}\sum_{i=1}^{m}x_i-\frac{1}{m}\sum_{i=1}^m\mathbb{E}(x_i)\geqq \epsilon)\leqq exp(-2m\epsilon^2)$ $P(\mid \frac{1}{m}\sum_{i=1}^{m}x_i-\frac{1}{m}\sum_{i=1}^m\mathbb{E}(x_i)\mid \geqq \epsilon)\leqq 2exp(-2m\epsilon^2)$


<span id = "concept 12-3" > ▲ </span>**[McDiarmid 不等式(268)](#chapter 12)** : 若$x_1,x_2,...,x_m$为$m$个独立随机变量，且对任意$1\leqq i\leqq m$，函数$f$满足


  $\sum_{x_1,x_2,...,x_m, x^{'}_i } |f(x_1,...,x_m) - f(x_1, ... , x_{i-1}, x^{'}_i, x_{i+1}, ..., x_m)| \leqq c_i$，

  则对任意$\epsilon\geqq 0$，有 $P(f(x_1,...,x_m)-E(f(x_1,...,x_m))\geqq \epsilon)\leqq exp(\frac{-2\epsilon^2}{\sum_i c_i^2})$ $P(\mid f(x_1,...,x_m)-E(f(x_1,...,x_m))\mid \geqq \epsilon)\leqq exp(\frac{-2\epsilon^2}{\sum_i c_i^2})$

<span id = "concept 12-4" > ▲ </span>**[概率近似正确(268)](#chapter 12)** : 略

<span id = "concept 12-5" > ▲ </span>**[概念类(concept class)(268)](#chapter 12)** : 令c表示概念，这是从样本空间$\mathcal{X}$到标记空间$\mathcal{Y}$的映射，它决定示例x的真实标记y，若对任何样例(x,y)有c(x)=y成立，则称c为目标概念，所有我们希望学得的目标概念所构成的集合称为概念类，用符号$\mathcal{C}$表示。


<span id = "concept 12-6" > ▲ </span>**[假设空间(hypothesis space)(268)](#chapter 12)** : 给定学习算法$\mathfrak{L}$，它所考虑的所有可能概念的集合称为“假设空间”，用符号$\mathcal{H}$表示。由于学习算法事先并不知道概念类的真实存在，因此假设空间和概念类往往不同。


<span id = "concept 12-7" > ▲ </span>**[PAC辨识(PAC Identify)(269)](#chapter 12)** : 对于$0<\epsilon, \delta<1$，所有$c\in\mathcal{C}$和分布$\mathcal{D}$，若存在学习算法$\mathfrak{L}$，其输出假设$h\in\mathcal{H}$满足


  $P(E(h)\leqq \epsilon)\geqq 1-\delta$

  则称学习算法$\mathfrak{L}$能从假设空间$\mathcal{H}$中PAC辨识概念类$\mathcal{C}$，这样的学习算法$\mathfrak{L}$能从假设空间$\mathcal{H}$中PAC辨识概念类$\mathcal{C}$.

<span id = "concept 12-8" > ▲ </span>**[PAC可学习(PAC Learnable)(269)](#chapter 12)** : 令$m$表示从分布$\mathcal{D}$中独立同分布采样得到的样例数目，$0<\epsilon,\delta<1$，对所有分布$\mathcal{D}$，若存在学习算法$\mathfrak{L}$和多项式函数$poly(.,.,.,.)$，使得对于任何$m\geqq poly(1/\epsilon,1/\delta,size(x),size(c))$, $\mathfrak{L}$能从假设空间$\mathcal{H}$中PAC辨识概念类$\mathcal{C}$，则称概念类$\mathcal{C}$对假设空间$\mathcal{H}$而言是PAC可学习的，也简称概念类$\mathcal{C}$是PAC可学习的。对于计算机算法来说，必须考虑时间复杂度，于是：


<span id = "concept 12-9" > ▲ </span>**[PAC学习算法(PAC Learning Algorithm)(270)](#chapter 12)** : 若学习算法$\mathfrak{L}$使概念类$\mathcal{C}$为PAC可学习的，且$\mathfrak{L}$的运行时间也是多项式函数$poly(1/\epsilon,1/\delta,size(x),size(c))$，则称概念类$\mathcal{C}$是高效PAC可学习的，称$\mathfrak{L}$为概念类$\mathcal{C}$的PAC学习算法。


<span id = "concept 12-10" > ▲ </span>**[时间复杂度(269)](#chapter 12)** : 假定学习算法$\mathfrak{L}$处理每个样本的时间为常数，则$\mathfrak{L}$的时间复杂度等价于样本复杂度。


<span id = "concept 12-11" > ▲ </span>**[样本复杂度(270)](#chapter 12)** : 满足PAC学习算法$\mathfrak{L}$所需的$m\geqq poly(1/\epsilon,1/\delta,size(x),size(c))$中最小的m，称为学习算法$\mathfrak{L}$的样本复杂度。


<span id = "concept 12-12" > ▲ </span>**[不可分(non-seperable)(269,272)](#chapter 12)** : 对于较为困难的学习问题，目标概念$c$往往不存在于假设空间$\mathcal{H}$中，假定对于任何$h\in\mathcal{H}, \hat{E(h)}\neq0$，也就是说，$\mathcal{H}$中的任意一个假设都会在训练集上出现或多或少的错误。$\mathcal{H}$中不存在任何假设能将所有示例完全正确分开，则称该问题对于学习算法$\mathfrak{L}$是不可分的，亦称不一致的。


<span id = "concept 12-13" > ▲ </span>**[不一致(non-consistent)(269)](#chapter 12)** : 即不可分。


<span id = "concept 12-14" > ▲ </span>**[可分(seperable)(269,270)](#chapter 12)** : 可分情形意味着目标概念$c$属于假设空间$\mathcal{H}$， 即 $c\in\mathcal{H}$，$\mathcal{H}$中存在假设能将所有示例按与真实标记一致的方式完全分开，我们将该问题对学习算法$\mathfrak{L}$是可分的，亦称一致的。


<span id = "concept 12-15" > ▲ </span>**[恰PAC可学习(properly PAC learnable)(270)](#chapter 12)** : 若学习算法$\mathfrak{L}$使概念类$\mathcal{C}$为PAC可学习的，且$\mathfrak{L}$的运行时间也是多项式函数$poly(1/\epsilon, 1/\delta, size(x), size(c))$，则称概念类$\mathcal{C}$是高效PAC可学习的，称$\mathfrak{L}$为概念类$\mathcal{C}$的PAC学习算法。若在PAC学习中假设空间与概念类完全相同，称为恰PAC可学习，这意味着学习算法的能力与学习任务恰好匹配。


<span id = "concept 12-16" > ▲ </span>**[有限假设空间(270)](#chapter 12)** : 一般而言，$\mathcal{H}$越大，其包含任意目标概念的可能性越大，但从中找到某个具体概念的难度也越大，$|\mathcal{H}|$有限时，我们称$\mathcal{H}$为有限假设空间，否则称为“无限假设空间”。


<span id = "concept 12-17" > ▲ </span>**[不可知PAC可学习(agnostic PAC learnable)(273)](#chapter 12)** : 令$m$表示从分布$\mathcal{D}$中独立同分布采样得到的样例数目，$1<\epsilon, \delta < 1$，对所有分布$\mathcal{D}$，若存在学习算法$\mathcal{L}$和多项式函数$poly(.,.,.,.)$，使得对于任何$m\leqq poly(1/\epsilon, 1/\delta, size(x), size(c))$，$\mathfrak{L}$能从假设空间$\mathcal{H}$中输出满足$P(E(h)-min_{h^{'} \in \mathcal{H}})\leqq\epsilon\geqq 1 - \delta$的假设h,则称假设空间$\mathcal{H}$是不可知PAC可学习的。


<span id = "concept 12-18" > ▲ </span>**[增长函数(273)](#chapter 12)** : 给定假设空间$\mathcal{H}$和示例集$D={x_1, x_2, ..., x_m}$，$\mathcal{H}$中每个假设h都能对$D$中示例赋予标记，标记结果可表示为


  $h|_D = {h(x_1), h(x_2), ... , h(x_m)}$

  随着m的增大，$\mathcal{H}$中所有假设对D中的示例所能赋予标记的可能结果数也会增大。

  对所有$m\in\mathbb{N}$，假设空间$\mathcal{H}$的增长函数

  $\prod_{\mathcal{H}}(m)= max_{\{x_1, ..., x_m\subseteq \mathcal{H}\}}|\{h(x_1), h(x_2),..., h(x_m)|h\subseteq \mathcal{H}\}|$，

  表示假设空间$\mathcal{H}$对m个示例所能赋予标记的最大可能结果数，可能结果数越大，假设空间的表示能力越强，对学习任务的适应能力也越强，可以利用增长函数来估计经验误差与泛化误差之间的关系。

<span id = "concept 12-19" > ▲ </span>**[对分(273)](#chapter 12)** : 假设空间$\mathcal{H}$中不同的假设对于$\mathcal{D}$中示例赋予标记的结果可能相同，也可能不同；尽管$\mathcal{H}$可能包含无穷多个假设，但其对$\mathcal{D}$中示例赋予标记的可能结果是有限的。对m个示例，最多有$2^m$个可能结果，对二分类问题来说，$\mathcal{H}$中的假设对$\mathcal{D}$中示例赋予标记的每种可能结果称为对$\mathcal{D}$的一种对分。


<span id = "concept 12-20" > ▲ </span>**[打散(273)](#chapter 12)** : 若假设空间$\mathcal{H}$能实现示例集$\mathcal{D}$上的所有对分，即$\prod_{\mathcal{H}}(m)=2^m$，则称示例集$\mathcal{D}$能被假设空间$\mathcal{H}$打散。


<span id = "concept 12-21" > ▲ </span>**[VC维(273,274)](#chapter 12)** : 假设空间的VC维是能被$\mathcal{H}$打散的最大示例集的大小，即$VC(\mathcal{H})=max{m: \prod_{\mathcal{H}}(m)=2^m}$，可用于度量假设空间的复杂度。


<span id = "concept 12-22" > ▲ </span>**[经验风险最小化(Empirical Risk Minimization, ERM)(278)](#chapter 12)** : 令h表示学习算法$\mathfrak{L}$输出的假设，若$h$满足$\hat{E}(h)=min_{h'}$，则称$\mathfrak{L}$为满足经验风险最小化原则的算法。


<span id = "concept 12-23" > ▲ </span>**[Rademacher复杂度(279)](#chapter 12)** : 经验误差最小的假设是


  $argmax_{h\in\mathcal{H}}\frac{1}{m}\sum_{i=1}^m y_i h(x_i)$，

  然而现实任务中的标记y有时候会收到噪声影响，不再是真实标记，再此情形下，选择假设空间$\mathcal{H}$中在训练集上表现最好的假设，有时还不如选择$\mathcal{H}$中事先考虑了随机噪声影响的假设。考虑随机变量$\sigma_i$，它以0.5的概率取值-1,0.5的概率取值+1，称为Rademacher随机变量，基于$\sigma_i$可将上式改写为

  $sup_{h\in\mathcal{H}}\frac{1}{m}\sum^m_{i=1}\sigma_i h(x_i)$,

  期望为

  $\mathbb{E}_{\sigma}[sup_{h\in\mathcal{H}}\sum_{i=1}^m \sigma_ih(x_i)]$，

  考虑实值函数空间 $\mathcal{F}:\mathcal{Z}\rightarrow\mathcal{R}$， 令$Z={z_1,z_2,...,z_m}$，

  其中$z_i\in\mathcal{Z}$, 将$\mathcal{X}$和$\mathcal{H}$替换成$Z$和$F$可得，函数空间$\mathcal{Z}$g关于$\mathcal{F}$的经验Rademacher复杂度

  $\hat{R}_Z(\mathcal{F})=\mathbb{E}_{\sigma}[sup_{f\in\mathcal{F}}\frac{1}{m}\sum_{i=1}^m\sigma_i f(z_i)]$，

  其衡量了函数空间$\mathcal{F}$与随机噪声在集合$\mathcal{Z}$中的相关性。对所有从$\mathcal{D}$独立同分布采样而得的大小为m的集合Z求期望可得函数空间$\mathcal{F}$关于上$\mathcal{Z}$分布的$\mathcal{D}$Rademacher复杂度。

<span id = "concept 12-24" > ▲ </span>**[稳定性(284)](#chapter 12)** : 算法在输入发生变化时，输出是否会随之发生较大的变化。


<span id = "concept 12-25" > ▲ </span>**[均匀稳定性(285)](#chapter 12)** : 对任何$x\in\mathcal{X},z=(x,y)$，若学习算法$\mathcal{L}$满足


  $|l(\mathcal{L}_D, z) - l(\mathcal{L}_{D_i},z)|\leqq\beta$，

  则称$\mathcal{L}$关于损失函数$l$满足$\beta$均匀稳定性。

  其中l为泛化损失，$D_i$为移除$D$中第i个样例得到的集合。



## 半监督学习

<span id = "concept 13-0" > ▲ </span>**[半监督学习(semi-supervised learning)(293,294)](#chapter 13)** : 使用未标记样本进行学习


<span id = "concept 13-1" > ▲ </span>**[查询(query)(293)](#chapter 13)** : 向专家寻求标记的过程。


<span id = "concept 13-2" > ▲ </span>**[未标记样本(unlabeled sample)(293)](#chapter 13)** : 类别标记未知的样本


<span id = "concept 13-3" > ▲ </span>**[有标记样本(labeled sample)(293)](#chapter 13)** : 类别标记已知的样本


<span id = "concept 13-4" > ▲ </span>**[主动学习(active learning)(293)](#chapter 13)** : 先用已标记样本训练一个模型，拿这个模型进行预测，与专家交互进行标记，然后把这个新获得的有标记样本加入已标记样本集中重新训练一个模型，再去预测和标记，若每次都挑出对改善模型性能帮助大的样本，则只需进行较少的标记就能构建出比较强的模型，从而大幅降低标记成本，这样的学习方式成为“主动学习”，其目标是使用尽量少的“查询”来获得尽量好的性能。


  主动学习引入了额外的专家知识，通过与外界的交互来将部分未标记样本转变为有标记样本。

<span id = "concept 13-5" > ▲ </span>**[聚类假设(cluster assumption)(294)](#chapter 13)** : 假设数据存在簇结构，同一个簇的样本属于同一个类别，这是一种将未标记样本所揭示的数据分布信息与类别标记相联系的假设。


<span id = "concept 13-6" > ▲ </span>**[直推学习(transductive learning)(295)](#chapter 13)** : 假定学习估计差中所考虑的未标记样本恰是带预测数据，学习的目的就是在这些未标记样本上获得最优泛化性能。不同于纯半监督学习的基于开放世界假设，希望学得模型能适用于训练过程中未观察到的数据，直推学习是基于封闭世界假设，仅试图对学习过程中观察到的未标记数据进行预测。


<span id = "concept 13-7" > ▲ </span>**[S3VM(Semi-Supervised Support Vector Machine)(298)](#chapter 13)** : 支持向量机在半监督学习上的推广，在不考虑未标记样本时，支持向量机试图找到最大间隔划分超平面，在考虑未标记样本后，S3VM试图找到能将两类有标记样本分开，且穿过数据低密度区域的划分超平面，，这里的基本假设是“低密度分割”，显然，这是聚类假设在考虑了线性超平面划分后的推广。


<span id = "concept 13-8" > ▲ </span>**[半监督SVM(298)](#chapter 13)** : 同S3VM


<span id = "concept 13-9" > ▲ </span>**[图半监督学习(300)](#chapter 13)** : 给定一个数据集，我们可将其映射为一个图，数据集中每个样本对应于图中一个节点，若两个样本之间的相似度很高(或相关性很强)，则对应的结点之间存在一条边，边的“强度”正比于样本之间的相似度(或相关性)，将有标记样本所对应的节点想象为染过色，而未标记样本所对应的节点尚未染色，于是半监督学习就对应于“颜色”在图上扩散或传播的过程。由于一个图对应了一个矩阵，这就使得我们能基于矩阵运算来进行半监督学习算法的推导与分析。


<span id = "concept 13-10" > ▲ </span>**[亲和矩阵(affinity matrix)(301)](#chapter 13)** : 表达数据集中样本间相关性的矩阵。


<span id = "concept 13-11" > ▲ </span>**[标记传播(label propagation)(302)](#chapter 13)** : 根据已有标记，对未标记样本进行标记。


<span id = "concept 13-12" > ▲ </span>**[基于分歧的方法(304)](#chapter 13)** : 使用多学习器，学习器之间的分歧对未标记数据的利用至关重要。


<span id = "concept 13-13" > ▲ </span>**[协同训练(co-training)(304)](#chapter 13)** : 利用多视图的相容互补性，假设数据拥有两个充分且条件独立视图，“充分”是指每个视图都包含足以产生最优学习器的信息，“条件独立”是指在给定类别标记条件下两个视图独立，在此情形下，首先在每个视图上基于有标记样本分别训练处一个分类器，然后让每个分类器分别去挑选自己“最有把握的”未标记样本赋予伪标记，并将 样本提供给另一个分类器作为新增的有标记样本用于训练更新，这个过程不断迭代进行，直到两个分类器都不再发生变化，或达到预先设定的迭代轮数为止。




## 概率图模型(probabilistic model)

<span id = "concept 14-0" > ▲ </span>**[马尔科夫网(Markov network)(319)](#chapter 14)** : 使用无向图表示变量间的相关关系的概率图模型。 概率图模型是一类用图来表达变量相关关系的概率模型。它以图为表示工具，最常见的是用一个结点表示一个或一组随机变量，结点之间的边表示变量间的概率相关关系，即『变量关系图』。根据边的性质不同，概率图模型可大致分为两类：第一类是使用有向无环图表示变量间的依赖关系，称为有向图模型或贝叶斯网；第二类是使用无向图表示变量间的相关关系，称为无向图模型或马尔科夫网。


<span id = "concept 14-1" > ▲ </span>**[推断(319)](#chapter 14)** : 概率模型提供了一种描述框架，将学习任务归结于计算变量的概率分布。在概率模型中，利用已知变量推测未知变量的分布称为『推断』，其核心是如何基于可观测变量推测出未知变量的条件分布。


<span id = "concept 14-2" > ▲ </span>**[隐马尔科夫模型(Hidden Markov Model)(319)](#chapter 14)** : 隐马尔科夫(HMM)模型是结构最简单的动态贝叶斯网，主要用于时序数据建模，在语音识别、自然语言处理等领域有广泛应用。


<span id = "concept 14-3" > ▲ </span>**[马尔科夫随机场(Markov Random Field)(322)](#chapter 14)** : 马尔科夫随机场(MRF)是典型的马尔科夫网，一种著名的无向图模型。图中每个结点表示一个或一组变量，结点之间的边表示两个变量之间的依赖关系。


<span id = "concept 14-4" > ▲ </span>**[势函数(potential functions)(322)](#chapter 14)** : 同因子。


<span id = "concept 14-5" > ▲ </span>**[因子(factor)(322)](#chapter 14)** : 马尔科夫随机场有一组势函数，亦称『因子』，这是定义在变量子集上的非负实函数，主要用于定义概率分布函数。  

  对结点的一个子集，若任意两结点间都有边连接，则称该结点子集为一个『团』。在马尔科夫随机场中，多个变量之间的联合概率分布能基于团分解为多个因子的乘积，每个因子仅与一个团相关。

<span id = "concept 14-6" > ▲ </span>**[全局马尔科夫性(global Markov property)(323)](#chapter 14)** : 在马尔科夫随机场中得到『条件独立性』需要借助『分离』的概念。若从结点集 A 中的结点到 B 中的结点都必须经过结点集 C 中的结点，则称结点集 A 和 B 被结点集 C 分离，C 称为『分离集』。  

  全局马尔科夫性就是指给定两个变量子集的分离集，则这两个变量子集条件独立。  
  也就是说，若令 A，B 和 C 对应的变量集分别为 $X_A$，$X_B$，$X_C$，则 $X_A$ 和 $X_B$ 在给定 $X_C$ 的条件下独立，记为：$X_A \perp X_B \mid X_C$。

<span id = "concept 14-7" > ▲ </span>**[局部马尔科夫性(local Markov property)(324)](#chapter 14)** : 由全局马尔科夫性得出的推论之一。给定某变量的邻接变量，则该变量条件独立于其他变量。  

  形式化地说，令 $V$ 为图的结点集，$n(v)$ 为结点 $v$ 在图上的邻接结点，$n^*(v) = n(v) \cup \{v\}$，有 $X_v \perp X_{V \setminus{n}^*(v)} \mid X_n(v)$.  
  注：$\setminus$ 表示『非』

<span id = "concept 14-8" > ▲ </span>**[成对马尔科夫性(pairwise Markov property)(325)](#chapter 14)** : 由全局马尔科夫性得出的推论之一。给定所有其他变量，两个非邻接变量条件独立。


  形式化地说，令图的结点集和边集分别为 $V$ 和 $E$，对图中的两个结点 $u$ 和 $v$，若 $\langle u,v \rangle \notin E$，则 $X_u \perp X_v \mid X_{V\setminus \langle u,v \rangle}$.  
  注：$\setminus$ 表示『非』

<span id = "concept 14-9" > ▲ </span>**[马尔科夫毯(Markov blanket)(325)](#chapter 14)** : 某变量的所有邻接变量组成的集合称为该变量的马尔科夫毯。


<span id = "concept 14-10" > ▲ </span>**[条件随机场(Conditional Random Field)(325)](#chapter 14)** : 一种判别式无向图模型。判别式模型对条件分布进行建模，可看作给定观测值的马尔科夫随机场，也可看作对率回归(常说的逻辑回归)的扩展。  

  条件随机场试图对多个变量在给定观测值后的条件概率进行建模。具体来说，若令 $X=\{x_1,x_2,...,x_n\}$ 为观测序列，$\mathrm{y} = \{y_1,y_2,...,y_n\}$ 为与之相应的标记序列，则条件随机场的目标是构建条件概率模型 $P(\mathrm{y}|X)$。

  标记变量 $y$ 可以是结构型变量，即其分量之间具有某种相关性。

  令 $G=\langle V,E \rangle$ 表示结点与标记变量 $\mathrm{y}$ 中元素一一对应的无向图，$\mathit{y}_v$ 表示与结点 $v$ 对应的标记变量，$n(v)$ 表示结点 $v$ 的邻接结点，若图 $G$ 的每个变量 $\mathit{y}_v$ 都满足马尔科夫性，即：  
  $P(\mathit{y} \mid \mathrm{x}, \mathrm{y}_{V\setminus\{v\}}) = P(\mathit{y}_v \mid \mathrm{x}, \mathrm{y}_{n(v)})$ 则 $(\mathrm{y}, \mathrm{x})$ 构成一个条件随机场。

<span id = "concept 14-11" > ▲ </span>**[链式条件随机场(chain-structured CRF)(326)](#chapter 14)** : 构成条件随机场的图 $G$，理论上来说可具有任意结构，只要能表示标记变量之间的条件独立性关系即可。  

  但在现实应用中，尤其是对标记序列建模时，最常用的仍是链式结构，即：链式条件随机场(chain-structured CRF)

<span id = "concept 14-12" > ▲ </span>**[边际分布(marginal distribution)(328)](#chapter 14)** : 边际分布是指对无关变量求和或积分后得到结果。  

  例如在马尔科夫网中，变量的联合分布被表示成极大团的势函数乘积，于是，给定参数 $\Theta$ 求解某个变量 $x$ 的分布，就变成对联合分布中其他变量进行积分的过程，这称为『边际化』(marginalization)。

<span id = "concept 14-13" > ▲ </span>**[变量消去(328)](#chapter 14)** : 概率图模型的推断方法大致可以分为：精确推断方法和近似推断方法。  

  精确推断方法实质是一种动态规划算法，它利用图模型所描述的条件独立性来削减计算目标概率值所需的计算量。变量消去法是最直观的精确推断算法，也是构建其他精确推断算法的基础。  
  变量消去法通过利用乘法对加法的分配率，把多个变量的积的求和问题，转化为对部分变量交替进行求积与求和的问题。这种转化使得每次的求和与求积运算限制在局部，仅与部分变量有关，从而简化了运算。  
  它的一个明显的缺点是：若需计算多个边际分布，重复使用变量消去法将会造成大量的冗余计算。

<span id = "concept 14-14" > ▲ </span>**[信念传播(Belief Propagation)(330,340)](#chapter 14)** : 亦称 Sum-Product 算法，将变量消去法中的求和操作看作一个消息传递过程，较好地解决了求解多个边际分布时的重复计算问题。  

  信念传播算法最早由 Pearl 作为精确推断技术提出，后来衍生出多种近似推断算法。对一般的带环图，信念传播算法需在初始化、消息传递等环节进行调整，由此形成了迭代信念传播算法(Loopy Belief Propagation)。

<span id = "concept 14-15" > ▲ </span>**[MCMC(Markov Chain Monte Carlo)(331)](#chapter 14)** : 马尔科夫链蒙特卡洛方法，概率图模型中最常用的采样技术。  

  MCMC 方法先设法构造一条马尔科夫链，使其收敛至平稳分布恰为待估计参数的后验分布，然后通过这条马尔科夫链来产生符合后验分布的样本，并基于这些样本来进行估计。这里马尔科夫链转移概率的构造至关重要，不同的构造方法将产生不同的 MCMC 算法。

<span id = "concept 14-16" > ▲ </span>**[MH 算法(Metropolis-Hastings)(333)](#chapter 14)** : MH(Metropolis-Hastings)算法是 MCMC 的重要代表。它基于『拒绝采样』来逼近平稳分布。算法每次根据上一轮采样结果获得候选样本，但这个候选样本会以一定概率被『拒绝』掉。


<span id = "concept 14-17" > ▲ </span>**[变分推断(variational inference)(334)](#chapter 14)** : 变分推断通过使用已知简单分布来逼近需推断的复杂分布，并通过限制近似分布的类型，从而得到一种局部最优、但具有确定解的近似后验分布。  

  变分推断使用的近似分布须具有良好的数值性质，通常是基于连续型变量的概率密度函数来刻画的。

<span id = "concept 14-18" > ▲ </span>**[盘式记法(plate notation)(334)](#chapter 14)** : 概率图模型一种简洁的表示方法。相互独立的、由相同机制生成的多个变量被放在一个方框(盘)内，并在方框中标出类似变量重复出现的个数 $N$，方框可以嵌套。通常用阴影标注出已知的、能观察到的变量。在很多学习任务中，对属性变量使用盘式记法将使得图表示非常简洁。


<span id = "concept 14-19" > ▲ </span>**[KL 散度(Kullback-Leibler divergence)(335,414)](#chapter 14)** : 亦称相对熵或信息散度，可用于度量两个概率分部之间的差异。给定两个概率分布 $P$ 和 $Q$，二者之间的 KL 散度定义为：  

  $KL(P \parallel Q) = \int_{-\infty}^{\infty} p(x) \log \frac {p(x)}{q(x)}dx$，  
  其中 $p(x)$ 和 $q(x)$ 分别为 $P$ 和 $Q$ 的概率密度函数。

<span id = "concept 14-20" > ▲ </span>**[平均场(mean field)(337)](#chapter 14)** : 使用变分法对隐变量进行推断，对隐变量 $z_j$ 分布进行估计时，融合了 $z_j$ 之外的其他 $z_{i \ne j}$ 的信息，这是通过联合似然函数 $\ln p(x,z)$ 在 $z_j$ 之外的隐变量分布上求期望的到的，称为平均场方法。


<span id = "concept 14-21" > ▲ </span>**[话题模型(topic model)(337)](#chapter 14)** : 一族生成式有向图模型，主要用于处理离散型的数据(如文本集合)，在信息检索、自然语言处理等领域有广泛应用。  

  话题表示一个概念，具体表示为一系列相关的词，以及它们在该概念下出现的概率。

<span id = "concept 14-22" > ▲ </span>**[隐狄利克雷分配模型(Latent Dirichlet Allocation)(337)](#chapter 14)** : 隐狄利克雷分配模型(Latent Dirichlet Allocation，简称 LDA)是话题模型的典型代表。  

  现实任务中可通过统计文档中出现的词来获得词频向量，但通常并不知道这组文档谈论了哪些话题。LDA 从生成式模型的角度看待文档和话题。  
  具体来说，LDA 认为每篇文档包含多个话题，不妨用向量 $\Theta_t \in \mathbb{R}^N$ 表示文档 $t$ 中所包含的每个话题的比例，$\Theta_{t,k}$ 即表示文档 $t$ 中包含话题 $k$ 的比例，进而通过下面的步骤由话题生成文档 $t$：

* 根据参数为 $\alpha$ 的狄利克雷分布随机采样一个话题分布 $\Theta_t$；
* 按如下步骤生成文档中的 $N$ 个词：
  * 根据 $\Theta_t$ 进行话题指派，得到文档 $t$ 中的词 $n$ 的话题 $z_t,n$；
  * 根据指派的话题所对应的词频分布 $\mathcal{\beta_k}$ 随机采样生成词。
<span id = "concept 14-23" > ▲ </span>**[非参数化(non-parametric)法(340)](#chapter 14)** : 一般认为在一个统计推断问题中，如给定或者假定了总体分布的具体形式，只是其中含有若干个参数，要基于来自总体的样本对这些参数做出估计或者进行某种形式的假设检验，这类推断方法称为非参数化方法。非参数化是指参数的数目无须事先指定，是贝叶斯学习方法的重要发展。





## 规则学习

<span id = "concept 15-0" > ▲ </span>**[规则(rule)(347)](#chapter 15)** : 机器学习中的 “规则” 通常是指语义明确、能描述数据分布所隐含的客观规律或领域的概念、可写成 “若……，则……” 形式的逻辑规则。


<span id = "concept 15-1" > ▲ </span>**[规则学习(rule learning)(347)](#chapter 15)** : 规则学习是从训练数据中学习出一组能用于对未见示例进行判别的规则。


<span id = "concept 15-2" > ▲ </span>**[逻辑文字(literal)(347)](#chapter 15)** : 在数理逻辑中，“文字” 专指原子公式(atom)及其否定。


<span id = "concept 15-3" > ▲ </span>**[冲突消解(conflict resolution)(348)](#chapter 15)** : 规则集合是每条规则的的集成，当同一个示例被判别结果不同的多条规则覆盖时，称发生了 “冲突”(conflict)，解决冲突的办法称为 “冲突消解”(conflict resolution)。常用的策略有投票法、排序法、元规则法等。


<span id = "concept 15-4" > ▲ </span>**[带序规则(ordered rule)(348)](#chapter 15)** : 排序法消解冲突时会在规则集合上定义一个顺序，在发生冲突时使用排序最前的规则；相应的规则学习过程称为 “带序规则”(ordered rule)学习或 “优先级规则”(priority rule)学习。


<span id = "concept 15-5" > ▲ </span>**[优先级规则(priority rule)(348)](#chapter 15)** : 同 “带序规则”


<span id = "concept 15-6" > ▲ </span>**[元规则(meta-rule)(348)](#chapter 15)** : 关于规则的规则。


<span id = "concept 15-7" > ▲ </span>**[默认规则(default rule)(348)](#chapter 15)** : 规则学习算法通常会设置一条 “默认规则”(default rule)来处理规则集合未覆盖的样本。


<span id = "concept 15-8" > ▲ </span>**[缺省规则(348)](#chapter 15)** : 同 “默认规则”，可认为是一种特殊的元规则。


<span id = "concept 15-9" > ▲ </span>**[命题规则(propositional rule)(348)](#chapter 15)** : 由 “原子命题”(propositional atom)和逻辑连接词 “与”(∧)、“或”(∨)、“非”(￢)和 “蕴含”(←)构成的简单陈述句。


<span id = "concept 15-10" > ▲ </span>**[原子命题(348)](#chapter 15)** : 最基本的命题，不含逻辑连接词的逻辑文字。


<span id = "concept 15-11" > ▲ </span>**[一阶规则(348)](#chapter 15)** : 也被称为 “关系型规则”(relational rule)，基本成分是能描述事物的属性或关系的 “原子公式”(atomic formula)，例如表达父子关系的谓词(predicate)“父亲(X,Y)” 就是原子公式。 如果进一步用谓词 “自然数(X)” 表示 X 是自然数，那么 “所有自然数加 1 都是自然数” 就可写作 “∀X∃Y(自然数(Y) ← 自然数(X)∧(Y=δ(X))”，或更简洁的 “∀X(自然数(δ(X)) ← 自然数(X))”。这样的规则就是一阶规则。其中 X 和 Y 称为逻辑变量，“∀” “∃” 分别表示 “任意” 和 “存在”，用于限定变量的取值范围，称为 “量词”(quantifier)。 从形式语言系统的角度看，命题规则是一阶规则的特例。


<span id = "concept 15-12" > ▲ </span>**[序贯覆盖(sequential covering)(349)](#chapter 15)** : 规则学习的目标是产生一个能覆盖尽可能多的样例的规则集。最直接的做法是 “序贯覆盖”(sequential covering)，即逐条归纳：在训练集上每学到一条规则，就将该规则覆盖的训练样例去除，然后以剩下的训练样例组成训练集重复上述过程。 由于每次只处理一部分数据，因此也被称为 “分治”(separate-and-conquer)策略。


<span id = "concept 15-13" > ▲ </span>**[特化(specialization)(350)](#chapter 15)** : 使用序贯覆盖法时，在属性和候选值较多时会由于组合爆炸而不可行。现实任务中一般有两种策略来产生规则。其中一种是 “自顶向下”(top-down)，即从比较一般的规则开始，逐渐添加新文字以缩小规则覆盖范围，直到满足预定条件为止；亦称为 “生成-测试”(generate-then-test)法，这个过程就是规则逐渐 “特化”(specialization)的过程。这种方法通常更容易产生泛化性能较好的规则，也是通常使用的一种策略。


<span id = "concept 15-14" > ▲ </span>**[泛化(generalization)(350)](#chapter 15)** : 另一种产生策略的规则是 “自底向上”(bottom-up)，即从比较特殊的规则开始，逐渐删除文字以扩大规则覆盖范围，直到满足条件为止；亦称为 “数据驱动”(data-driven)法，这个过程就是规则逐渐 “泛化”(generalization)的过程。适用于训练样本较少的情形；通常在一阶规则学习这类假设空间非常复杂的任务上使用较多。


<span id = "concept 15-15" > ▲ </span>**[似然率(Likelihood Ratio Statistics,LRS)(352)](#chapter 15)** : 用于在已知某些观测数据时，对其参数进行估计，是关于模型参数的函数。在规则学习中，它衡量了规则(集)覆盖样例的分布与训练集经验分布的差别。LRS 越大，说明采用规则(集)进行预测与直接使用训练集正、反例比率进行猜测的差别越大；LRS 越小，说明规则(集)的效果越可能仅是偶然现象。


<span id = "concept 15-16" > ▲ </span>**[RIPPER(Repeated Incremental Pruning to Produce Error Reduction)(353)](#chapter 15)** : 一种著名的规则学习算法，它首先使用 IREP\* 剪枝机制生成规则集 $\mathcal{R}$，对 $\mathcal{R}$ 中的每条规则 $r_i$ 产生两个变体：


  * $r'_i$: 基于 $r_i$ 覆盖的样例，用 IREP\* 重新生成一条规则 $r'_i$，该规则称为替换规则(replacement rule)；
  * $r''_i$: 基于 $r_i$ 增加文字进行特化，然后再用 IREP\* 剪枝生成一条规则 $r''_i$，该规则称为修订规则(revised rule)。

  接下来，把 $r'_i$ 和 $r''_i$ 分别与 $\mathcal{R}$ 中除 $r_i$ 之外的规则放在一起，组成规则集 $\mathcal{R'}$ 和 $\mathcal{R''}$，将它们与 $\mathcal{R}$ 一起进行比较，选择最优的规则集保留下来。 RIPPER 将 $\mathcal{R}$ 中的所有规则放在一起重新加以优化，避免了最初按序生成时，每条规则没有对其后产生的规则加以考虑常常导致算法陷入局部最优的问题。

<span id = "concept 15-17" > ▲ </span>**[ILP(Inductive Logic Programming,归纳逻辑程序设计)(357,364)](#chapter 15)** : 归纳逻辑程序设计在一阶规则学习中引入了函数和逻辑表达式嵌套。一方面，这使得机器学习系统具备了更为强大的表达能力；另一方面 ILP 可看作用机器学习技术来解决基于背景知识的逻辑程序(logic program)归纳，其学得的 “规则” 可被 PROLOG 等逻辑程序设计语言直接使用。


<span id = "concept 15-18" > ▲ </span>**[归纳逻辑程序设计(357,364)](#chapter 15)** : 同 ILP。


<span id = "concept 15-19" > ▲ </span>**[最小一般泛化(Least General Generalization)(358)](#chapter 15)** : 自底向上的规则生成策略中，将 “特殊” 规则转变为更 “一般” 规则的技术叫 “最小一般泛化”(Least General Generalization，简称 LGG)。 给定一阶公式 r1 和 r2，LGG 先找出涉及相同谓词的文字，然后对文字中每个位置的常量逐一进行考察，若常量在两个文字中相同则保持不变，记为 LGG(t,t)=t；否则将他们替换为同一个新变量，并将该替换应用于公式的所有其他位置：假定这两个不同的常量分别为 s,t，新变量为 V，则记为 LGG(s,t) = V，并在以后所有出现 LGG(s,t) 的位置用 V 来代替。


<span id = "concept 15-20" > ▲ </span>**[归纳(induction)(359)](#chapter 15)** : 归纳是从个别事物出发概括出一般规律性。机器学习属于归纳的范畴。


<span id = "concept 15-21" > ▲ </span>**[逆归结(359)](#chapter 15)** : 假设两个逻辑表达式 C1 和 C2 成立，且分别包含了互补项 L1 与 L2；不失一般性，令 L = L1 = ￢L2，C1 = A ∨ L，C2 = B ∨ ￢L。归结原理是通过演绎推理消去 L 而得到 “归结项” C = A ∨ B。 而逆归结与上面过程相反，它研究的是在已知 C 和某个 Ci 的情况下如何得到 Cj。 基于逆归结，我们可基于背景知识来发明新的概念和关系。 在逻辑推理实践中，有四种完备的逆归结操作：吸收(absorption)、辨识(identification)、内构(intra-construction)、互构(inter-construction)。


<span id = "concept 15-22" > ▲ </span>**[演绎(deduction)(359)](#chapter 15)** : 演绎是从一般性规律出发来探讨具体事物。


<span id = "concept 15-23" > ▲ </span>**[置换(substitution)(361)](#chapter 15)** : 置换(substitution)是用某些项来替换逻辑表达式中的变量。


<span id = "concept 15-24" > ▲ </span>**[合一(unification)(361)](#chapter 15)** : 合一(unification)是用一种变量置换令两个或多个逻辑表达式相等。


<span id = "concept 15-25" > ▲ </span>**[最一般合一置换(most general unifer,简称 MGU)(361)](#chapter 15)** : 若 δ 是一组一阶逻辑表达式 W 的合一化子，且对 W 的任意合一化子 θ 均存在相应的置换 λ 使 θ = δ o λ，则称 δ 为 W 的 “最一般合一置换” 或 “最一般合一化子”。


<span id = "concept 15-26" > ▲ </span>**[归结商(resolution quotient)(362)](#chapter 15)** : 逆归结中，已知 C 和某个 Ci，则 Cj = C/Ci 称为 “归结商”。


<span id = "concept 15-27" > ▲ </span>**[关系学习(363)](#chapter 15)** : 关系学习是指学习对概念的网络式描述。


<span id = "concept 15-28" > ▲ </span>**[统计关系学习(statistical relational learning)(364)](#chapter 15)** : 将关系学习与统计学习相结合，如概率归纳逻辑程序设计、概率关系模型、贝叶斯逻辑程序、马尔科夫逻辑网等统称为 “统计关系学习”。



## 强化学习(reinforcement learning)

<span id = "concept 16-0" > ▲ </span>**[MDP(371)](#chapter 16)** : 在概率论和统计学中，马可夫决策过程(英语：Markov Decision Processes，缩写为 MDPs)提供了一个数学架构模型，用于面对部份随机，部份可由决策者控制的状态下，如何进行决策，以俄罗斯数学家安德雷·马尔可夫的名字命名。在经由动态规划与强化学习以解决最佳化问题的研究领域中，马可夫决策过程是一个有用的工具。


<span id = "concept 16-1" > ▲ </span>**[奖赏(reward)(371)](#chapter 16)** : 奖励函数定义了强化学习 Agent 的目标，它将环境的状态映射为一个数字(奖励)，表现了该状态的内在愿望。Agent 的目标是最大限度地提高长期收益。


<span id = "concept 16-2" > ▲ </span>**[马尔科夫决策过程(Markov Decision Process)(371)](#chapter 16)** : Markov Decision Process，通常用来描述强化学习任务：机器处于环境 $E$ 中，状态空间为 $X$，其中每个状态 $x \in X$ 是机器感知到的环境的描述；机器能采取的动作构成了动作空间 $A$；若某个动作 $a \in A$ 作用在当前状态 $x$ 上，则潜在的转移函数 $P$ 将使得环境从当前状态按某种概率转移到另一个状态；在转移到另一个状态的同时，环境会根据潜在的『奖赏』函数 $R$ 反馈给机器一个奖赏。


<span id = "concept 16-3" > ▲ </span>**[强化学习(reinforcement learning)(371)](#chapter 16)** : 强化学习是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。强化学习任务对应了四元组 $E = \langle \mathit{X,A,P,R} \rangle$，其中 $P: X \times A \times X \to \mathbb{R}$ 指定了状态转移概率，$R: X \times A \times X \to \mathbb{R}$ 指定了奖赏；在有的应用中，奖赏函数可能仅与状态转移有关，即 $R: X \times X \to \mathbb{R}$。


<span id = "concept 16-4" > ▲ </span>**[再励学习(371)](#chapter 16)** : 强化学习，亦称再励学习。


<span id = "concept 16-5" > ▲ </span>**[策略(policy)(372)](#chapter 16)** : 在环境中状态的转移、奖赏的返回是不受机器控制的，机器只能通过选择要执行的动作来影响环境，也只能通过观察转移后的状态和返回的奖赏来感知环境。  

  机器要做的是通过在环境中不断地尝试而学得一个『策略』(policy)$\pi$，根据这个策略，在状态 $x$ 下就能得知要执行的动作 $a = \pi(x)$。  
  简单来说，policy 是 Agent 的决策功能，规定了在 Agent 可能遇到的任何情况下应采取的行动。这是 Agent 的核心。  
  策略有两种表示方法：一种是将策略表示为函数 $\pi: X \to A$，确定性策略常用这种表示；另一种是概率表示 $\pi: X \times A \to \mathbb{R}$，随机性策略常用这种表示，$\pi(x,a)$ 为状态 $x$ 下选择动作 $a$ 的概率，这里必须有 $\sum_a \pi(x,a) = 1$。  
  在强化学习任务中，学习的目的就是要找到能使长期累积奖赏最大化的策略。

<span id = "concept 16-6" > ▲ </span>**[K-摇臂赌博机(K-armed bandit)(373)](#chapter 16)** : 单步强化学习对应的理论模型，K-摇臂赌博机(K-armed bandit)有 K 个摇臂，赌徒在投入一个硬币后可选择按下其中一个摇臂，每个摇臂以一定的概率吐出硬币，但这个概率赌徒并不知道。赌徒的目标是通过一定的策略最大化自己的奖赏，即获得最多的硬币。


<span id = "concept 16-7" > ▲ </span>**[ϵ-贪心(374)](#chapter 16)** : 强化学习面临「探索-利用窘境」，$\epsilon$-贪心法基于一个概率来对探索和利用进行折中：每次尝试时，以 $\epsilon$ 的概率进行探索，即以均匀概率随机选取一个摇臂；以 $1 - \epsilon$ 的概率进行利用，即选择当前平均奖赏最高的摇臂(若有多个，则最随机选择一个)。


<span id = "concept 16-8" > ▲ </span>**[探索-利用窘境(Exploration-Exploitation dilemma)(374)](#chapter 16)** : 若获知每个摇臂的期望奖赏，可采用「仅探索」法：将所有的尝试机会平均分配给每个摇臂(即轮流按下每个摇臂)，最后以每个摇臂各自的平均吐币概率作为其奖赏期望的近似估计。若执行奖赏最大的动作，则可采用「仅利用」法：按下目前最优的(即到目前为止平均奖赏最大的)摇臂，若有多个摇臂同为最优，则从中随机选取一个。  

  「探索」(即估计摇臂的优劣)和「利用」(即选择当前最优摇臂)这两者是矛盾的，因为尝试次数(即总投币数)有限，加强了一方则会自然削弱另一方，这就是强化学习所面临的「探索-利用窘境」(Exploration-Exploitation dilemma)。

<span id = "concept 16-9" > ▲ </span>**[Softmax(375)](#chapter 16)** : Softmax 算法基于当前已知的摇臂平均奖赏来对探索和利用进行折中。若个摇臂的平均奖赏想当，则选取个摇臂的概率也相当；若某些摇臂的平均奖赏高于其他摇臂，则它们被选取的概率也明显更高。  

  Softmax 算法中摇臂概率的分配是基于 Boltzmann 分布：  
  $P(k) = \frac {e^{\frac {Q(k)}{\tau}}}{\sum_{i=1}^K e^{\frac {Q(i)}{\tau}}}$，  
  其中，$Q(i)$ 记录当前摇臂的平均奖赏；$\tau > 0$ 称为「温度」，$\tau$ 越小则平均奖赏高的摇臂被选取的概率越高。$\tau$ 趋于 0 时 Softmax 将趋于「仅利用」，$\tau$ 趋于无穷大时 Softmax 则将趋于「仅探索」。

<span id = "concept 16-10" > ▲ </span>**[有模型学习(model-based learning)(377)](#chapter 16)** : 在已知模型的环境中学习称为「有模型学习」，即机器已对环境进行了建模，能在机器内部模拟出与环境相同或近似的情况。


<span id = "concept 16-11" > ▲ </span>**[状态-动作值函数(state-action value function)(377)](#chapter 16)** : 在模型已知时，对任意策略 $\pi$ 能估计出该策略带来的期望累积奖赏。令函数 $V^{\pi}(x)$ 表示从状态 $x$ 出发，使用策略 $\pi$ 所带来的累积奖赏；函数 $Q^{\pi}(x,a)$ 表示从状态 $x$ 出发，执行动作 $a$ 后再使用策略 $\pi$ 带来的累积奖赏。这里的 $V(\cdot)$ 称为「状态值函数」(state value function)，$Q(\cdot)$ 称为「状态-动作值函数」(state-action value function)，分别表示指定「状态」上以及指定「状态-动作」上的累积奖赏。


<span id = "concept 16-12" > ▲ </span>**[状态值函数(state value function)(377)](#chapter 16)** : 见「状态-动作值函数」。


<span id = "concept 16-13" > ▲ </span>**[Bellman 等式(380)](#chapter 16)** : 对于状态值函数，由于 MDP 具有马尔科夫性质，即系统下一时刻的状态仅由当前时刻的状态决定，不依赖于以往任何状态，于是值函数有很简单的递归形式。对于 $T$ 步累积奖赏有：  

  $V_T^{\pi}(x) = \sum_{a \in A} \pi (x, a) \sum_{x' \in X} P_{x \to x'}^a \lgroup \frac {1}{T} R_{x \to x'}^a + \frac {T-1}{T} V_{T-1}^{\pi} (x') \rgroup$，  
  这样的递归等式称为 Bellman 等式。

<span id = "concept 16-14" > ▲ </span>**[策略迭代(policy iteration)(381)](#chapter 16)** : 一种求解最优解的方法。从一个初始策略(通常是随机策略)出发，先进性策略评估，然后改进策略，评估改进的策略，再进一步改进策略，……不断迭代进行策略评估和改进，直到策略收敛、不再改进为止。这样的做法称为「策略迭代」(policy iteration)。


<span id = "concept 16-15" > ▲ </span>**[值迭代(value iteration)(382)](#chapter 16)** : 策略迭代算法在每次改进策略后都需重新进行策略评估，这通常比较耗时。由于策略改进和值函数的改进是一致的，因此可将策略改进视为值函数的改善。这种改善值函数的算法就称为值迭代(value iteration)算法。


<span id = "concept 16-16" > ▲ </span>**[免模型学习(model-free learning)(382)](#chapter 16)** : 在现实的强化学习任务中，环境的转移概率、奖赏函数往往很难得知，甚至很难知道环境中一共有多少状态。若学习算法不依赖于环境建模，则称为「免模型学习」(model-free learning)。


<span id = "concept 16-17" > ▲ </span>**[TD(Temporal Difference) 学习(386,393)](#chapter 16)** : 由于蒙特卡洛强化学习算法没有充分利用强化学习任务的 MDP 结构，因此效率要低很多。时序差分(Temporal Difference，简称 TD)学习则结合了动态规划与蒙特卡洛方法的思想，能做到更高效的免模型学习。


<span id = "concept 16-18" > ▲ </span>**[时序差分学习(386,393)](#chapter 16)** : 同 TD 学习。


<span id = "concept 16-19" > ▲ </span>**[Sarsa 算法(387,390)](#chapter 16)** : 该算法每次更新值函数需前一步的状态(state)、前一步的动作(action)、奖赏值(reward)、当前状态(state)、将要执行的动作(action)，因此得名 Sarsa 算法。Sarsa 让系统按照策略指引进行探索，在探索每一步都进行状态价值的更新，更新公式如下：  

  $Q^\pi_{t+1} (x,a) = Q^\pi_t (x,a) + \alpha \lgroup R^\alpha_{x \to x'} + \gamma Q^\pi_t(x',a') - Q^\pi_t(x,a) \rgroup$，  
  其中，$x'$ 是前一次在状态 $x$ 执行动作 $a$ 后转移到的状态，$a'$ 是策略 $\pi$ 在 $x'$ 上选择的动作。  
  Sarsa 是一个同策略(on-policy)算法，算法中的评估(上式)和执行($a' = \pi^\epsilon(x')$)的均为 $\epsilon$-贪心策略。

<span id = "concept 16-20" > ▲ </span>**[Q-学习(Q-learning)(387,393)](#chapter 16)** : 将 Sarsa 修改为异策略(off-policy)算法，即动作值函数更新(评估)不同于选取动作(执行)时遵循的策略，就得到 Q-学习算法，Q-学习的动作值函数更新公式如下：  

  $Q^\pi_{t+1} (x,a) = Q^\pi_t (x,a) + \alpha \lgroup R^\alpha_{x \to x'} + \gamma max_{a} Q^\pi_t(x',a) - Q^\pi_t(x,a) \rgroup$

<span id = "concept 16-21" > ▲ </span>**[表格值函数(tabular value function)(388)](#chapter 16)** : 如果我们假定强化学习任务是在有限状态空间上进行，每个状态可以用一个编号来指代；值函数就是关于有限状态的「表格值函数」(tabular value)，也就是说值函数能表示为一个数组，输入 $i$ 对应的函数值就是数组元素 $i$ 的值，且更改一个状态上的值不影响其他状态上的值。


<span id = "concept 16-22" > ▲ </span>**[值函数近似(value function approximation)(388)](#chapter 16)** : 实际强化学习任务所面临的状态空间往往是连续的，有无穷多个状态。我们假定状态空间为 $n$ 维实数空间 $X = \mathbb{R}^n$，此时显然无法用表格值函数来记录状态值。但考虑简单情形，即值函数能表达为状态的线性函数：  

  $V_\theta(x) = \theta^Tx$，  
  其中 $x$ 为状态向量，$\theta$ 为参数向量。由于此时的值函数难以像有限状态那样精确记录每个状态的值，因此这样的值函数求解被称为值函数近似(value function approximation)。

<span id = "concept 16-23" > ▲ </span>**[模仿学习(imitation learning)(390)](#chapter 16)** : 在强化学习的经典任务设置中，机器所能获得的反馈信息仅有多步决策后的累计奖赏，但在现实任务中，往往能得到人类专家的决策过程范例。从这样的范例中学习，称为「模仿学习」(imitation learning)。


<span id = "concept 16-24" > ▲ </span>**[逆强化学习(inverse reinforcement learning)(391)](#chapter 16)** : 在很多任务中，设计奖赏函数往往相当困难，从人类专家提供的范例数据中反推出奖赏函数有助于解决该问题，这就是「逆强化学习」(inverse reinforcement learning)。  

  逆强化学习的基本思想是：欲使机器做出与范例一致的行为，等价于在某个奖赏函数的环境中求解最优策略，该最优策略所产生的轨迹与范例数据一致。换言之，我们要寻找某种奖赏函数使得范例数据是最优的，然后即可使用这个奖赏函数来训练强化学习策略。

<span id = "concept 16-25" > ▲ </span>**[近似动态规划(approximate dynamic programming)(393)](#chapter 16)** : 强化学习在运筹学与控制论领域的研究被称为「近似动态规划」(approximate dynamic programming)。


## 附录

<span id = "concept 17-0" > ▲ </span>**[行列式(determinant)(399)](#chapter 17)** : n 阶方阵 A 的行列式(determinant)定义为：  

  $det(A) = \sum_{\sigma \in S_n} par(\sigma) A_{1\sigma_1}A_{2\sigma_2}...A_{n\sigma_n}$  
  其中，Sn 为所有 n 阶排列(permutation)的集合，par(σ) 的值为 -1 或 +1 取决于 σ = (σ1,σ2,...σn) 为奇排列或偶排列，即其中出现降序的次数为奇数或偶数，例如 (1,3,2) 中降序次数为 1，(3,1,2) 中降序次数为 2。对于单位阵，有 det(I) = 1。

  直观理解：

  * 是什么：以二维为例，表示一个区域的面积，负数则是将区域翻转，或者说定向改变。如果矩阵所代表的变换将空间压缩到更小的维度(不满秩)，则行列式为 0(比如二维到一维，面积就变成了零)。列代表基向量，行代表坐标，一个 m×n 的矩阵表示 n 个基向量表示的空间映射在 m 维的坐标上。行列式是面积(二维)或体积(三维)缩放的比例。 
  * 怎么算：以二维为例，主对角线元素代表两个维度缩放的比例，其余两个元素代表两个维度的坐标区域对角线的缩放。  

<span id = "concept 17-1" > ▲ </span>**[迹(trace)(399)](#chapter 17)** : 对于 n 阶方阵 A，它的迹(trace)是主对角线上的元素之和，即：  

  $tr(A) = \sum_{i=1}^n A_ii$

<span id = "concept 17-2" > ▲ </span>**[Frobenius 范数(400)](#chapter 17)** : 矩阵 A(m×n) 的 Frobenius 范数定义为：  

  $\Arrowvert A \Arrowvert_F = (tr(A^TA))^{1/2} = \lgroup \sum_{i=1}^m \sum_{j=1}^n A_{ij}^2 \rgroup ^{1/2}$  
  矩阵的 Frobenius 范数就是将矩阵张成向量后的 L2 范数，其实就是所有元素的平方和再开方。

<span id = "concept 17-3" > ▲ </span>**[低秩矩阵近似问题(402)](#chapter 17)** : 给定一个秩为 r 的矩阵 A，欲求其最优 k 秩近似矩阵 A'(k ≤ r)，这样的问题称为低秩矩阵近似问题。  

  该问题可以形式化为：  
  $min_{A' \in R^{m*n}} \ \ \Arrowvert A - A' \Arrowvert_F, \ \ \ s.t. rank(A') = k$  
  该问题可以使用奇异值分解：对矩阵 A 进行奇异值分解后，将 Σ 矩阵(见奇异值分解)的 r-k 个最小的奇异值置零获得矩阵 Σ\_k，A\_k = U\_k Σ\_k V\_k^T 就是最优解，其中 U\_k 和 V\_k 分别是 U 和 V 前 k 列组成的矩阵。这个结果也称为 Eckart-Young-Mirsky 定理。

<span id = "concept 17-4" > ▲ </span>**[奇异值分解(Singular Value Decomposition,简称 SVD)(402)](#chapter 17)** : 对任意矩阵 $A \in \mathbb{R}^{m\times n}$ 都可分解为：$A = U\sum V^T$，其中，$U \in \mathbb{R}^{m\times m}$ 是满足 $U^TU=I$ 的 m 阶酉矩阵(unitary matrix)；$V \in \mathbb{R}^{n \times n}$ 是满足 $V^TV=I$ 的 n 阶酉矩阵；$\sum \in \mathbb{R}^{m \times n}$ 是 m×n 的矩阵，其中 $(\sum)_{ii} = \sigma_i$ 且其他位置的元素均为 0，$\sigma_i$ 为非负实数且满足 $\sigma_1 \ge \sigma_2 \ge ... \ge 0$。


<span id = "concept 17-5" > ▲ </span>**[拉格朗日乘子法(Lagrange multipliers)(403)](#chapter 17)** : 拉格朗日乘子法是一种寻找多元函数在一组约束下的极值的方法。通过引入拉格朗日乘子，可将有 d 个变量与 k 个约束条件的最优化问题转化为具有 d+k 个变量的无约束优化问题求解。有等式约束和不等式约束两种。  

  以等式约束的优化问题为例。假定 x 为 d 维向量，要求 x 的某个取值 x\* 使目标函数 f(x) 最小且同时满足 g(x)=0 的约束。从几何角度看该问题的目标是在由方程 g(x)=0 确定的 d-1 维曲面上寻找能使目标函数 f(x) 最小化的点。此时很容易得出在最优点目标函数与约束函数相切(即目标函数在该点的梯度正交于约束曲面)。由此可知，在最优点，梯度 $\nabla g(x), \nabla f(x)$ 方向相同或相反：，即存在 λ ≠ 0 使得 $\nabla f(x^*) + \lambda \nabla g(x^*) = 0$，λ 称为拉格朗日乘子，定义拉格朗日函数为：$L(x, \lambda) = f(x) + \lambda g(x)$。

<span id = "concept 17-6" > ▲ </span>**[对偶函数(dual function)(405)](#chapter 17)** : 将优化问题的约束推广到多个：具有 m 个等式约束和 n 个不等式约束，且可行域 $\mathbb{D} \subset \mathbb{R}^d$ 非空的优化问题：  

  $min_x f(x) \ \ s.t.\ \ h_i(x) = 0\ (i=1,...m);\ g_j(x) \le 0\ (j=1,...n)$  
  该问题为优化问题的主问题(primal problem)，相应的拉格朗日函数为：  
  $L(x,\lambda,\mu) = f(x) + \sum_{i=1}^m \lambda_i h_i(x) + \sum_{j=1}^n \mu_j g_j(x)$，  
  其对偶函数定义为：  
  $\Gamma(\lambda, \mu) = \inf_{x\in D} L (x, \lambda, \mu) = \inf_{x\in D} \lgroup f(x) + \sum_{i=1}^m \lambda_i h_i(x) + \sum_{j=1}^n \mu_j g_j(x)\rgroup$。  
  对偶函数给出了主问题的最优值下界，因为若 x\* 为主问题可行域的点，对任意 $\mu \succeq 0, \lambda$，都有 $\sum_{i=1}^m \lambda_i h_i(x) + \sum_{j=1}^n \mu_j g_j(x) \le 0$，进而有 $\Gamma(\lambda,\mu) \le L(x^*, \lambda, \mu) \le f(x^*)$。

<span id = "concept 17-7" > ▲ </span>**[二次规划(Quadratic Programming,简称 QP)(406)](#chapter 17)** : 一类典型的优化问题，包括凸二次优化和非凸二次优化。目标函数是变量的二次函数，约束条件是变量的线性不等式。假定变量个数为 d，约束条件个数为 m，标准的二次规划问题形如：  

  $\min_x \ \ \frac{1}{2} x^TQx + c^Tx, \ \ s.t. Ax \le b$  
  其中，x 为 d 维向量， Q ∈ R 为实对称矩阵，A ∈ R 为实矩阵，b ∈ R 和 c ∈ R 为实向量，Ax ≤ b 的每一行对应一个约束。

<span id = "concept 17-8" > ▲ </span>**[半正定规划(Seme-Definite Programming,简称 SDP)(407)](#chapter 17)** : 是一类凸优化问题，其中的变量可组织成半正定对称矩阵形式，且优化问题的目标函数和约束都是这些变量的线性函数。  

  给定 d×d 的对称矩阵 **X, C**，$C·X = \sum_{i=1}^d\sum_{j=1}^dC_{ij}X_{ij}$，  
  若 Ai(i=1,...,m) 也是 d×d 的对称矩阵，bi(i=1,2,...,m) 为 m 个实数，则半正定规划问题形如：  
  $min_X C · X; \ \ s.t. \ A_i \cdot X = b_i; \ \ i = 1,2,...,m, X \succeq 0$

<span id = "concept 17-9" > ▲ </span>**[伯努利分布(Bernoulli distribution)(409)](#chapter 17)** : 关于布尔变量 x ∈ {0,1} 的概率分布，其连续参数 μ ∈ \[0,1\] 表示变量 x=1 的概率。  

  $P(x|\mu) = Bern(x|\mu) = \mu^x(1-\mu)^{(1-x)}$  
  $\mathbb{E}[x] = \mu; var[x] = \mu(1-\mu)$

<span id = "concept 17-10" > ▲ </span>**[均匀分布(uniform distribution)(409)](#chapter 17)** : 关于定义在区间 `[a,b](a<b)` 上连续变量的简单概率分布。  

  $p(x|a,b) = U(x|a,b) = \frac{1}{b-a}$  
  $\mathbb{E}[x] = \frac{a+b}{2}; var[x] = \frac{(b-a)^2}{12}$

<span id = "concept 17-11" > ▲ </span>**[多项分布(multinominal distribution)(410)](#chapter 17)** : 将伯努利分布由单变量扩展为 d 维，并在此基础上扩展二项分布就得到多项分布，它描述了在 N 次独立实验中有 mi 次 xi=1 的概率。  

  $P(m_1,m_2,...,m_d|N,\mu) = Mult(m_1,m_2,...,m_d|N,\mu) = \frac{N!}{m_1!m_2!...m_d!} \prod_{i=1}^d \mu_i^{m_i}$  
  $\mathbb{E}[m_i] = N\mu_i; \ var[m_i] = N\mu_i(1-\mu_i); \ cov[m_j,m_i] = -N\mu_j\mu_i$

<span id = "concept 17-12" > ▲ </span>**[二项分布(binomial distribution)(410)](#chapter 17)** : 描述 N 次是独立的伯努利实验中有 m 次成功(x=1)的概率。  

  $P(m|N,\mu) = Bin(m|N,\mu) = {N \choose m} \mu^m (1-\mu)^{N-m}$

<span id = "concept 17-13" > ▲ </span>**[贝塔分布(Beta distribution)(411)](#chapter 17)** : 关于连续变量 μ ∈ \[0,1\] 的概率分布，由两个参数 a&gt;0, b&gt;0 确定：  

  $p(\mu|a,b) = Beta(\mu|a,b) = \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} \mu^{a-1} (1-\mu)^{b-1} = \frac{1}{B(a,b)} \mu^{a-1}(1-\mu)^{b-1}$  
  $\mathbb{E}[\mu] = \frac{a}{a+b}; \ var[\mu] = \frac{ab}{(a+b)^2(a+b+a)}; \ \Gamma(a) = \int_{0}^{+\infty}t^{a-1}e^{-t}dt$  
  当 a=b=1 时，贝塔分布退化为均匀分布。

<span id = "concept 17-14" > ▲ </span>**[狄利克雷分布(Dirichlet distribution)(412)](#chapter 17)** : 关于一组 d 个连续变量 μi ∈ \[0,1\] 的概率分布，$\sum_{i=1}^d \mu_i = 1$。令 $\mu = (\mu_1,...,\mu_d)$，参数 $\alpha = (\alpha_1,...,\alpha_d), \ \alpha_i>0, \hat{\alpha} = \sum_{i=1}^d \alpha_i$  

  $p(\mu|\alpha) = Dir(\mu|\alpha) = \frac{\Gamma(\hat{\alpha})}{\Gamma(\alpha_1)...\Gamma(\alpha_i)} \prod_{i=1}^d \mu_i^{(\alpha_i-1)}$  
  $\mathbb{E}[\mu_i] = \frac{\alpha_i}{\hat{\alpha}}, \ var[\mu_i] = \frac{\alpha_i(\hat{\alpha}-\alpha_i)}{\hat{\alpha}^2(\hat{\alpha}+1)}, \ cov[\mu_j,\mu_i] = \frac{\alpha_j\alpha_i}{\hat{\alpha}^2(\hat{\alpha}+1)}$  
  当 d=2 时，狄利克雷分布退化为贝塔分布。

<span id = "concept 17-15" > ▲ </span>**[高斯分布(Gaussian distribution)(412)](#chapter 17)** : 亦称正态分布(normal distribution)，是应用最广泛的连续概率分布。  

  对于单变量 x ∈ (-∞, +∞)，高斯分布的参数为均值 μ ∈ (-∞, +∞) 和 方差 σ^2 &gt; 0。  
  $p(x|\mu,\sigma^2) = \mathcal{N}(x|\mu,\sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp \{ -\frac{(x-\mu)^2}{2\sigma^2} \}$  
  $\mathbb{E}=\mu, \ var[x]=\sigma^2$  
  对于 d 维向量 **x**，多元高斯分布的参数为 d 维均值向量 **μ** 和 d×d 的对称正定协方差矩阵 **Σ**。  
  $p(x|\mu,\sum) = \mathcal{N}(x|\mu,\sum) = \frac{1}{\sqrt{2\pi^d \det(\sum)}} \exp \{ -\frac{1}{2}(x-\mu)^T {\sum}^{-1}(x-\mu) \}$  
  $\mathbb{E}=\mu, \ var[x]=\sum$

<span id = "concept 17-16" > ▲ </span>**[正态分布(normal distribution)(412)](#chapter 17)** : 同高斯分布。


<span id = "concept 17-17" > ▲ </span>**[共轭分布(conjugate distribution)(413)](#chapter 17)** : 假设变量 x 服从分布 P(x\|Θ)，其中 Θ 为参数，X={x1,x2,...,xm} 为变量 x 的观测样本，假设参数 Θ 服从先验分布 ∏(Θ)。  

  若由先验分布 ∏(Θ) 和抽样分布 P(X\|Θ) 决定的后验分布 F(Θ\|X) 与 ∏(Θ) 是同种类型的分布，则称先验分布 ∏(Θ) 为分布 P(X\|Θ) 或 P(x\|Θ) 的共轭分布。

<span id = "concept 17-18" > ▲ </span>**[相对熵(relative entropy)(414)](#chapter 17)** : 亦称 KL 散度或信息散度，可用于度量两个概率分布之间的差异。给定两个概率分布 P 和 Q，二者之间的相对熵定义为：  

  $KL(P||Q) = \int_{-\infty}^{+\infty} p(x)\log\frac{p(x)}{q(x)}dx$  
  其中 p(x) 和 q(x) 分别为 P 和 Q 的概率密度函数。  
  通俗地说，用分布 Q 的最佳信息传递方式来传达分布 P，比用分布 P 自己的最佳信息方式传达平均多耗费的信息长度为 KL 散度。

<span id = "concept 17-19" > ▲ </span>**[信息散度(information divergence)(414)](#chapter 17)** : 同相对熵。


<span id = "concept 17-20" > ▲ </span>**[交叉熵(cross entropy)(415)](#chapter 17)** : KL 散度展开可得：  

  $KL(P||Q) = \int_{-\infty}^{+\infty} p(x)\log p(x)dx - \int_{-\infty}^{+\infty} p(x)\log q(x)dx = -H(P) + H(P,Q)$  
  其中 H(P) 为熵，H(P,Q) 为 P 和 Q 的交叉熵。 通俗地说，用分布 Q 的最佳信息传递方式传达分布 P 中随机抽选的一个事件，所需的平均信息长度为交叉熵。

<span id = "concept 17-21" > ▲ </span>**[熵(entropy)(415)](#chapter 17)** : 熵是对整个事件信息量的量化，传达信息所需的最优平均信息长度为香农熵。  

  $H(P) = \sum_xP(x)\log\frac{1}{P(x)}$

附：一些不错的学习资料

* 奇异值分解
  * [奇异值分解 SVD 的数学解释 - CSDN 博客](https://blog.csdn.net/u010099080/article/details/68060274)
  * [(3 条消息) 奇异值的物理意义是什么？ - 知乎](https://www.zhihu.com/question/22237507)
  * [机器学习中的数学 (5)- 强大的矩阵奇异值分解 (SVD) 及其应用 - LeftNotEasy - 博客园](http://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/1939687.html)
  * [奇异值分解 (SVD) 原理详解及推导 - CSDN 博客](https://blog.csdn.net/zhongkejingwang/article/details/43053513)
* 拉格朗日乘子法
  * [(3 条消息) 拉格朗日乘子法如何理解？ - 知乎](https://www.zhihu.com/question/38586401)
  * [【整理】深入理解拉格朗日乘子法(Lagrange Multiplier) 和 KKT 条件 - mo\_wang - 博客园](http://www.cnblogs.com/mo-wang/p/4775548.html)
  * [An Introduction to Lagrange Multipliers](http://www.slimy.com/~steuard/teaching/tutorials/Lagrange.html)
* 梯度
  * [文章](https://www.matongxue.com/madocs/222.html#/madoc)
  * [为什么梯度反方向是函数值局部下降最快的方向？](https://zhuanlan.zhihu.com/p/24913912)
  * [梯度 - YouTube](https://www.youtube.com/watch?v=npkl19rcpdY)
* 正定矩阵和半正定矩阵
  * [正定矩阵与半正定矩阵定义性质与理解 - CSDN 博客](https://blog.csdn.net/asd136912/article/details/79146151)
* 贝塔分布
  * [带你理解 beta 分布 - CSDN 博客](https://blog.csdn.net/a358463121/article/details/52562940)
* 狄利克雷分布
  * [(2 条消息) 什么是狄利克雷分布？狄利克雷过程又是什么？ - 知乎](https://www.zhihu.com/question/26751755)
  * [机器学习的数学基础(1)--Dirichlet 分布 - CSDN 博客](https://blog.csdn.net/jwh_bupt/article/details/8841644)
  * [科学网—再谈分布之分布(dirichlet 分布)- 贝叶斯分析之 2 - 张天蓉的博文](http://blog.sciencenet.cn/blog-677221-1051014.html)
  * [通俗理解 Dirichlet 分布及其实践 \| A Notebook](https://xijunlee.github.io/2017/09/09/Dirichlet分布与Beta分布/)
  * [Dirichlet Distribution(狄利克雷分布)与 Dirichlet Process(狄利克雷过程) \| 数据学习者官方网站 (Datalearner)](https://www.datalearner.com/blog/1051459673766843)
  * [LDA数学八卦](http://emma.memect.com/t/9756da9a47744de993d8df13a26e04e38286c9bc1c5a0d2b259c4564c6613298/LDA)
* 熵、相对熵、交叉熵
  * [Shannon entropy in the context of machine learning and AI](https://medium.com/swlh/shannon-entropy-in-the-context-of-machine-learning-and-ai-24aee2709e32)
  * [如何理解KL散度的不对称性 \| 机器之心](https://www.jiqizhixin.com/articles/0224)
  * [【 深度学习 】熵，交叉熵，KL 散度 Entropy, Cross-Entropy and KL-Divergence](https://www.bilibili.com/video/av19193502?from=search&seid=9145887951572377038)

